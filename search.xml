<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>堆的应用-合并有序小文件</title>
    <url>/2021/06/07/mergeFiles/</url>
    <content><![CDATA[<p>&ensp;&ensp;假设我们有 100 个小文件，每个文件的大小是 100MB，每个文件中存储的都是有序的字符串。我们希望将这些 100 个小文件合并成一个有序的大文件。这里就会用到优先级队列。</p>
<p>&ensp;&ensp;整体思路有点像归并排序中的合并函数。我们从这 100 个文件中，各取第一个字符串，放入数组中，然后比较大小，把最小的那个字符串放入合并后的大文件中，并从数组中删除。</p>
<span id="more"></span>

<p>&ensp;&ensp;假设，这个最小的字符串来自于 13.txt 这个小文件，我们就再从这个小文件取下一个字符串，并且放到数组中，重新比较大小，并且选择最小的放入合并后的大文件，并且将它从数组中删除。依次类推，直到所有的文件中的数据都放入到大文件为止。</p>
<p>&ensp;&ensp;这里我们用数组这种数据结构，来存储从小文件中取出来的字符串。每次从数组中取最小字符串，都需要循环遍历整个数组，显然，这不是很高效。有没有更加高效方法呢？</p>
<p>&ensp;&ensp;我们知道，删除堆顶数据和往堆中插入数据的时间复杂度都是 O(logn)，n 表示堆中的数据个数，这里就是 100。是不是比原来数组存储的方式高效了很多呢？</p>
<p>&ensp;&ensp;思路已经有了，这里我用Java实现了一个小规模的合并100个包含有序数字的demo:</p>
<p>1.声明几个静态变量</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/** 有序文件列表**/</span><br><span class="line">public static ArrayList&lt;File&gt; fileList = new ArrayList&lt;&gt;();    </span><br><span class="line"> /** 小顶堆 **/</span><br><span class="line">private static Heap&lt;Node&gt; heap = new Heap&lt;&gt;(101, new Comparator&lt;Node&gt;() &#123;        </span><br><span class="line">    @Override</span><br><span class="line">    public int compare(Node o1, Node o2) &#123;            </span><br><span class="line">       <span class="keyword">if</span> (Long.parseLong(o1.getWord()) &gt; Long.parseLong(o2.getWord())) &#123;               </span><br><span class="line">           <span class="built_in">return</span> -1;</span><br><span class="line">       &#125; <span class="keyword">else</span> <span class="keyword">if</span> (Long.parseLong(o1.getWord()) &lt; Long.parseLong(o2.getWord())) &#123;                </span><br><span class="line">           <span class="built_in">return</span> 1;</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;               </span><br><span class="line">           <span class="built_in">return</span> 0;</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;);   </span><br><span class="line"> /**  file -&gt; fileReader 保存每个文件的输入流**/</span><br><span class="line">private static HashMap&lt;File, BufferedReader&gt; readerMap = new HashMap&lt;&gt;();    </span><br><span class="line">/** 每个文件的行数 **/</span><br><span class="line">private static int fileLine = 100000;</span><br></pre></td></tr></table></figure>

<p>2.创建小文件并写入内容</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 创建小文件(如果存在，将其删除）并写入内容</span><br><span class="line"> *</span><br><span class="line"> * @param dic</span><br><span class="line"> */</span><br><span class="line">public static void create(String dic) throws IOException &#123;</span><br><span class="line">    File file = new File(dic);        </span><br><span class="line">    <span class="keyword">if</span> (!file.exists()) &#123;</span><br><span class="line">        file.mkdirs();</span><br><span class="line">    &#125;        </span><br><span class="line">    <span class="keyword">if</span> (file.isDirectory()) &#123;</span><br><span class="line">        String fileName = dic + <span class="string">&quot;\\test&quot;</span>;            </span><br><span class="line">        <span class="keyword">for</span> (int i = 0; i &lt; 100; i++) &#123;</span><br><span class="line">           File f = new File(fileName + i + <span class="string">&quot;.txt&quot;</span>);                <span class="keyword">if</span> (!f.exists()) &#123;</span><br><span class="line">               f.createNewFile();</span><br><span class="line">               writeFileContent(f.getAbsolutePath(), i);</span><br><span class="line">           &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                f.delete();</span><br><span class="line">                f.createNewFile();</span><br><span class="line">                writeFileContent(f.getAbsolutePath(), i);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;    </span><br><span class="line">/**</span><br><span class="line"> * 写入内容，每行相差&lt;!--fileLine--&gt;</span><br><span class="line"> *</span><br><span class="line"> * @param fileName</span><br><span class="line"> * @param i</span><br><span class="line"> */</span><br><span class="line">public static void writeFileContent(String fileName, long i) &#123;</span><br><span class="line">    File file = new File(fileName);        </span><br><span class="line">    <span class="keyword">if</span> (file.exists()) &#123;            </span><br><span class="line">        try (PrintWriter pw = new PrintWriter(new FileOutputStream(file))) &#123;                </span><br><span class="line">            <span class="keyword">for</span> (int j = 0; j &lt; fileLine; j++) &#123;</span><br><span class="line">                pw.write(i + <span class="string">&quot;\r\n&quot;</span>);</span><br><span class="line">                pw.flush();</span><br><span class="line">                i = i + fileLine;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; catch (FileNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>3.初始化fileList和fileReaded</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">public static void init(File file) throws FileNotFoundException &#123;        </span><br><span class="line">    <span class="keyword">if</span> (file.isDirectory()) &#123;</span><br><span class="line">        File[] files = file.listFiles();            </span><br><span class="line">        <span class="keyword">for</span> (File f : files) &#123;                </span><br><span class="line">            <span class="keyword">if</span> (f.isDirectory()) &#123;</span><br><span class="line">                init(f);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;                    </span><br><span class="line">                <span class="keyword">if</span> (f.getName().indexOf(<span class="string">&quot;bigFile&quot;</span>) &lt; 0) &#123;</span><br><span class="line">                    fileList.add(f);</span><br><span class="line">                    readerMap.put(f, new BufferedReader(new InputStreamReader(new FileInputStream(f))));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;            </span><br><span class="line">        <span class="keyword">if</span> (file.getName().indexOf(<span class="string">&quot;bigFile&quot;</span>) &lt; 0) &#123;</span><br><span class="line">            fileList.add(file);</span><br><span class="line">            readerMap.put(file, new BufferedReader(new InputStreamReader(new FileInputStream(file))));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>4.创建大文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 新建大文件，如果存在，将其删除</span><br><span class="line"> * </span><br><span class="line"> * @<span class="built_in">return</span></span><br><span class="line"> * @throws IOException</span><br><span class="line"> */</span><br><span class="line">public static File createBigFile() throws IOException &#123;</span><br><span class="line">   File bigFile = new File(<span class="string">&quot;D:\\data\\mergeFileData\\bigFile.txt&quot;</span>);        </span><br><span class="line">   <span class="keyword">if</span> (!bigFile.exists()) &#123;</span><br><span class="line">        bigFile.createNewFile();</span><br><span class="line">   &#125;        </span><br><span class="line">   try (FileWriter fileWriter = new FileWriter(bigFile)) &#123;</span><br><span class="line">        fileWriter.write(<span class="string">&quot;&quot;</span>);</span><br><span class="line">        fileWriter.flush();</span><br><span class="line">   &#125;        </span><br><span class="line">   <span class="built_in">return</span> bigFile;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>5.初始化堆，从每个小文件读入一行到堆中。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">public static void initHeap(File bigFile) throws FileNotFoundException &#123;        </span><br><span class="line">    <span class="keyword">for</span> (File file : fileList) &#123;</span><br><span class="line">         BufferedReader reader = readerMap.get(file);</span><br><span class="line">         String word;            </span><br><span class="line">         try &#123;</span><br><span class="line">            word = reader.readLine();                </span><br><span class="line">            <span class="keyword">if</span> (word != null) &#123;</span><br><span class="line">                heap.insert(new Node(word, file));</span><br><span class="line">            &#125;</span><br><span class="line">       &#125; catch (IOException e) &#123;</span><br><span class="line">           e.printStackTrace();</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>6.循环堆，删除堆顶元素，并将堆顶元素写入大文件中，若堆顶元素来自于此时被读的文件，则继续读此文件，否则继续删除堆顶元素以读取下一个文件.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">public static void move(File bigFile) &#123;        </span><br><span class="line">    try (PrintWriter pw = new PrintWriter(new FileOutputStream(bigFile))) &#123;            </span><br><span class="line">        <span class="keyword">while</span> (heap.getCount() &gt; 0) &#123;</span><br><span class="line">            Node minNode = heap.deleteFirst();</span><br><span class="line">            pw.write(minNode.getWord() + <span class="string">&quot;\r\n&quot;</span>);</span><br><span class="line">            File file = minNode.getFile();</span><br><span class="line">            BufferedReader reader = readerMap.get(file);</span><br><span class="line">            String word = reader.readLine();                </span><br><span class="line">            <span class="keyword">if</span> (word != null &amp;&amp; word != <span class="string">&quot;\r\n&quot;</span>) &#123;</span><br><span class="line">                Node node = new Node(word, file);</span><br><span class="line">                heap.insert(node);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        heap.print();</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><a href="https://github.com/Xuwudong/algo">完整代码链接（文件为MergeFiles.java）</a></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>堆</tag>
      </tags>
  </entry>
  <entry>
    <title>算法的奥秘-回溯（1）</title>
    <url>/2021/06/17/backtracing-1/</url>
    <content><![CDATA[<p>&ensp;&ensp;今天分享一道简单的回溯算法题（在我看来并不简单！），毁灭吧，赶紧的！<br>题目：二进制手表<br>描述：二进制手表顶部有 4 个 LED 代表 小时（0-11），底部的 6 个 LED 代表 分钟（0-59）。</p>
<p>每个 LED 代表一个 0 或 1，最低位在右侧。</p>
<span id="more"></span>

<p><img src="/images/backtracing/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%89%8B%E8%A1%A8.webp" alt="avatar"></p>
<p>例如，上面的二进制手表读取 “3:25”。<br><br>给定一个非负整数 n 代表当前 LED 亮着的数量，返回所有可能的时间。</p>
<p>示例：<br>输入: n = 1<br><br>返回: [“1:00”, “2:00”, “4:00”, “8:00”, “0:01”, “0:02”, “0:04”, “0:08”, “0:16”, “0:32”]<br><br>提示：</p>
<ul>
<li>输出的顺序没有要求。</li>
<li>小时不会以零开头，比如 “01:00” 是不允许的，应为 “1:00”。</li>
<li>分钟必须由两位数组成，可能会以零开头，比如 “10:2” 是无效的，应为 “10:02”。</li>
<li>超过表示范围（小时 0-11，分钟 0-59）的数据将会被舍弃，也就是说不会出现 “13:00”, “0:61” 等时间。</li>
</ul>
<p>分析：题目需要返回所有可能的时间，可以对手表建模，时钟定义一个数组hours,包含4盏灯，代表数值分别为【1,2，4,8】，分钟定义一个数组mins，包含6盏灯，代表数值分别为【1,2，4,8，16,32】。对于输入n,需要从hours中取出i盏灯，mins中取出n-j盏灯，并将合并的结果存入list。这就是子集的变形，很容易想到用回溯求解，但是做起来还是有一些注意点值得关注，直接看代码！</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">int[] hours = new int[]&#123;1, 2, 4, 8&#125;;</span><br><span class="line">int[] mins = new int[]&#123;1, 2, 4, 8, 16, 32&#125;;</span><br><span class="line"></span><br><span class="line">public List&lt;String&gt; readBinaryWatch(int num) &#123;</span><br><span class="line">    List&lt;String&gt; res = new ArrayList&lt;&gt;();</span><br><span class="line">    dfs(res, num, 0, 0, 0, 0);</span><br><span class="line">    <span class="built_in">return</span> new ArrayList&lt;&gt;(res);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * dfs</span><br><span class="line"> *</span><br><span class="line"> * @param res    结果集</span><br><span class="line"> * @param num    灯的个数</span><br><span class="line"> * @param indexH hours的索引</span><br><span class="line"> * @param indexM mins的索引</span><br><span class="line"> * @param hour   当前hour的值</span><br><span class="line"> * @param min    当前min的值</span><br><span class="line"> */</span><br><span class="line">private void dfs(List&lt;String&gt; res, int num, int indexH, int indexM, int hour, int min) &#123;</span><br><span class="line">    <span class="keyword">if</span> (num == 0) &#123;</span><br><span class="line">        // 递归结束条件为num == 0,注意不是indexH + indexM == num, 因为indexH表示的是hours的索引。</span><br><span class="line">        String minStr = (0 &lt;= min &amp;&amp; min &lt;= 9) ? <span class="string">&quot;0&quot;</span> + min : min + <span class="string">&quot;&quot;</span>;</span><br><span class="line">        String str = hour + <span class="string">&quot;:&quot;</span> + minStr;</span><br><span class="line">        res.add(str);</span><br><span class="line">        <span class="built_in">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    // 这种循环结构就是求hours的子集，此题就是求hours求指定长度的各个子集的和</span><br><span class="line">    <span class="keyword">for</span> (int i = indexH; i &lt; hours.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (hour + hours[i] &gt;= 12) &#123;</span><br><span class="line">            // 如果大于12，后面的循环不用看了，直接<span class="built_in">break</span></span><br><span class="line">            <span class="built_in">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        dfs(res, num - 1, i + 1, indexM, hour + hours[i], min);</span><br><span class="line">        // dfs后不用回溯是因为dfs前并没有改变hour的值</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (int i = indexM; i &lt; mins.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (min + mins[i] &gt;= 60) &#123;</span><br><span class="line">            // 如果大于60，后面的循环不用看了，直接<span class="built_in">break</span></span><br><span class="line">            <span class="built_in">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        // 注意这里递归到mins时，并不需要再次递归到hours,不然结果会重复,所以indexH填4</span><br><span class="line">        dfs(res, num - 1, 4, i + 1, hour, min + mins[i]);</span><br><span class="line">        // dfs后不用回溯是因为dfs前并没有改变min的值</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意点：</p>
<ul>
<li>题目递归结束的条件是num == 0，而不是indexH + indexM == num。</li>
<li>回溯算法一般都可以通过剪枝减少递归，具体看代码中的break片段。</li>
<li>此题有两个求子集的过程，所以有两个for循环，注意下面一个循环中的dfs，indexH的取值不能传当前值了（如果传了当前值，递归进去又会走一遍hours循环，这样结果就有重复值了），所以直接取4。</li>
<li>回溯算法一般都需要在回溯时做“还原”操作，但是这里因为dfs前并没有改正hour和min的值，所以dfs后不用“还原”。</li>
</ul>
<p>这是自己的一些想法，如果你有更好的想法欢迎留言！</p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>回溯</tag>
      </tags>
  </entry>
  <entry>
    <title>算法的奥秘-回溯（2）</title>
    <url>/2021/06/17/backtracing-2/</url>
    <content><![CDATA[<p>&ensp;&ensp;今天分享一下最近学习回溯算法的一些经验与心得！根据百度百科的解释：回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。回溯法是一种选优搜素法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个状态的点称为“回溯点”。许多复杂的，规模较大的问题都可以使用回溯法，有“通用解题方法”的美称。直接看题，毁灭吧，赶紧的！</p>
<p>&ensp;&ensp;我们知道二叉树的前序遍历dfs的代码是这样写的：</p>
<span id="more"></span>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">public void treeDFS(TreeNode root) &#123;</span><br><span class="line">    <span class="keyword">if</span> (root == null)</span><br><span class="line">        <span class="built_in">return</span>;</span><br><span class="line">    System.out.println(root.val);</span><br><span class="line">    treeDFS(root.left);</span><br><span class="line">    treeDFS(root.right);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&ensp;&ensp;这里可以通过仿照一下二叉树，写一下9叉树前序遍历的代码：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">public void treeDFS(TreeNode node) &#123;</span><br><span class="line">    // 递归终止条件</span><br><span class="line">    <span class="keyword">if</span>(node == null) &#123;</span><br><span class="line">        <span class="built_in">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(node.val);</span><br><span class="line">    <span class="keyword">for</span>(int i = 0;i &lt; 9;i++) &#123;</span><br><span class="line">        // 一些操作，可有可无，视情况而定</span><br><span class="line">        treeDfs(<span class="string">&quot;第i个节点&quot;</span>);</span><br><span class="line">        // 回退操作，可有可无，视情况而定</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>&ensp;&ensp;这就是回溯算法的基本框架，几乎所有回溯算法都离不开这个框架，接下来我们看几个实例。</p>
<p>1、全排列</p>
<p>给定一个 没有重复 数字的序列，返回其所有可能的全排列。</p>
<p>示例:</p>
<p>输入: [1,2,3]</p>
<p>输出:</p>
<p>[<br>  [1,2,3],</p>
<p>  [1,3,2],</p>
<p>  [2,1,3],</p>
<p>  [2,3,1],</p>
<p>  [3,1,2],</p>
<p>  [3,2,1]</p>
<p>]<br>这其实是一颗三叉树，根据上面的框架，写出代码：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) &#123;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();</span><br><span class="line">        Deque&lt;Integer&gt; deque = new ArrayDeque&lt;&gt;();</span><br><span class="line">        int n = nums.length;</span><br><span class="line">        boolean[] used = new boolean[n];</span><br><span class="line">        dfs(res, deque, n, 0, used, nums);</span><br><span class="line">        <span class="built_in">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * dfs</span><br><span class="line">     * @param res res </span><br><span class="line">     * @param deque deque</span><br><span class="line">     * @param n  n</span><br><span class="line">     * @param first 层数</span><br><span class="line">     * @param used 是否有使用到数组标记</span><br><span class="line">     * @param nums nums</span><br><span class="line">     */</span><br><span class="line">    private void dfs(List&lt;List&lt;Integer&gt;&gt; res, Deque&lt;Integer&gt; deque, int n, int first, boolean[] used, int[] nums) &#123;</span><br><span class="line">        <span class="keyword">if</span> (first == n) &#123;</span><br><span class="line">            res.add(new ArrayList&lt;&gt;(deque));</span><br><span class="line">            <span class="built_in">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        // 注意i= 0</span><br><span class="line">        <span class="keyword">for</span> (int i = 0; i &lt; n; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!used[i]) &#123;</span><br><span class="line">                deque.addLast(nums[i]);</span><br><span class="line">                used[i] = <span class="literal">true</span>;</span><br><span class="line">                // 这里是first +1 ,first代表层数</span><br><span class="line">                dfs(res, deque, n, first + 1, used, nums);</span><br><span class="line">                deque.removeLast();</span><br><span class="line">                used[i] = <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>注意点：</p>
<ul>
<li>for 循环 i 值是从0开始的，这样才能出现【3,2，1】这样的集合。</li>
<li>dfs 递归传的是first + 1，而不是i+1,因为first这里表示的是遍历层数，而i表示的是遍历数组的索引。也可以去掉first参数。直接将deque.size() == n 作为递归终止条件。</li>
</ul>
<p>2、全排列 || </p>
<p>给定一个可包含重复数字的序列 nums ，按任意顺序 返回所有不重复的全排列。</p>
<p>示例 1：</p>
<p>输入：nums = [1,1,2]</p>
<p>输出：</p>
<p>[[1,1,2],</p>
<p> [1,2,1],</p>
<p> [2,1,1]]</p>
<p>示例 2：</p>
<p>输入：nums = [1,2,3]</p>
<p>输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]]</p>
<p>直接看代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">public List&lt;List&lt;Integer&gt;&gt; permuteUnique(int[] nums) &#123;</span><br><span class="line">    List&lt;List&lt;Integer&gt;&gt; list = new ArrayList&lt;&gt;();</span><br><span class="line">    Deque&lt;Integer&gt; deque = new ArrayDeque&lt;&gt;();</span><br><span class="line">    boolean[] used = new boolean[nums.length];</span><br><span class="line">    // 有重复的队列，先排序</span><br><span class="line">    Arrays.sort(nums);</span><br><span class="line">    dfs(list, deque, nums, 0, used);</span><br><span class="line">    <span class="built_in">return</span> list;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void dfs(List&lt;List&lt;Integer&gt;&gt; list, Deque&lt;Integer&gt; deque, int[] nums, int first, boolean[] used) &#123;</span><br><span class="line">    <span class="keyword">if</span> (first == nums.length) &#123;</span><br><span class="line">        list.add(new ArrayList&lt;&gt;(deque));</span><br><span class="line">        <span class="built_in">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (int i = 0; i &lt; nums.length; i++) &#123;</span><br><span class="line">        // 去重</span><br><span class="line">        <span class="keyword">if</span> (used[i] || (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !used[i - 1])) &#123;</span><br><span class="line">            <span class="built_in">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        deque.addLast(nums[i]);</span><br><span class="line">        used[i] = <span class="literal">true</span>;</span><br><span class="line">        dfs(list, deque, nums, first + 1, used);</span><br><span class="line">        used[i] = <span class="literal">false</span>;</span><br><span class="line">        deque.removeLast();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意点：</p>
<ul>
<li>这里需要去重，最简单的做法就是先将nums排序，这样相同的元素就在一起了，然后在第一题的基础上加上这句就行了</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (used[i] || (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !used[i - 1])) &#123;</span><br><span class="line">    <span class="built_in">continue</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>3、子集</p>
<p>给你一个整数数组 nums ，数组中的元素 互不相同 。返回该数组所有可能的子集（幂集）。<br>解集 不能 包含重复的子集。你可以按 任意顺序 返回解集。</p>
<p>示例 1：</p>
<p>输入：nums = [1,2,3]</p>
<p>输出：[[],[1],[2],[1,2],[3],[1,3],[2,3],[1,2,3]]</p>
<p>示例 2：</p>
<p>输入：nums = [0]</p>
<p>输出：[[],[0]]</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) &#123;</span><br><span class="line">    List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();</span><br><span class="line">    Deque&lt;Integer&gt; deque = new ArrayDeque&lt;&gt;();</span><br><span class="line">    dfs(res, deque, nums, 0);</span><br><span class="line">    <span class="built_in">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void dfs(List&lt;List&lt;Integer&gt;&gt; res, Deque&lt;Integer&gt; deque, int[] nums, int index) &#123;</span><br><span class="line">    res.add(new ArrayList&lt;&gt;(deque));</span><br><span class="line">    <span class="keyword">for</span> (int i = index; i &lt; nums.length; i++) &#123;</span><br><span class="line">        deque.addLast(nums[i]);</span><br><span class="line">        dfs(res, deque, nums, i + 1);</span><br><span class="line">        deque.removeLast();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意点:</p>
<ul>
<li>for 循环 i的初始值应该是index,如果i = 0的话，nums[i]就重复了</li>
<li>dfs递归时传的index= i+ 1，而不是index+ 1，如果传的是index + 1,那么for循环那么多次递归进去的值都是一样的。</li>
</ul>
<p>4、子集||</p>
<p>给定一个可能包含重复元素的整数数组 nums，返回该数组所有可能的子集（幂集）。</p>
<p>说明：解集不能包含重复的子集。</p>
<p>示例:</p>
<p>输入: [1,2,2]</p>
<p>输出:</p>
<p>[</p>
<p>  [2],</p>
<p>  [1],</p>
<p>  [1,2,2],</p>
<p>  [2,2],</p>
<p>  [1,2],</p>
<p>  []</p>
<p>]</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">public List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(int[] nums) &#123;</span><br><span class="line">    Arrays.sort(nums);</span><br><span class="line">    List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();</span><br><span class="line">    Deque&lt;Integer&gt; deque = new ArrayDeque&lt;&gt;();</span><br><span class="line">    dfs(res, deque, nums, 0);</span><br><span class="line">    <span class="built_in">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void dfs(List&lt;List&lt;Integer&gt;&gt; res, Deque&lt;Integer&gt; deque, int[] nums, int index) &#123;</span><br><span class="line">    res.add(new ArrayList&lt;Integer&gt;(deque));</span><br><span class="line">    <span class="keyword">for</span> (int i = index; i &lt; nums.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (i &gt; index &amp;&amp; nums[i] == nums[i - 1]) &#123;</span><br><span class="line">            <span class="built_in">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        deque.addLast(nums[i]);</span><br><span class="line">        dfs(res, deque, nums, i + 1);</span><br><span class="line">        deque.removeLast();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意点：</p>
<ul>
<li>这里跟第二题求全排列一样的思路，要去重就先排序，将重复的元素放在一起，然后通过这行代码过滤掉：<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (i &gt; index &amp;&amp; nums[i] == nums[i - 1]) &#123;</span><br><span class="line">                <span class="built_in">continue</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p>5、组合求和</p>
<p>给定一个无重复元素的数组 candidates 和一个目标数 target ，找出 candidates 中所有可以使数字和为 target 的组合。</p>
<p>candidates 中的数字可以无限制重复被选取。</p>
<p>说明：</p>
<p>所有数字（包括 target）都是正整数。</p>
<p>解集不能包含重复的组合。 </p>
<p>示例 1：</p>
<p>输入：candidates = [2,3,6,7], target = 7,</p>
<p>所求解集为：</p>
<p>[</p>
<p>  [7],</p>
<p>  [2,2,3]</p>
<p>]</p>
<p>示例 2：</p>
<p>输入：candidates = [2,3,5], target = 8,</p>
<p>所求解集为：</p>
<p>[</p>
<p>  [2,2,2,2],</p>
<p>  [2,3,3],</p>
<p>  [3,5]</p>
<p>]</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) &#123;</span><br><span class="line">    List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();</span><br><span class="line">    dfs(res, new ArrayList&lt;&gt;(), 0, candidates, target);</span><br><span class="line">    <span class="built_in">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void dfs(List&lt;List&lt;Integer&gt;&gt; res, List&lt;Integer&gt; list, int index, int[] arr, int left) &#123;</span><br><span class="line">    <span class="keyword">if</span> (left == 0) &#123;</span><br><span class="line">        res.add(new ArrayList&lt;&gt;(list));</span><br><span class="line">        <span class="built_in">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (int i = index; i &lt; arr.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (arr[i] &lt;= left) &#123;</span><br><span class="line">            list.add(arr[i]);</span><br><span class="line">            // 注意这里递归的index取 i,而不是index，取index的话会遍历回去</span><br><span class="line">            dfs(res, list, i, arr, left - arr[i]);</span><br><span class="line">            list.remove(list.size() - 1);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意点：</p>
<ul>
<li><p>这里的递归终止条件是left == 0</p>
</li>
<li><p>dfs递归时的index应该取值i,这样才会遍历到同一个元素。</p>
</li>
</ul>
<p>6、组合</p>
<p>给定两个整数 n 和 k，返回 1 … n 中所有可能的 k 个数的组合。</p>
<p>示例:</p>
<p>输入: n = 4, k = 2</p>
<p>输出:</p>
<p>[</p>
<p>  [2,4],</p>
<p>  [3,4],</p>
<p>  [2,3],</p>
<p>  [1,2],</p>
<p>  [1,3],</p>
<p>  [1,4],</p>
<p>]</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> public List&lt;List&lt;Integer&gt;&gt; combine(int n, int k) &#123;</span><br><span class="line">    List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();</span><br><span class="line">    Deque&lt;Integer&gt; deque = new ArrayDeque&lt;&gt;();</span><br><span class="line">    dfs(res, deque, n, k, 0);</span><br><span class="line">    <span class="built_in">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void dfs(List&lt;List&lt;Integer&gt;&gt; res, Deque&lt;Integer&gt; deque, int n, int k, int index) &#123;</span><br><span class="line">    <span class="keyword">if</span> (deque.size() == k) &#123;</span><br><span class="line">        res.add(new ArrayList&lt;&gt;(deque));</span><br><span class="line">        <span class="built_in">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (int i = index; i &lt; n; i++) &#123;</span><br><span class="line">        deque.addLast(i + 1);</span><br><span class="line">        dfs(res, deque, n, k, i + 1);</span><br><span class="line">        deque.removeLast();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意点：</p>
<ul>
<li>这里需要注意递归终止条件是deque.size() == k</li>
</ul>
<p>通过上面的分析，我们发现其实递归算法都离不开那个框架，只不过需要根据具体的题目改变一些递归终止条件，递归前要做的事，递归的传值。接下来看一题综合的，起码用到了上面的三道题的套路。</p>
<p>7、活字印刷</p>
<p>你有一套活字字模 tiles，其中每个字模上都刻有一个字母 tiles[i]。返回你可以印出的非空字母序列的数目。</p>
<p>注意：本题中，每个活字字模只能使用一次。</p>
<p>示例 1：</p>
<p>输入：”AAB”</p>
<p>输出：8</p>
<p>解释：可能的序列为 “A”, “B”, “AA”, “AB”, “BA”, “AAB”, “ABA”, “BAA”。</p>
<p>示例 2：</p>
<p>输入：”AAABBC”</p>
<p>输出：188</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">private int count = 0;</span><br><span class="line"></span><br><span class="line">public int numTilePossibilities(String tiles) &#123;</span><br><span class="line">    char[] arr = tiles.toCharArray();</span><br><span class="line">    Arrays.sort(arr);</span><br><span class="line">    boolean[] used = new boolean[arr.length];</span><br><span class="line">    dfs(arr, used, 0);</span><br><span class="line">    <span class="built_in">return</span> count;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private void dfs(char[] arr, boolean[] used, int index) &#123;</span><br><span class="line">    <span class="keyword">if</span> (index != 0) &#123;</span><br><span class="line">        count++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (int i = 0; i &lt; arr.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (used[i] || (i &gt; 0 &amp;&amp; arr[i] == arr[i - 1] &amp;&amp; !used[i - 1])) &#123;</span><br><span class="line">            <span class="built_in">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        used[i] = <span class="literal">true</span>;</span><br><span class="line">        dfs(arr, used, index + 1);</span><br><span class="line">        used[i] = <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意点：</p>
<ul>
<li><p>这题其实就是求不重复的，能反过来的（相当于全排列）子集，所以我们用到了三个套路：</p>
</li>
<li><p>全排列：used标记数组，并且i 从0开始遍历。</p>
</li>
<li><p>不重复：先排序，再相邻元素相同并且上一个元素已经遍历过的剪枝判断</p>
</li>
<li><p>子集：只要index &gt; 0 ,每dfs一次，子集的个数就加1，另外子集其实不需要显示写终止条件的。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>回溯</tag>
      </tags>
  </entry>
  <entry>
    <title>算法的奥秘-回溯（3）</title>
    <url>/2021/06/17/backtracing-3/</url>
    <content><![CDATA[<p>&ensp;&ensp;今天打算分享下回溯算法中的另一种题型–是否存在***，这种题型一般都不用走完整个dfs过程，如果存在就可以直接返回了，这样相当于剪枝了，可以很大程度提升算法执行时间。那还等什么，毁灭吧，赶紧的！</p>
<p>1、单词搜素</p>
<p>给定一个二维网格和一个单词，找出该单词是否存在于网格中。</p>
<p>单词必须按照字母顺序，通过相邻的单元格内的字母构成，其中“相邻”单元格是那些水平相邻或垂直相邻的单元格。同一个单元格内的字母不允许被重复使用。</p>
<span id="more"></span>

<p>示例:</p>
<p>board =</p>
<p>[</p>
<p>  [‘A’,’B’,’C’,’E’],</p>
<p>  [‘S’,’F’,’C’,’S’],</p>
<p>  [‘A’,’D’,’E’,’E’]</p>
<p>]</p>
<p>给定 word = “ABCCED”, 返回 true</p>
<p>给定 word = “SEE”, 返回 true</p>
<p>给定 word = “ABCB”, 返回 false</p>
<p>提示：</p>
<ul>
<li><p>board 和 word 中只包含大写和小写英文字母。</p>
</li>
<li><p>1 &lt;= board.length &lt;= 200</p>
</li>
<li><p>1 &lt;= board[i].length &lt;= 200</p>
</li>
<li><p>1 &lt;= word.length &lt;= 10^3</p>
</li>
</ul>
<p>代码：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">public boolean exist(char[][] board, String word) &#123;</span><br><span class="line">    <span class="keyword">for</span> (int i = 0; i &lt; board.length; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (int j = 0; j &lt; board[i].length; j++) &#123;</span><br><span class="line">            boolean[][] used = new boolean[board.length][board[i].length];</span><br><span class="line">            <span class="keyword">if</span> (dfs(i, j, board, word, 0, used)) &#123;</span><br><span class="line">                <span class="built_in">return</span> <span class="literal">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private boolean dfs(int row, int col, char[][] board, String word, int index, boolean[][] used) &#123;</span><br><span class="line">    <span class="keyword">if</span> (index == word.length()) &#123;</span><br><span class="line">        <span class="built_in">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (row &lt; 0 || row &gt;= board.length || col &lt; 0 || col &gt;= board[row].length || board[row][col] != word.charAt(index) || used[row][col]) &#123;</span><br><span class="line">        <span class="built_in">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    used[row][col] = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    boolean res = dfs(row + 1, col, board, word, index + 1, used) ||</span><br><span class="line">            dfs(row, col + 1, board, word, index + 1, used) ||</span><br><span class="line">            dfs(row - 1, col, board, word, index + 1, used) ||</span><br><span class="line">            dfs(row, col - 1, board, word, index + 1, used);</span><br><span class="line">    used[row][col] = <span class="literal">false</span>;</span><br><span class="line">    <span class="built_in">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意点：</p>
<ol>
<li><p>可以看到连续四个dfs那里，用的是短路或，这样保证了只要存在true的结果，其他的dfs也就不用递归进去了，也就达到了剪枝的效果。</p>
</li>
<li><p>注意这里dfs进去前没有判断边界条件，而是放在了进去后再进行判断，有时候知道怎么做就是写不出来，这点也要注意。</p>
</li>
</ol>
<br>
2、累加数

<p>累加数是一个字符串，组成它的数字可以形成累加序列。</p>
<p>一个有效的累加序列必须至少包含 3 个数。除了最开始的两个数以外，字符串中的其他数都等于它之前两个数相加的和。</p>
<p>给定一个只包含数字 ‘0’-‘9’ 的字符串，编写一个算法来判断给定输入是否是累加数。</p>
<p>说明: 累加序列里的数不会以 0 开头，所以不会出现 1, 2, 03 或者 1, 02, 3 的情况。</p>
<p>示例 1:</p>
<p>输入: “112358”</p>
<p>输出: true </p>
<p>解释: 累加序列为: 1, 1, 2, 3, 5, 8 。1 + 1 = 2, 1 + 2 = 3, 2 + 3 = 5, 3 + 5 = 8</p>
<p>示例 2:</p>
<p>输入: “199100199”</p>
<p>输出: true </p>
<p>解释: 累加序列为: 1, 99, 100, 199。1 + 99 = 100, 99 + 100 = 199</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">private String s;</span><br><span class="line"></span><br><span class="line">private int n;</span><br><span class="line"></span><br><span class="line">public boolean isAdditiveNumber(String num) &#123;</span><br><span class="line">    s = num;</span><br><span class="line">    n = s.length();</span><br><span class="line">    <span class="built_in">return</span> dfs(0, 0, 0, 0);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> *</span><br><span class="line"> * @param index 下标</span><br><span class="line"> * @param sum 前两个数之和</span><br><span class="line"> * @param previous 前一个数</span><br><span class="line"> * @param count 已经添加的个数</span><br><span class="line"> * @<span class="built_in">return</span></span><br><span class="line"> */</span><br><span class="line">private boolean dfs(int index, long sum, long previous, int count) &#123;</span><br><span class="line">    <span class="keyword">if</span> (index == n) &#123;</span><br><span class="line">        <span class="keyword">if</span> (count &gt;= 3) &#123;</span><br><span class="line">            <span class="built_in">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    // value值用于累加值</span><br><span class="line">    long value = 0;</span><br><span class="line">    <span class="keyword">for</span> (int i = index; i &lt; n; i++) &#123;</span><br><span class="line">        // 第一个数是0，而且当前value大于一位，直接<span class="built_in">break</span></span><br><span class="line">        <span class="keyword">if</span> (i &gt; index &amp;&amp; s.charAt(index) == <span class="string">&#x27;0&#x27;</span>) &#123;</span><br><span class="line">            <span class="built_in">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        value = value * 10 + s.charAt(i) - <span class="string">&#x27;0&#x27;</span>;</span><br><span class="line">        <span class="keyword">if</span> (count &gt;= 2) &#123;</span><br><span class="line">            <span class="keyword">if</span> (value &lt; sum) &#123;</span><br><span class="line">                // 继续累加value</span><br><span class="line">                <span class="built_in">continue</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (value &gt; sum) &#123;</span><br><span class="line">                // 累加value无意义，直接<span class="built_in">break</span></span><br><span class="line">                <span class="built_in">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        // 忽略<span class="literal">false</span>结果，妙！</span><br><span class="line">        <span class="keyword">if</span> (dfs(i + 1, previous + value, value, count + 1)) &#123;</span><br><span class="line">            <span class="built_in">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意点：</p>
<ul>
<li>这里dfs进去直接忽略了false结果，试想这里如果不忽略false，也返回一个false结果，那么只要一次尝试不成功就不会继续尝试了,这样就没有达到穷举的效果，而一点返回true，说明我们这种字符串分割方法就是我们要的结果，因此可以直接返回true，一层接着一层，最终最外层返回true，给到调用方，结束递归。</li>
</ul>
]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>回溯</tag>
      </tags>
  </entry>
  <entry>
    <title>小公司的大梦想 - 秒杀</title>
    <url>/2021/06/17/spide/</url>
    <content><![CDATA[<p>&ensp;&ensp;最近工作上有一个限量点餐的需求，本来公司人不多，但是谁知餐厅供应的特色腊肠牛肉饭特少，而员工对这特色饭情有独钟，导致餐厅一开始营业员工就开始疯抢，这也就形成了电商行业中著名的秒杀情景。</p>
<p>&ensp;&ensp;而此时我以前的代码实现的下单方案是：先从数据库中查询出该时段该菜式的销售量，再与该菜式总的库存进行比较，如果大于库存，直接返回“菜式已售罄”；如果小于库存，则进行后面的下单流程。有一点经验或认知的朋友，一眼就能看出这里存在并发问题。可能是因为一直被动接受业务的原因，直到和同时聊起项目被同事怀疑代码有并发bug时，才仔细一想确实有bug。这里需要指出的是项目使用的语言是Node.js，尽管Node是单线程的，但是单线程只是针对一个请求来说，对于多个请求，还是存在并发问题的。这其中的道理可以类比Java的指令重排：对于单线程，再怎么指令重排也不会影响到线程的执行结果；但是对于别的线程看到的结果就有可能不同了。这也是Java线程安全问题的本质原因。</p>
<span id="more"></span>

<p>&ensp;&ensp;经过一番查阅资料和请教大佬，最终决定使用redis的列表来做队列，基于排队的理念来实现“秒杀”。具体的将每个菜式的库存保存在Redis中，然后对于每个时段每个菜式的请求用一个list保存（餐厅的菜式供应是分时段的，每个时段开始时菜式库存都会初始化为原来值）。当请求来了先把请求放到队列的右边，然后从左边取出前‘’库存量‘’个请求，判断当前请求是否在这前“库存量”个请求中。如果在，进行下单操作；如果不在，返回‘’库存不足‘’。对应业务具体思路如下：</p>
<p>&ensp;&ensp;这里对于为了标识每个请求不同，将请求人的 id+uuid.v4() 作为值rpush进对应的菜式列表，如果请求n份菜式，就rpush n次值。因为业务同时需要取消订单、修改订单，取消订单时需要找到添加订单时push进去的值并删除，因此需要将添加订单时push进去的值存起来，这里使用订单orderId做key，添加订单时push进去的值做value存入Redis中；修改订单麻烦一点，因为加菜会rpush进新的请求并判断请求是不是在前“库存量”内，所以在生成订单时如果不满足库存要求，就要将该请求删除掉。另外假设下订单时选了一份菜，修改订单时如果将该菜式数量加1，如果此时生成不同的 id + uuid.v4()值存进去的话，等以后将这两份分别删除的话，就得分别拿到这两份菜式对应的id + uuid.v4()值,如果n次修改订单并添加该菜式的数量，就会生成n个id + uuid.v4()值，这样操作起来就比较麻烦了，所以修改订单时如果对同一个菜式进行修改，使用的id + uuid.v4()值就是这个订单生成时对应的id + uuid.v4() 值，这样带来的另一个问题是修改订单时判断list前‘库存量’个请求的数量要跟修改订单后的数量一致才表示能够进行修改操作，否则返回“库存不足”。</p>
<p>&ensp;&ensp;核心代码实现如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/** </span><br><span class="line">  * &#123;Array&#125; dishes </span><br><span class="line">  * &#123;Number&#125; dishes[*].dishesId  - 菜式id</span><br><span class="line">  * &#123;Number&#125; dishes[*].number    - 菜式数量</span><br><span class="line">  * &#123;String&#125; keyPrefix           - 请求list的key前缀</span><br><span class="line">  * &#123;String&#125; keySuffix           - 请求list的key后缀，由餐厅id + 营业开始时间时间戳组成</span><br><span class="line">  * &#123;String&#125; userValue           - 请求list的请求值，由用户Id + uuid.v4()组成</span><br><span class="line">  * &#123;Object&#125; dishNumberMap &#123;dishId:number&#125;,number表示修改订单成功后该菜式的数量 </span><br><span class="line">  */ </span><br><span class="line"> async <span class="keyword">function</span> checkStock(dishes,keyPrefix,keySuffix,userValue,dishNumberMap)&#123; </span><br><span class="line">     <span class="built_in">let</span> stckMap = &#123;&#125;; // 保存菜式的库存</span><br><span class="line">     <span class="keyword">for</span> (<span class="built_in">let</span> dish of dishes) &#123; </span><br><span class="line">         <span class="built_in">let</span> stock = awaic cache.get(<span class="string">&#x27;stock:&#x27;</span> + dish.dishesId); // 获取菜式库存</span><br><span class="line">         <span class="keyword">if</span> (!stock &amp;&amp; stock != -1)&#123; // -1表示无限库存</span><br><span class="line">             stockMap[dish.dishesId] = stock; </span><br><span class="line">             <span class="keyword">for</span>(<span class="built_in">let</span> i = 0;i&lt;dish.number;i++)&#123; </span><br><span class="line">                 // rpush keyPrefix + dishesId + keySuffix : list </span><br><span class="line">                 await cache.rpush(keyPrefix + dish.dishesId + keySuffix,userValue); </span><br><span class="line">             &#125; </span><br><span class="line">         &#125; </span><br><span class="line">     &#125; </span><br><span class="line">     <span class="keyword">for</span> (<span class="built_in">let</span> dish of dishes) &#123; </span><br><span class="line">         <span class="built_in">let</span> number = (dishNumberMap &amp;&amp; dishNumberMap[dish.dishesId]) || dish.number; </span><br><span class="line">         <span class="built_in">let</span> stock = stockMap[dish.dishesId]; </span><br><span class="line">         <span class="keyword">if</span> (!stock &amp;&amp; stock != -1) &#123; // -1表示无限库存  </span><br><span class="line">             // 取前stock个请求 </span><br><span class="line">             <span class="built_in">let</span> userValueList = await cache.lrange(keyPrefix + dish.dishesId + keySuffix,0,stock -1); </span><br><span class="line">             <span class="keyword">if</span> ((_.countBy(userValueList)[userValue] || 0) &lt; number)&#123; // 判断数量是否相等 </span><br><span class="line">                 // 队列前stock个请求包含的userVaule个数小于请求的number值，则移除当前请求，为了修改订单时可以push进新的userValue </span><br><span class="line">                 <span class="keyword">for</span> (<span class="built_in">let</span> d of dishes)&#123; </span><br><span class="line">                     await cache.lrem(keyPrefix + d.dishesId + keySuffix, -d.number,userValue); </span><br><span class="line">                 &#125; </span><br><span class="line">                 <span class="built_in">return</span> Promise.reject(<span class="string">&#x27;库存不足&#x27;</span>); </span><br><span class="line">             &#125; </span><br><span class="line">         &#125; </span><br><span class="line">     &#125; </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>&ensp;&ensp;总结一下，主要利用了队列来实现对有限资源的请求与分发，以及redis 单线程的特点实现线程安全。当然还有更好的方案，这个方案很简单，但是扩展性很差，而且也不能确定就一定没有问题。如果你有更好的解决方案或者对此有什么问题和见解欢迎留言~</p>
]]></content>
      <categories>
        <category>技术应用</category>
      </categories>
      <tags>
        <tag>秒杀</tag>
      </tags>
  </entry>
  <entry>
    <title>算法的奥秘-栈（基础篇）</title>
    <url>/2021/06/17/stack-1/</url>
    <content><![CDATA[<p>&ensp;&ensp;今天分享下栈的基础算法，栈一句话描述就是一个后进先出的容器，跟栈相对立的一个结构是队列，队列的特征是元素先进先出。他们之间可以互相转换。那还等什么，毁灭吧，赶紧的！</p>
<br>
1、用队列实现栈

<p>请你仅使用两个队列实现一个后入先出（LIFO）的栈，并支持普通队列的全部四种操作（push、top、pop 和 empty）。</p>
<span id="more"></span>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">class MyStack &#123;</span><br><span class="line"></span><br><span class="line">    Queue&lt;Integer&gt; queue1 = new LinkedList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    Queue&lt;Integer&gt; queue2 = new LinkedList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    /** Initialize your data structure here. */</span><br><span class="line">    public MyStack() &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    /** Push element x onto stack. */</span><br><span class="line">    public void push(int x) &#123;</span><br><span class="line">        queue2.add(x);</span><br><span class="line">        while(!queue1.isEmpty()) &#123;</span><br><span class="line">            queue2.add(queue1.poll());</span><br><span class="line">        &#125;</span><br><span class="line">        Queue&lt;Integer&gt; temp = queue1;</span><br><span class="line">        queue1 = queue2;</span><br><span class="line">        queue2 = temp;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    /** Removes the element on top of the stack and returns that element. */</span><br><span class="line">    public int pop() &#123;</span><br><span class="line">        return queue1.poll();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    /** Get the top element. */</span><br><span class="line">    public int top() &#123;</span><br><span class="line">        return queue1.peek();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    /** Returns whether the stack is empty. */</span><br><span class="line">    public boolean empty() &#123;</span><br><span class="line">        return queue1.isEmpty();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>入栈操作时，首先将元素入队到queue2,然后将queue1的全部元素依次出队并入队到queue2，此时queue2的前端元素即为新入栈的元素，再将queue1与queue2互换，即queue1的元素即为栈内的元素，queue1的前端和后端分别对应栈顶和栈底。</p>
</li>
<li><p>由于每次入栈操作都确保queue1的前端元素为栈顶元素，因此出栈操作和获取栈顶操作都可以简单的实现。</p>
</li>
</ul>
<br>
  2、用栈实现队列

<p>请你仅使用两个栈实现先入先出队列。队列应当支持一般队列支持的所有操作（push、pop、peek、empty）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">class MyQueue &#123;</span><br><span class="line">    Stack&lt;Integer&gt; stack1 = new Stack&lt;&gt;();</span><br><span class="line">    Stack&lt;Integer&gt; stack2 = new Stack&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    /** Initialize your data structure here. */</span><br><span class="line">    public <span class="function"><span class="title">MyQueue</span></span>() &#123;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    /** Push element x to the back of queue. */</span><br><span class="line">    public void push(int x) &#123;</span><br><span class="line">        <span class="keyword">while</span>(!stack1.isEmpty()) &#123;</span><br><span class="line">            stack2.push(stack1.pop());</span><br><span class="line">        &#125;</span><br><span class="line">        stack1.push(x);</span><br><span class="line">        <span class="keyword">while</span>(!stack2.isEmpty()) &#123;</span><br><span class="line">            stack1.push(stack2.pop());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    /** Removes the element from <span class="keyword">in</span> front of queue and returns that element. */</span><br><span class="line">    public int <span class="function"><span class="title">pop</span></span>() &#123;</span><br><span class="line">        <span class="built_in">return</span> stack1.pop();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    /** Get the front element. */</span><br><span class="line">    public int <span class="function"><span class="title">peek</span></span>() &#123;</span><br><span class="line">        <span class="built_in">return</span> stack1.peek();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    /** Returns whether the queue is empty. */</span><br><span class="line">    public boolean <span class="function"><span class="title">empty</span></span>() &#123;</span><br><span class="line">        <span class="built_in">return</span> stack1.isEmpty();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>元素x入栈时，首先将stack1中的元素依次出栈并入栈到stack2,然后将x入栈到stack1,再将stack2中的元素依次出栈并入栈到stack1,这样x就位于stack1的栈底，而原来stack1中的元素位置没有变化，即实现了队列的效果。</li>
</ul>
<br>

<p>  3、最小栈</p>
<p>设计一个支持 push ，pop ，top 操作，并能在常数时间内检索到最小元素的栈。</p>
<ul>
<li>push(x) —— 将元素 x 推入栈中。</li>
<li>pop() —— 删除栈顶的元素。</li>
<li>top() —— 获取栈顶元素。</li>
<li>getMin() —— 检索栈中的最小元素。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">class MinStack &#123;</span><br><span class="line"></span><br><span class="line">    Stack&lt;Integer&gt; stack = new Stack&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    Stack&lt;Integer&gt; minStack = new Stack&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * initialize your data structure here.</span><br><span class="line">     */</span><br><span class="line">    public MinStack() &#123;</span><br><span class="line">        minStack.push(Integer.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void push(int val) &#123;</span><br><span class="line">        stack.push(val);</span><br><span class="line">        minStack.push(Math.min(minStack.peek(), val));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void pop() &#123;</span><br><span class="line">        int pop = stack.pop();</span><br><span class="line">        minStack.pop();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int top() &#123;</span><br><span class="line">        return stack.peek();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public int getMin() &#123;</span><br><span class="line">        return minStack.peek();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>对于栈来说，如果一个元素 a 在入栈时，栈里有其它的元素 b, c, d，那么无论这个栈在之后经历了什么操作，只要 a 在栈中，b, c, d 就一定在栈中，因为在 a 被弹出之前，b, c, d 不会被弹出。</p>
</li>
<li><p>因此，在操作过程中的任意一个时刻，只要栈顶的元素是 a，那么我们就可以确定栈里面现在的元素一定是 a, b, c, d。</p>
</li>
<li><p>那么，我们可以在每个元素 a 入栈时把当前栈的最小值 m 存储起来。在这之后无论何时，如果栈顶元素是 a，我们就可以直接返回存储的最小值 m。</p>
</li>
</ul>
<br>
4、最大栈

<p>   和最小栈同样的思路，读者可以自己尝试着写写。</p>
 <Br> 
5、队列的最大值

<p>请定义一个队列并实现函数 max_value 得到队列里的最大值，要求函数max_value、push_back 和 pop_front 的均摊时间复杂度都是O(1)。</p>
<p>若队列为空，pop_front 和 max_value 需要返回 -1</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">class MaxQueue &#123;</span><br><span class="line">    Queue&lt;Integer&gt; q;</span><br><span class="line">    Deque&lt;Integer&gt; d;</span><br><span class="line"></span><br><span class="line">    public MaxQueue() &#123;</span><br><span class="line">        q = new LinkedList&lt;Integer&gt;();</span><br><span class="line">        d = new LinkedList&lt;Integer&gt;();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public int max_value() &#123;</span><br><span class="line">        if (d.isEmpty()) &#123;</span><br><span class="line">            return -1;</span><br><span class="line">        &#125;</span><br><span class="line">        return d.peekFirst();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public void push_back(int value) &#123;</span><br><span class="line">        while (!d.isEmpty() &amp;&amp; d.peekLast() &lt; value) &#123;</span><br><span class="line">            d.pollLast();</span><br><span class="line">        &#125;</span><br><span class="line">        d.offerLast(value);</span><br><span class="line">        q.offer(value);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    public int pop_front() &#123;</span><br><span class="line">        if (q.isEmpty()) &#123;</span><br><span class="line">            return -1;</span><br><span class="line">        &#125;</span><br><span class="line">        int ans = q.poll();</span><br><span class="line">        if (ans == d.peekFirst()) &#123;</span><br><span class="line">            d.pollFirst();</span><br><span class="line">        &#125;</span><br><span class="line">        return ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>&ensp;&ensp;这题其实是队列的特性，题目的标签是栈，但是目前没想到利用栈的解法，这里分享一种通过双端队列实现的方法。</p>
<p>&ensp;&ensp;本算法基于问题的一个重要性质：当一个元素进入队列的时候，它前面所有比它小的元素就不会再对答案产生影响。</p>
<p>&ensp;&ensp;举个例子，如果我们向队列中插入数字序列 1 1 1 1 2，那么在第一个数字 2 被插入后，数字 2 前面的所有数字 1 将不会对结果产生影响。因为按照队列的取出顺序，数字 2 只能在所有的数字 1 被取出之后才能被取出，因此如果数字 1 如果在队列中，那么数字 2 必然也在队列中，使得数字 1 对结果没有影响。</p>
<p>&ensp;&ensp;按照上面的思路，我们可以设计这样的方法：从队列尾部插入元素时，我们可以提前取出队列中所有比这个元素小的元素，使得队列中只保留对结果有影响的数字。这样的方法等价于要求维持队列单调递减，即要保证每个元素的前面都没有比它小的元素。</p>
<p>&ensp;&ensp;那么如何高效实现一个始终递减的队列呢？我们只需要在插入每一个元素 value 时，从队列尾部依次取出比当前元素 value 小的元素，直到遇到一个比当前元素大的元素 value’ 即可。</p>
</Br>]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title>XXL-JOB任务一直卡在进行中状态排查</title>
    <url>/2021/06/17/xxl-job-running-check/</url>
    <content><![CDATA[<p>&ensp;&ensp;最近发现 xxl-job（xxl-job是一个轻量级分布式任务调度平台） 的任务一直卡在进行中状态，期间 dump 过执行器的进程，发现线程已经没了，而且没有任何异常日志，网上查看原因，这是作者给的答案：</p>
<p><img src="/images/xxl-job-running-check/1.png" alt="avatar"></p>
<p>&ensp;&ensp;于是查询任务调度日志，发现确实没有回调。但是仍旧不明白线程为啥突然没了，而且还不报错。..后来就看 xxl-job 源码，看看 xxl-job 的调度原理，但因为有工作原因也还没查到，先放一边了。</p>
<span id="more"></span>

<p>&ensp;&ensp;直到今天补偿优惠券发放，发现没发完，一看任务还在执行中，dump 下进程却发现线程已经没了，才知道又碰到了这问题，还是没有任何异常日志。</p>
<p><img src="/images/xxl-job-running-check/2.png" alt="avatar"></p>
<p>&ensp;&ensp;看上图处于运行中的任务（因为截图慢了，当时第一个 taskId = 88 的任务调度时间是 2020-11-15 04:05:20），调度机器和第三个任务是同一个（因为该任务阻塞处理策略设置的是丢弃后续调度，所以碰到这种情况肯定不正常（第三个任务不应该处于进行中状态，第一个任务确实是处于运行中，只是任务运行时间很长））。</p>
<p>&ensp;&ensp;仔细看这张图，发现第二个任务 taskId = 86 这个也不应该一直处于进行中状态，这个任务执行时间很短的，而且它调度的时间和第一个调度任务调度时间非常接近，难道这期间发生了什么？</p>
<p>&ensp;&ensp;开始排查这个运行的比较快的任务。</p>
<p><img src="/images/xxl-job-running-check/3.png" alt="avatar"></p>
<p>&ensp;&ensp;如上图，查询这个任务的关键字日志，发现了一条 main 线程打的日志很特别：xxl-job register jobhandler success ,好像见过，搜一下看看</p>
<p><img src="/images/xxl-job-running-check/4.png" alt="avatar"></p>
<p>&ensp;&ensp;有很多条，想起这是注册任务的日志。。查看源码</p>
<p><img src="/images/xxl-job-running-check/5.png" alt="avatar"></p>
<p>&ensp;&ensp;发现是在启动时注册的，难道程序重启了？</p>
<p>&ensp;&ensp;再次搜索重启关键字</p>
<p><img src="/images/xxl-job-running-check/6.png" alt="avatar"></p>
<p>&ensp;&ensp;还真的重启了..,难怪任务线程突然没了，早应该想到的。</p>
<p><img src="/images/xxl-job-running-check/12.webp" alt="avatar"></p>
<p>&ensp;&ensp;这是重启前与重启后的两条日志（后面要用到），查看包发布记录没人操作过进程，难道包发布自动重启了？</p>
<p>&ensp;&ensp;于是联系运维开发热线，确认了包发布不会自动重启进程，除非进程挂了，包发布会自动拉起。</p>
<p><img src="/images/xxl-job-running-check/7.png" alt="avatar"></p>
<p>&ensp;&ensp;查看监控，也能看到进程确认重启了，但重启前内存好好的，full gc 却发生在重启后。。这时突然想到测试机有碰到过由于系统内存不足导致进程被杀的情况，于是看了一下机器内存</p>
<p><img src="/images/xxl-job-running-check/8.png" alt="avatar"></p>
<p>&ensp;&ensp;确实剩余不多了，完全有可能，于是查询相关日志。</p>
<p><img src="/images/xxl-job-running-check/9.png" alt="avatar"></p>
<p>&ensp;&ensp;可以看到光标那行，04:04:28 有个 Java 进程被杀了，时间刚刚对应上面图中进程重启前的最后一条日志。</p>
<p>&ensp;&ensp;至此，终于破案了，<strong>系统内存不足，导致进程被杀，来不及回调 xxl-job,并且没有任何异常，然后再被包发布拉起，xxl-job 中的任务也就一直处于进行中了。</strong></p>
<p><img src="/images/xxl-job-running-check/10.png" alt="avatar"></p>
<p>&ensp;&ensp;xxl-job 确实做了这种情况的处理。但是没有生效，阅读源码发现</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">            // monitor</span><br><span class="line">while (!toStop) &#123;</span><br><span class="line">	try &#123;</span><br><span class="line">		// 任务结果丢失处理：调度记录停留在 &quot;运行中&quot; 状态超过10min，且对应执行器心跳注册失败不在线，则将本地调度主动标记失败；</span><br><span class="line">		Date losedTime = DateUtil.addMinutes(new Date(), -10);</span><br><span class="line">		List&lt;Long&gt; losedJobIds  = XxlJobAdminConfig.getAdminConfig().getXxlJobLogDao().findLostJobIds(losedTime);</span><br><span class="line">		if (losedJobIds!=null &amp;&amp; losedJobIds.size()&gt;0) &#123;</span><br><span class="line">			for (Long logId: losedJobIds) &#123;</span><br><span class="line">				XxlJobLog jobLog = new XxlJobLog();</span><br><span class="line">				jobLog.setId(logId);</span><br><span class="line">				jobLog.setHandleTime(new Date());</span><br><span class="line">				jobLog.setHandleCode(ReturnT.FAIL_CODE);</span><br><span class="line">				jobLog.setHandleMsg( I18nUtil.getString(&quot;joblog_lost_fail&quot;) );</span><br><span class="line">				XxlJobAdminConfig.getAdminConfig().getXxlJobLogDao().updateHandleInfo(jobLog);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125; catch (Exception e) &#123;</span><br><span class="line">		if (!toStop) &#123;</span><br><span class="line">			logger.error(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job, job fail monitor thread error:&#123;&#125;&quot;, e);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">    try &#123;</span><br><span class="line">        TimeUnit.SECONDS.sleep(60);</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        if (!toStop) &#123;</span><br><span class="line">            logger.error(e.getMessage(), e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>&ensp;&ensp;JobLosedMonitorHelper 类有一个线程在干这事，任务结果丢失处理：调度记录停留在 “运行中” 状态超过 10min，且对应执行器心跳注册失败不在线，则将本地调度主动标记失败。该任务确实有运行超过 10min,但是再看执行器里面的 XxlJobSpringExecutor 类：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">public class XxlJobSpringExecutor extends XxlJobExecutor implements ApplicationContextAware, SmartInitializingSingleton, DisposableBean &#123;</span><br><span class="line">    private static final Logger logger = LoggerFactory.getLogger(XxlJobSpringExecutor.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    // start</span><br><span class="line">    @Override</span><br><span class="line">    public void <span class="function"><span class="title">afterSingletonsInstantiated</span></span>() &#123;</span><br><span class="line"></span><br><span class="line">        // init JobHandler Repository</span><br><span class="line">        /*initJobHandlerRepository(applicationContext);*/</span><br><span class="line"></span><br><span class="line">        // init JobHandler Repository (<span class="keyword">for</span> method)</span><br><span class="line">        initJobHandlerMethodRepository(applicationContext);</span><br><span class="line"></span><br><span class="line">        // refresh GlueFactory</span><br><span class="line">        GlueFactory.refreshInstance(1);</span><br><span class="line"></span><br><span class="line">        // super start</span><br><span class="line">        try &#123;</span><br><span class="line">            super.start();</span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            throw new RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // destroy</span><br><span class="line">    @Override</span><br><span class="line">    public void <span class="function"><span class="title">destroy</span></span>() &#123;</span><br><span class="line">        super.destroy();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>&ensp;&ensp;destory 方法会去执行 ExecutorRegistryThread 中的 stop 方法：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">public void <span class="function"><span class="title">toStop</span></span>() &#123;</span><br><span class="line">    toStop = <span class="literal">true</span>;</span><br><span class="line">    // interrupt and <span class="built_in">wait</span></span><br><span class="line">    registryThread.interrupt();</span><br><span class="line">    try &#123;</span><br><span class="line">        registryThread.join();</span><br><span class="line">    &#125; catch (InterruptedException e) &#123;</span><br><span class="line">        logger.error(e.getMessage(), e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>&ensp;&ensp;ExecutorRegistryThread 中的 register 线程代码如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">registryThread = new Thread(new <span class="function"><span class="title">Runnable</span></span>() &#123;</span><br><span class="line">	@Override</span><br><span class="line">	public void <span class="function"><span class="title">run</span></span>() &#123;</span><br><span class="line">		// registry</span><br><span class="line">		<span class="keyword">while</span> (!toStop) &#123;</span><br><span class="line">			try &#123;</span><br><span class="line">				RegistryParam registryParam = new RegistryParam(RegistryConfig.RegistType.EXECUTOR.name(), appname, address);</span><br><span class="line">				<span class="keyword">for</span> (AdminBiz adminBiz : XxlJobExecutor.getAdminBizList()) &#123;</span><br><span class="line">					try &#123;</span><br><span class="line">						ReturnT&lt;String&gt; registryResult = adminBiz.registry(registryParam);</span><br><span class="line">						<span class="keyword">if</span> (registryResult != null &amp;&amp; ReturnT.SUCCESS_CODE == registryResult.getCode()) &#123;</span><br><span class="line">							registryResult = ReturnT.SUCCESS;</span><br><span class="line">							logger.debug(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job registry success, registryParam:&#123;&#125;, registryResult:&#123;&#125;&quot;</span>, new Object[]&#123;registryParam, registryResult&#125;);</span><br><span class="line">							<span class="built_in">break</span>;</span><br><span class="line">						&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">							logger.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job registry fail, registryParam:&#123;&#125;, registryResult:&#123;&#125;&quot;</span>, new Object[]&#123;registryParam, registryResult&#125;);</span><br><span class="line">						&#125;</span><br><span class="line">					&#125; catch (Exception e) &#123;</span><br><span class="line">						logger.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job registry error, registryParam:&#123;&#125;&quot;</span>, registryParam, e);</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125; catch (Exception e) &#123;</span><br><span class="line">				<span class="keyword">if</span> (!toStop) &#123;</span><br><span class="line">					logger.error(e.getMessage(), e);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			try &#123;</span><br><span class="line">				<span class="keyword">if</span> (!toStop) &#123;</span><br><span class="line">					TimeUnit.SECONDS.sleep(RegistryConfig.BEAT_TIMEOUT);</span><br><span class="line">				&#125;</span><br><span class="line">			&#125; catch (InterruptedException e) &#123;</span><br><span class="line">				<span class="keyword">if</span> (!toStop) &#123;</span><br><span class="line">					logger.warn(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job, executor registry thread interrupted, error msg:&#123;&#125;&quot;</span>, e.getMessage());</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		// registry remove</span><br><span class="line">		try &#123;</span><br><span class="line">			RegistryParam registryParam = new RegistryParam(RegistryConfig.RegistType.EXECUTOR.name(), appname, address);</span><br><span class="line">			<span class="keyword">for</span> (AdminBiz adminBiz : XxlJobExecutor.getAdminBizList()) &#123;</span><br><span class="line">				try &#123;</span><br><span class="line">					ReturnT&lt;String&gt; registryResult = adminBiz.registryRemove(registryParam);</span><br><span class="line">					<span class="keyword">if</span> (registryResult != null &amp;&amp; ReturnT.SUCCESS_CODE == registryResult.getCode()) &#123;</span><br><span class="line">						registryResult = ReturnT.SUCCESS;</span><br><span class="line">						logger.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job registry-remove success, registryParam:&#123;&#125;, registryResult:&#123;&#125;&quot;</span>, new Object[]&#123;registryParam, registryResult&#125;);</span><br><span class="line">						<span class="built_in">break</span>;</span><br><span class="line">					&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">						logger.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job registry-remove fail, registryParam:&#123;&#125;, registryResult:&#123;&#125;&quot;</span>, new Object[]&#123;registryParam, registryResult&#125;);</span><br><span class="line">					&#125;</span><br><span class="line">				&#125; catch (Exception e) &#123;</span><br><span class="line">					<span class="keyword">if</span> (!toStop) &#123;</span><br><span class="line">						logger.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job registry-remove error, registryParam:&#123;&#125;&quot;</span>, registryParam, e);</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			<span class="keyword">if</span> (!toStop) &#123;</span><br><span class="line">				logger.error(e.getMessage(), e);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		logger.info(<span class="string">&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job, executor registry thread destory.&quot;</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>&ensp;&ensp;可以看到 register remove 部分有去 registerRemove 当前执行器地址并且打印相关日志，但是系统强制 kill 了进程，导致 destroy()方法没有执行，执行器没有进行 registerRemove 回调，xxl-job admin 也就无法感知执行器已经失败不在线，导致没有终止这个运行大于 10min 的任务，看重启前的日志也可以说明确实没有进行 registerRemove 回调，所以不管什么系统做好优雅关闭确实很重要。</p>
]]></content>
      <categories>
        <category>问题排查</category>
      </categories>
      <tags>
        <tag>xxl-job</tag>
        <tag>经验</tag>
      </tags>
  </entry>
  <entry>
    <title>ES使用拼音搜索并且highlight搜索结果</title>
    <url>/2022/01/01/es-pinyin-highlight/</url>
    <content><![CDATA[<h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>基于<a href="https://github.com/medcl/elasticsearch-analysis-pinyin">此pinyin分词器</a> 实现搜索,自定义analyzer,使用type ngarm当做tokenizer,使用type pinyin当做filter,并且设置<code>&quot;term_vector&quot;: &quot;with_positions_offsets&quot;</code></p>
<span id="more"></span>
<h3 id="🌰"><a href="#🌰" class="headerlink" title="🌰"></a>🌰</h3><h4 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT es_pinyin_highlight</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;mappings&quot;</span> : &#123;</span><br><span class="line">      <span class="string">&quot;dynamic&quot;</span> : <span class="string">&quot;false&quot;</span>,</span><br><span class="line">      <span class="string">&quot;properties&quot;</span> : &#123;</span><br><span class="line">        <span class="string">&quot;text&quot;</span>: &#123;</span><br><span class="line">          <span class="string">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span>,</span><br><span class="line">          <span class="string">&quot;fields&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;pinyin&quot;</span>:&#123;</span><br><span class="line">              <span class="string">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span>,</span><br><span class="line">              <span class="string">&quot;analyzer&quot;</span>: <span class="string">&quot;pinyin_analyzer&quot;</span>,</span><br><span class="line">              <span class="string">&quot;search_analyzer&quot;</span>: <span class="string">&quot;standard&quot;</span>,</span><br><span class="line">              <span class="string">&quot;term_vector&quot;</span>: <span class="string">&quot;with_positions_offsets&quot;</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;settings&quot;</span> : &#123;</span><br><span class="line">      <span class="string">&quot;index&quot;</span> : &#123;</span><br><span class="line">        <span class="string">&quot;analysis&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;analyzer&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;pinyin_analyzer&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;tokenizer&quot;</span>: <span class="string">&quot;my_ngram&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;filter&quot;</span>: [</span><br><span class="line">                        <span class="string">&quot;pinyin_filter&quot;</span></span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;tokenizer&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;my_ngram&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;ngram&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;min_gram&quot;</span>: 2,</span><br><span class="line">                    <span class="string">&quot;max_gram&quot;</span>: 3,</span><br><span class="line">                    <span class="string">&quot;token_chars&quot;</span>: [</span><br><span class="line">                        <span class="string">&quot;letter&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;digit&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;punctuation&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;symbol&quot;</span></span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;filter&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;pinyin_filter&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;pinyin&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;keep_full_pinyin&quot;</span>: <span class="literal">false</span>,</span><br><span class="line">                    <span class="string">&quot;keep_joined_full_pinyin&quot;</span>: <span class="literal">true</span>,</span><br><span class="line">                    <span class="string">&quot;keep_none_chinese_in_joined_full_pinyin&quot;</span>: <span class="literal">true</span>,</span><br><span class="line">                    <span class="string">&quot;none_chinese_pinyin_tokenize&quot;</span>: <span class="literal">false</span>,</span><br><span class="line">                    <span class="string">&quot;remove_duplicated_term&quot;</span>: <span class="literal">true</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PUT /es_pinyin_highlight/_create/1</span><br><span class="line">&#123;<span class="string">&quot;text&quot;</span>:<span class="string">&quot;ES是世界上最好的搜索工具&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">POST /es_pinyin_highlight/_search</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;query&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;match&quot;</span>: &#123;</span><br><span class="line">      <span class="string">&quot;text.pinyin&quot;</span>: <span class="string">&quot;sousuo&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">   <span class="string">&quot;highlight&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;fields&quot;</span> : &#123;</span><br><span class="line">            <span class="string">&quot;text&quot;</span> : &#123;&#125;,</span><br><span class="line">            <span class="string">&quot;text.pinyin&quot;</span> : &#123;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="搜索结果"><a href="#搜索结果" class="headerlink" title="搜索结果"></a>搜索结果</h5><p><img src="/images/es/es_pinyin_highlight_res.png" alt="img.png"></p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ol>
<li>基于ngarm当做tokenizer，需要控制<code>min_gram</code>、<code>max_gram</code>参数的大小，防止token过多，造成索引膨胀，写入性能降低</li>
</ol>
<hr>
<p>如果你有更好的方案，欢迎comment</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://github.com/medcl/elasticsearch-analysis-pinyin/issues/185">https://github.com/medcl/elasticsearch-analysis-pinyin/issues/185</a></p>
]]></content>
      <tags>
        <tag>ES</tag>
      </tags>
  </entry>
  <entry>
    <title>工作经验</title>
    <url>/2022/05/04/work-experience/</url>
    <content><![CDATA[<blockquote>
<p>最近工作中遇到一些不愉快的事情，有自己的原因，也有其他的原因，为了避免后续再遇到这种情况，以及自己更好地成长，这里总结一下</p>
</blockquote>
<h2 id="如何更好的工作"><a href="#如何更好的工作" class="headerlink" title="如何更好的工作"></a>如何更好的工作</h2><ol>
<li>客观对待工作中的问题，尽量不掺杂个人感情。</li>
<li>对某件事情有疑问或者不同的看法时及时沟通，尽量与对方达成一致，如果达不成一致，可以拉会进行投票，看大家的看法，遵循更多人的意见。切忌攻击、逃跑或者忽略对待。</li>
<li>沟通起来要有耐心。</li>
<li>公司花钱买了我们的时间，遇到工作与学习冲突时，将工作放第一位；努力做好每份工作，追求极致，在追求极致中学习成长。</li>
<li>除了工作中学习，自身的学习（补缺补漏）也必不可少；保持良好心态，不急躁，不浮躁，不与别人比较，只与昨天的自己比较，争取每天进步一点点。</li>
<li>保持乐观心态，平衡好生活与工作，没有紧急事情9点下班，去健身房走走动动，增强体质，持续发展。</li>
</ol>
]]></content>
      <tags>
        <tag>工作经验</tag>
      </tags>
  </entry>
  <entry>
    <title>手工模拟实现 Docker 容器网络（转）！</title>
    <url>/2022/05/08/make-docker-net/</url>
    <content><![CDATA[<blockquote>
<p>网络虚拟化，其实用一句话来概括就是用软件来模拟实现真实的物理网络连接。比如 Docker 就是用纯软件的方式在宿主机上模拟出来的独立网络环境。我们今天来徒手打造一个虚拟网络，实现在这个网络里访问外网资源，同时监听端口提供对外服务的功能。</p>
</blockquote>
<span id="more"></span>

<p><img src="/images/make-docker-net/img.png" alt="avatar"></p>
<h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><h3 id="veth-bridge-与-namespace"><a href="#veth-bridge-与-namespace" class="headerlink" title="veth, bridge 与 namespace"></a>veth, bridge 与 namespace</h3><p>Linux 下的 veth 是一对儿虚拟网卡设备，和我们常见的 lo 很类似。在这儿设备里，从一端发送数据后，内核会寻找该设备的另一半，所以在另外一端就能收到。不过 veth 只能解决一对一通信的问题。<br>详情参考<a href="https://mp.weixin.qq.com/s/sSQFINJ8RO8Nc4XtcyQIjQ">轻松理解Docker网络虚拟化基础之veth设备</a>  </p>
<p>如果有很多对儿 veth 需要互相通信的话，就需要引入 bridge 这个虚拟交换机。各个 veth 对儿可以把一头连接在 bridge 的接口上，bridge 可以和交换机一样在端口之间转发数据，使得各个端口上的 veth 都可以互相通信。<br>参见<a href="https://mp.weixin.qq.com/s/JnKz1fUgZmGdvfxOm2ehZg">聊聊Linux上软件实现的”交换机”-bridge</a>  </p>
<p>Namespace 解决的是隔离性的问题。每个虚拟网卡设备、进程、socket、路由表等等网络栈相关的对象默认都是归属在 init_net 这个缺省的 namespace 中的。不过我们希望不同的虚拟化环境之间是隔离的，<br>用 Docker 来举例，那就是不能让 A 容器用到 B 容器的设备、路由表、socket 等资源，甚至连看一眼都不可以。只有这样才能保证不同的容器之间复用资源的同时，还不会影响其它容器的正常运行。<br>参见<a href="https://mp.weixin.qq.com/s/lscMpc5BWAEzjgYw6H0wBw">彻底弄懂Linux网络命名空间</a>  </p>
<p>通过 veth、namespace 和 bridge 我们在一台 Linux 上就能虚拟多个网络环境出来。而且它们之间、和宿主机之间都可以互相通信。<br><img src="/images/make-docker-net/img_1.png" alt="avatar"></p>
<p>了解这些过后，我们还剩一个问题没有解决，那就是虚拟出来的网络环境和外部网络的通信。还拿 Docker 容器来举例，你启动的容器里的服务肯定是需要访问外部的数据库的。还有就是可能需要暴露比如 80 端口对外提供服务。<br>例如在 Docker 中我们通过下面的命令将容器的 80 端口上的 web 服务要能被外网访问的到。</p>
<p>我们今天的文章主要就是解决这两个问题的，一是从虚拟网络中访问外网，二是在虚拟网络中提供服务供外网使用。解决它们需要用到路由和 nat 技术。</p>
<h3 id="路由选择"><a href="#路由选择" class="headerlink" title="路由选择"></a>路由选择</h3><p>Linux 是在发送数据包的时候，会涉及到路由过程。这个发送数据包既包括本机发送数据包，也包括途径当前机器的数据包的转发。  </p>
<p>先来看本机发送数据包。其中本机发送在<a href="https://mp.weixin.qq.com/s/wThfD9th9e_-YGHJJ3HXNQ">25 张图，一万字，拆解 Linux 网络包发送过程</a>这一篇我们讨论过。  </p>
<p>所谓路由其实很简单，就是该选择哪张网卡（虚拟网卡设备也算）将数据写进去。到底该选择哪张网卡呢，规则都是在路由表中指定的。Linux 中可以有多张路由表，最重要和常用的是 local 和 main。  </p>
<p>local 路由表中统一记录本地，确切地说是本网络命名空间中的网卡设备 IP 的路由规则。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#ip route list table local</span></span><br><span class="line"><span class="built_in">local</span> 10.143.x.y dev eth0 proto kernel scope host src 10.143.x.y</span><br><span class="line"><span class="built_in">local</span> 127.0.0.1 dev lo proto kernel scope host src 127.0.0.1</span><br></pre></td></tr></table></figure>
<p>其它的路由规则，一般都是在 main 路由表中记录着的。可以用 <code>ip route list table main</code> 查看，也可以用更简短的 <code>route -n</code><br><img src="/images/make-docker-net/img_2.png" alt="avatar"></p>
<p>再看途径当前机器的数据包的转发。除了本机发送以外，转发也会涉及路由过程。如果 Linux 收到数据包以后发现目的地址并不是本地的地址的话，就可以选择把这个数据包从自己的某个网卡设备上转发出去。<br>这个时候和本机发送一样，也需要读取路由表。根据路由表的配置来选择从哪个设备将包转走。  </p>
<p>不过值得注意的是，Linux 上转发功能默认是关闭的。也就是发现目的地址不是本机 IP 地址默认是将包直接丢弃。需要做一些简单的配置，然后 Linux 才可以干像路由器一样的活儿，实现数据包的转发。</p>
<h3 id="iptables-与-NAT"><a href="#iptables-与-NAT" class="headerlink" title="iptables 与 NAT"></a>iptables 与 NAT</h3><p>Linux 内核网络栈在运行上基本上是一个纯内核态的东西，但为了迎合各种各样用户层不同的需求，内核开放了一些口子出来供用户层来干预。其中 iptables 就是一个非常常用的干预内核行为的工具，它在内核里埋下了五个钩子入口，这就是俗称的五链。  </p>
<p>Linux 在接收数据的时候，在 IP 层进入 ip_rcv 中处理。再执行路由判断，发现是本机的话就进入 ip_local_deliver 进行本机接收，最后送往 TCP 协议层。在这个过程中，埋了两个 HOOK，第一个是 PRE_ROUTING。这段代码会执行到 iptables 中 pre_routing 里的各种表。发现是本地接收后接着又会执行到 LOCAL_IN，这会执行到 iptables 中配置的 input 规则。  </p>
<p>在发送数据的时候，查找路由表找到出口设备后，依次通过 __ip_local_out、 ip_output 等函数将包送到设备层。在这两个函数中分别过了 OUTPUT 和 POSTROUTING 开的各种规则。  </p>
<p>如果是转发过程，Linux 收到数据包发现不是本机的包可以通过查找自己的路由表找到合适的设备把它转发出去。那就先是在 ip_rcv 中将包送到 ip_forward 函数中处理，最后在 ip_output 函数中将包转发出去。在这个过程中分别过了 PREROUTING、FORWARD 和 POSTROUTING 三个规则。  </p>
<p>综上所述，iptables 里的五个链在内核网络模块中的位置就可以归纳成如下这幅图。<br><img src="/images/make-docker-net/img_3.png" alt="avatar"></p>
<p>数据接收过程走的是 1 和 2，发送过程走的是 4 、5，转发过程是 1、3、5。有了这张图，我们能更清楚地理解 iptable 和内核的关系。  </p>
<p>在 iptables 中，根据实现的功能的不同，又分成了四张表。分别是 raw、mangle、nat 和 filter。<br>其中 nat 表实现我们常说的 NAT（Network AddressTranslation） 功能。其中 nat 又分成 SNAT（Source NAT）和 DNAT（Destination NAT）两种。  </p>
<p>SNAT 解决的是内网地址访问外部网络的问题。它是通过在 POSTROUTING 里修改来源 IP 来实现的。  </p>
<p>DNAT 解决的是内网的服务要能够被外部访问到的问题。它在通过 PREROUTING 修改目标 IP 实现的。  </p>
<h2 id="实现虚拟网络与外网通信"><a href="#实现虚拟网络与外网通信" class="headerlink" title="实现虚拟网络与外网通信"></a>实现虚拟网络与外网通信</h2><blockquote>
<p>基于以上的基础知识，我们用纯手工的方式搭建一个可以和 Docker 类似的虚拟网络。而且要实现和外网通信的功能。</p>
</blockquote>
<h3 id="实验环境准备"><a href="#实验环境准备" class="headerlink" title="实验环境准备"></a>实验环境准备</h3><p>我们先来创建一个虚拟的网络环境出来，其命名空间为 net1。宿主机的 IP 是 10.248 的网段，可以访问外部机器。虚拟网络为其分配 192.168.0 的网段，这个网段是私有的，外部机器无法识别。<br><img src="/images/make-docker-net/%E6%B5%81%E7%A8%8B%E5%9B%BE_1_1.jpg" alt="avatar"></p>
<p>这个虚拟网络的搭建过程如下。先创建一个 netns 出来，命名为 net1。  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ip netns add net1</span></span><br></pre></td></tr></table></figure>

<p>创建一个 veth 对儿（veth1 - veth1_p），把其中的一头 veth1 放在 net1 中，给它配置上 IP，并把它启动起来。  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ip link add veth1 type veth peer name veth1_p</span></span><br><span class="line"><span class="comment"># ip link set veth1 netns net1</span></span><br><span class="line"><span class="comment"># ip netns exec net1 ip addr add 192.168.0.2/24 dev veth1  # IP</span></span><br><span class="line"><span class="comment"># ip netns exec net1 ip link set veth1 up</span></span><br></pre></td></tr></table></figure>

<p>创建一个 bridge，给它也设置上 ip。接下来把 veth 的另外一端 veth1_p 插到 bridge 上面。最后把网桥和 veth1_p 都启动起来。  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># brctl addbr br0</span></span><br><span class="line"><span class="comment"># ip addr add 192.168.0.1/24 dev br0</span></span><br><span class="line"><span class="comment"># ip link set dev veth1_p master br0</span></span><br><span class="line"><span class="comment"># ip link set veth1_p up</span></span><br><span class="line"><span class="comment"># ip link set br0 up</span></span><br></pre></td></tr></table></figure>
<p>这样我们就在 Linux 上创建出了一个虚拟的网络。  </p>
<h3 id="请求外网资源"><a href="#请求外网资源" class="headerlink" title="请求外网资源"></a>请求外网资源</h3><p>现在假设我们上面的 net1 这个网络环境中想访问外网。这里的外网是指的虚拟网络宿主机外部的网络。<br>我们假设它要访问的另外一台机器 IP 是 百度：163.177.151.109<br><img src="/images/make-docker-net/%E6%B5%81%E7%A8%8B%E5%9B%BE.jpg" alt="avatar"></p>
<p>我们直接来访问一下试试  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ip netns exec net1 ping 163.177.151.109</span></span><br><span class="line">connect: Network is unreachable</span><br></pre></td></tr></table></figure>

<p>我们推断可能是路由出问题了，看一下这个命名空间的路由表。  </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ip netns exec net1 route -n</span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">192.168.0.0     0.0.0.0         255.255.255.0   U     0      0        0 veth1</span><br></pre></td></tr></table></figure>

<p>怪不得，原来 net1 这个 namespace 下默认只有 192.168.0.* 这个网段的路由规则。我们 ping 的 IP 是 163.177.151.109 ，根据这个路由表里找不到出口。自然就发送失败了。  </p>
<p>我们来给 net 添加上默认路由规则，只要匹配不到其它规则就默认送到 veth1 上，同时指定下一条是它所连接的 bridge（192.168.0.1）。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ip netns exec net1 route add default gw 192.168.0.1 veth1</span></span><br></pre></td></tr></table></figure>

<p>再 ping 一下试试。  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># ip netns exec net1 ping 163.177.151.109 -c 2</span></span><br><span class="line">PING  163.177.151.109 ( 163.177.151.109) 56(84) bytes of data.</span><br><span class="line"></span><br><span class="line">---  163.177.151.109 ping statistics ---</span><br><span class="line">2 packets transmitted, 0 received, 100% packet loss, time 999ms</span><br></pre></td></tr></table></figure>

<p>额好吧，仍然不通。上面路由帮我们把数据包从 veth 正确送到了 bridge 这个网桥上。接下来网桥还需要 bridge 转发到 eth0 网卡上。所以我们得打开下面这两个转发相关的配置</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># sysctl net.ipv4.conf.all.forwarding=1</span></span><br><span class="line"><span class="comment"># iptables -P FORWARD ACCEPT</span></span><br></pre></td></tr></table></figure>

<p>不过这个时候，还存在一个问题。那就是外部的机器并不认识 192.168.0.* 这个网段的 ip。它们之间都是通过  10.248.<em>.</em>  来进行通信的。设想下我们工作中的电脑上没有外网 IP 的时候是如何正常上网的呢？外部的网络只认识外网 IP。没错，那就是我们上面说的 NAT 技术。  </p>
<p>我们这次的需求是实现内部虚拟网络访问外网，所以需要使用的是 SNAT。它将 namespace 请求中的 IP（192.168.0.2）换成外部网络认识的 10.248.*.*，进而达到正常访问外部网络的效果。  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># iptables -t nat -A POSTROUTING -s 192.168.0.0/24 ! -o br0 -j MASQUERADE</span></span><br></pre></td></tr></table></figure>

<p>来再 ping 一下试试，欧耶，通了！  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ip netns exec net1 ping 163.177.151.109 -c 2</span></span><br><span class="line">PING 163.177.151.109 (163.177.151.109) 56(84) bytes of data.</span><br><span class="line">64 bytes from 163.177.151.109: icmp_seq=1 ttl=44 time=45.0 ms</span><br><span class="line">64 bytes from 163.177.151.109: icmp_seq=2 ttl=44 time=44.9 ms</span><br></pre></td></tr></table></figure>
<p>这时候我们可以开启 tcpdump 抓包查看一下，在 bridge 上抓到的包我们能看到还是原始的源 IP 和 目的 IP。<br><img src="/images/make-docker-net/img_5.png" alt="avatar"><br>再到 eth0 上查看的话，源 IP 已经被替换成可和外网通信的 eth0 上的 IP 了。<br><img src="/images/make-docker-net/img_6.png" alt="avatar"></p>
<p>至此，容器就可以通过宿主机的网卡来访问外部网络上的资源了。我们来总结一下这个发送过程<br><img src="/images/make-docker-net/%E6%B5%81%E7%A8%8B%E5%9B%BE_1_all.jpg" alt="总结"></p>
<h2 id="开放容器端口"><a href="#开放容器端口" class="headerlink" title="开放容器端口"></a>开放容器端口</h2><p>我们再考虑另外一个需求，那就是把在这个命名空间内的服务提供给外部网络来使用。<br>和上面的问题一样，我们的虚拟网络环境中 192.168.0.2 这个 IP 外界是不认识它的。只有这个宿主机知道它是谁。所以我们同样还需要 NAT 功能。<br>这次我们是要实现外部网络访问内部地址，所以需要的是 DNAT 配置。DNAT 和 SNAT 配置中有一个不一样的地方就是需要明确指定容器中的端口在宿主机上是对应哪个。比如在 docker 的使用中，是通过 -p 来指定端口的对应关系。  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker run -p 8000:80 ...</span></span><br></pre></td></tr></table></figure>
<p>我们通过如下这个命令来配置 DNAT 规则  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># iptables -t nat -A PREROUTING  ! -i br0 -p tcp -m tcp --dport 8088 -j DNAT --to-destination 192.168.0.2:80</span></span><br></pre></td></tr></table></figure>
<p>这里表示的是宿主机在路由之前判断一下如果流量不是来自 br0，并且是访问 tcp 的 8088 的话，那就转发到 192.168.0.2:80 。  </p>
<p>在 net1 环境中启动一个 Server  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip netns <span class="built_in">exec</span> net1 nc -lp 80</span><br></pre></td></tr></table></figure>

<p>开启抓包， <code>tcpdump  tcp port 8088 -i eth0  -n host 10.143.*.*</code>。可见在请求的时候，目的是宿主机的 IP 的端口。<br><img src="/images/make-docker-net/img_7.png" alt="img.png"></p>
<p>但数据包到宿主机协议栈以后命中了我们配置的 DNAT 规则，宿主机把它转发到了 br0 上。在 bridge 上由于没有那么多的网络流量包，所以不用过滤直接抓包就行，<code> tcpdump -i br0</code>。<br><img src="/images/make-docker-net/img_8.png" alt="img.png"></p>
<p>bridge 当然知道 192.168.0.2 是 veth 1。于是，在 veth1 上监听 80 的服务就能收到来自外界的请求了！我们来总结一下这个接收过程  </p>
<p><img src="/images/make-docker-net/%E6%B5%81%E7%A8%8B%E5%9B%BE_2_all.jpg" alt="总结"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>现在业界已经有很多公司都迁移到容器上了。我们的开发写出来的代码大概率是要运行在容器上的。因此深刻理解容器网络的工作原理非常的重要。这有这样将来遇到问题的时候才知道该如何下手处理。  </p>
<p>本文开头我们先是简单介绍了 veth、bridge、namespace、路由、iptables 等基础知识。Veth 实现连接，bridge 实现转发，namespace 实现隔离，路由表控制发送时的设备选择，iptables 实现 nat 等功能。  </p>
<p>接着基于以上基础知识，我们采用纯手工的方式搭建了一个虚拟网络环境。  </p>
<p>这个虚拟网络可以访问外网资源，也可以提供端口服务供外网来调用。这就是 Docker 容器网络工作的基本原理。 </p>
<p>整个实验作者打包写成一个 Makefile，放到了这里：<a href="https://github.com/yanfeizhang/coder-kung-fu/tree/main/tests/network/test07">https://github.com/yanfeizhang/coder-kung-fu/tree/main/tests/network/test07</a></p>
<p>最后，我们再扩展一下。今天我们讨论的问题是 Docker 网络通信的问题。Docker 容器通过端口映射的方式提供对外服务。外部机器访问容器服务的时候，仍然需要通过容器的宿主机 IP 来访问。  </p>
<p>在 Kubernets 中，对跨主网络通信有更高的要求，要不同宿主机之间的容器可以直接互联互通。所以 Kubernets 的网络模型也更为复杂。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://mp.weixin.qq.com/s/Arcz3RWe_o0Ijw6uPWKdVw">手工模拟实现 Docker 容器网络！</a></p>
]]></content>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title>go垃圾收集器</title>
    <url>/2022/07/10/go_garbage_collector/</url>
    <content><![CDATA[<h2 id="设计原理"><a href="#设计原理" class="headerlink" title="设计原理"></a>设计原理</h2><h3 id="标记清除"><a href="#标记清除" class="headerlink" title="标记清除"></a>标记清除</h3><blockquote>
<p>标记清除（Mark-Sweep）算法是最常见的垃圾收集算法，标记清除收集器是跟踪式垃圾收集器，其执行过程可以分成标记（Mark）和清除（Sweep）两个阶段：</p>
</blockquote>
<ol>
<li>标记阶段 — 从根对象出发查找并标记堆中所有存活的对象；</li>
<li>清除阶段 — 遍历堆中的全部对象，回收未被标记的垃圾对象并将回收的内存加入空闲链表；</li>
</ol>
<ul>
<li>问题：两个阶段都需要STW<span id="more"></span></li>
</ul>
<h3 id="三色抽象"><a href="#三色抽象" class="headerlink" title="三色抽象"></a>三色抽象</h3><blockquote>
<p>为了解决原始标记清除算法带来的长时间 STW，多数现代的追踪式垃圾收集器都会实现三色标记算法的变种以缩短 STW 的时间。三色标记算法将程序中的对象分成白色、黑色和灰色三类：</p>
</blockquote>
<ul>
<li>白色对象 — 潜在的垃圾，其内存可能会被垃圾收集器回收；</li>
<li>黑色对象 — 活跃的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象；</li>
<li>灰色对象 — 活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象；<br><img src="/images/go_garbage_collector/img.png" alt="img.png"><br>在垃圾收集器开始工作时，程序中不存在任何的黑色对象，<strong>垃圾收集的根对象会被标记成灰色</strong>，<strong>垃圾收集器只会从灰色对象集合中取出对象开始扫描，当灰色集合中不存在任何对象时，标记阶段就会结束</strong>。</li>
</ul>
<p>三色标记垃圾收集器的工作原理很简单，我们可以将其归纳成以下几个步骤：</p>
<ol>
<li>从灰色对象的集合中选择一个灰色对象并将其标记成黑色；</li>
<li><strong>将黑色对象指向的所有对象都标记成灰色</strong>，保证该对象和被该对象引用的对象都不会被回收；</li>
<li>重复上述两个步骤直到对象图中不存在灰色对象；</li>
</ol>
<p>当三色的标记清除的标记阶段结束之后，应用程序的堆中就不存在任何的灰色对象<strong>，我们只能看到黑色的存活对象以及白色的垃圾对象，垃圾收集器可以回收这些白色的垃圾</strong>，</p>
<ul>
<li>问题: 因为用户程序可能在标记执行的过程中修改对象的指针，所以三色标记清除算法本身是不可以并发或者增量执行的，它仍然需要 STW</li>
</ul>
<h3 id="屏障技术"><a href="#屏障技术" class="headerlink" title="屏障技术"></a>屏障技术</h3><blockquote>
<p>内存屏障技术是一种屏障指令，它可以让 CPU 或者编译器在执行内存相关操作时遵循特定的约束，目前多数的现代处理器都会乱序执行指令以最大化性能，<br>但是该技术能够保证内存操作的顺序性，<strong>在内存屏障前执行的操作一定会先于内存屏障后执行的操作</strong>。<br> 想要在并发或者增量的标记算法中保证正确性，我们需要达成以下两种三色不变性（Tri-color invariant）中的一种：</p>
</blockquote>
<ol>
<li>强三色不变性 — 黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象；</li>
<li>弱三色不变性 — 黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径7；<br><img src="/images/go_garbage_collector/img_1.png" alt="img_1.png"></li>
</ol>
<p>上图分别展示了遵循强三色不变性和弱三色不变性的堆内存，遵循上述两个不变性中的任意一个，我们都能保证垃圾收集算法的正确性，而屏障技术就是在并发或者增量标记过程中保证三色不变性的重要技术。</p>
<p>垃圾收集中的屏障技术更像是一个钩子方法，<strong>它是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码</strong>，根据操作类型的不同，我们可以将它们分成读屏障（Read barrier）和写屏障（Write barrier）两种，<br>因为读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以<strong>编程语言往往都会采用写屏障保证三色不变性</strong>。</p>
<h4 id="Dijkstra-插入写屏障"><a href="#Dijkstra-插入写屏障" class="headerlink" title="Dijkstra 插入写屏障"></a>Dijkstra 插入写屏障</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">writePointer(slot, ptr):</span><br><span class="line">    shade(ptr)</span><br><span class="line">    *slot = ptr</span><br></pre></td></tr></table></figure>
<p>每当执行类似 *slot = ptr 的表达式时，我们会执行上述写屏障通过 shade 函数尝试改变指针的颜色。<strong>如果 ptr 指针是白色的，那么该函数会将该对象设置成灰色</strong>，其他情况则保持不变。<br><img src="/images/go_garbage_collector/img_2.png" alt="img_2.png"></p>
<p>Dijkstra 的插入写屏障是一种相对保守的屏障技术，它会将有存活可能的对象都标记成灰色以满足强三色不变性。</p>
<p>它也有明显的缺点。因为<strong>栈上的对象在垃圾收集中也会被认为是根对象</strong>，所以为了保证内存的安全，Dijkstra <strong>必须为栈上的对象增加写屏障或者在标记阶段完成重新对栈上的对象进行扫描</strong>，</p>
<h4 id="Yuasa-删除写屏障"><a href="#Yuasa-删除写屏障" class="headerlink" title="Yuasa 删除写屏障"></a>Yuasa 删除写屏障</h4><p>一旦该写屏障开始工作，它会保证开启写屏障时堆上所有对象的可达，所以也被称作快照垃圾收集（Snapshot GC）</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">writePointer(slot, ptr)</span><br><span class="line">    shade(*slot)</span><br><span class="line">    *slot = ptr</span><br></pre></td></tr></table></figure>
<p>上述代码会在老对象的引用被删除时，<strong>将白色的老对象涂成灰色</strong>，这样删除写屏障就可以保证弱三色不变性，老对象引用的下游对象一定可以被灰色对象引用。</p>
<p><img src="/images/go_garbage_collector/img_3.png" alt="img_3.png"></p>
<p>假设我们在应用程序中使用 Yuasa 提出的删除写屏障，在一个垃圾收集器和用户程序交替运行的场景中会出现如上图所示的标记过程：</p>
<ol>
<li>垃圾收集器将根对象指向 A 对象标记成黑色并将 A 对象指向的对象 B 标记成灰色；</li>
<li>用户程序将 A 对象原本指向 B 的指针指向 C，触发删除写屏障，但是因为 B 对象已经是灰色的，所以不做改变；</li>
<li><strong>用户程序将 B 对象原本指向 C 的指针删除，触发删除写屏障，白色的 C 对象被涂成灰色；</strong></li>
<li>垃圾收集器依次遍历程序中的其他灰色对象，将它们分别标记成黑色；<br>上述过程中的第三步触发了 Yuasa 删除写屏障的着色，因为用户程序删除了 B 指向 C 对象的指针，所以 C 和 D 两个对象会分别违反强三色不变性和弱三色不变性：</li>
</ol>
<ul>
<li>强三色不变性 — 黑色的 A 对象直接指向白色的 C 对象；</li>
<li>弱三色不变性 — 垃圾收集器无法从某个灰色对象出发，经过几个连续的白色对象访问白色的 C 和 D 两个对象；</li>
<li>*Yuasa 删除写屏障通过对 C 对象的着色，保证了 C 对象和下游的 D 对象能够在这一次垃圾收集的循环中存活**，避免发生悬挂指针以保证用户程序的正确性。</li>
</ul>
<h3 id="增量和并发"><a href="#增量和并发" class="headerlink" title="增量和并发"></a>增量和并发</h3><p>为了减少应用程序暂停的最长时间和垃圾收集的总暂停时间，我们会使用下面的策略优化现代的垃圾收集器：</p>
<ul>
<li>增量垃圾收集 — 增量地标记和清除垃圾，降低应用程序暂停的最长时间；<ul>
<li>增量式的垃圾收集需要与三色标记法一起使用，为了保证垃圾收集的正确性，我们需要在垃圾收集开始前<strong>打开写屏障</strong>，这样用户程序修改内存都会先经过写屏障的处理，保证了堆内存中对象关系的强三色不变性或者弱三色不变性。</li>
</ul>
</li>
<li>并发垃圾收集 — 利用多核的计算资源，在用户程序执行时并发标记和清除垃圾；<ul>
<li><strong>通过开启读写屏障</strong>、<strong>利用多核优势与用户程序并行执行</strong></li>
</ul>
</li>
</ul>
<h2 id="演进过程"><a href="#演进过程" class="headerlink" title="演进过程"></a>演进过程</h2><p>最开始的垃圾收集器是不精确的单线程 STW 收集器，最新版本的垃圾收集器支持<strong>并发垃圾收集、去中心化协调</strong>等特性</p>
<h3 id="并发垃圾收集"><a href="#并发垃圾收集" class="headerlink" title="并发垃圾收集"></a>并发垃圾收集</h3><blockquote>
<p>Go 语言在 v1.5 中引入了并发的垃圾收集器，该垃圾收集器使用了我们上面提到的<strong>三色抽象和写屏障技术</strong>保证垃圾收集器执行的正确性</p>
</blockquote>
<p>Go 语言的并发垃圾收集器会在扫描对象之前暂停程序做一些标记对象的准备工作，其中包括<strong>启动后台标记的垃圾收集器以及开启写屏障</strong></p>
<h3 id="回收堆目标"><a href="#回收堆目标" class="headerlink" title="回收堆目标"></a>回收堆目标</h3><p>Go 语言 v1.5 引入并发垃圾收集器的同时使用<strong>垃圾收集调步（Pacing）算法计算触发的垃圾收集的最佳时间</strong>，<strong>确保触发的时间既不会浪费计算资源，也不会超出预期的堆大小</strong>。<br><img src="/images/go_garbage_collector/img_4.png" alt="img_4.png"></p>
<h3 id="混合写屏障"><a href="#混合写屏障" class="headerlink" title="混合写屏障"></a>混合写屏障</h3><p>在 Go 语言 v1.7 版本之前，运行时会使用 <strong>Dijkstra 插入写屏障保证强三色不变性</strong>，但是运行时<strong>并没有在所有的垃圾收集根对象上开启插入写屏障</strong>。<br>因为应用程序可能包含成百上千的 Goroutine，而垃圾收集的根对象一般包括全局变量和<strong>栈对象</strong>，如果运行时需要在几百个 Goroutine 的栈上都开启写屏障，会带来巨大的额外开销，<br>所以 Go 团队在实现上选择了<strong>在标记阶段完成时暂停程序、将所有栈对象标记为灰色并重新扫描</strong></p>
<p>Go 语言在 v1.8 <strong>组合 Dijkstra 插入写屏障和 Yuasa 删除写屏障</strong>构成了如下所示的混合写屏障，<strong>该写屏障会将被覆盖的对象标记成灰色并在当前栈没有扫描时将新对象也标记成灰色</strong>：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">writePointer(slot, ptr):</span><br><span class="line">    shade(*slot)</span><br><span class="line">    <span class="keyword">if</span> current stack is grey:</span><br><span class="line">        shade(ptr)</span><br><span class="line">    *slot = ptr</span><br></pre></td></tr></table></figure>
<p>为了移除栈的重扫描过程，除了引入混合写屏障之外，在垃圾收集的标记阶段，<strong>我们还需要将创建的所有新对象都标记成黑色，防止新分配的栈内存和堆内存中的对象被错误地回收</strong>，因为栈内存在标记阶段最终都会变为黑色，所以不再需要重新扫描栈空间。</p>
<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>Go 语言的垃圾收集可以分成清除终止、标记、标记终止和清除四个不同阶段，它们分别完成了不同的工作<br><img src="/images/go_garbage_collector/img_5.png" alt="img.png"></p>
<ol>
<li>清理终止阶段；<ol>
<li><strong>暂停程序</strong>，所有的处理器在这时会进入安全点（Safe point）；</li>
<li>如果当前垃圾收集循环是强制触发的，我们还需要处理还未被清理的内存管理单元；</li>
</ol>
</li>
<li>标记阶段；<ol>
<li>将状态切换至 _<strong>GCmark</strong>、<strong>开启写屏障</strong>、<strong>用户程序协助</strong>（Mutator Assists）并将根对象入队；</li>
<li>恢复执行程序，标记进程和用于协助的用户程序会开始并发标记内存中的对象，写屏障会将被覆盖的指针和新指针都标记成灰色，<strong>而所有新创建的对象都会被直接标记成黑色</strong>；</li>
<li>开始扫描根对象，包括所有 Goroutine 的栈、全局对象以及不在堆中的运行时数据结构，扫描 Goroutine 栈期间会暂停当前处理器；</li>
<li>依次处理灰色队列中的对象，将对象标记成黑色并将它们指向的对象标记成灰色；</li>
<li>使用分布式的终止算法检查剩余的工作，发现标记阶段完成后进入标记终止阶段；</li>
</ol>
</li>
<li>标记终止阶段；<ol>
<li><strong>暂停程序</strong>、将状态切换至 _<strong>GCmarktermination</strong> 并关闭辅助标记的用户程序；</li>
<li>清理处理器上的线程缓存；</li>
</ol>
</li>
<li>清理阶段；<ol>
<li>将状态切换至 _<strong>GCoff</strong> 开始清理阶段，初始化清理状态并<strong>关闭写屏障；</strong></li>
<li><strong>恢复用户程序，所有新创建的对象会标记成白色</strong>；</li>
<li>后台并发清理所有的内存管理单元，<strong>当 Goroutine 申请新的内存管理单元时就会触发清理（惰性清除）</strong>；<br>运行时虽然只会使用 _GCoff、_GCmark 和 _GCmarktermination 三个状态表示垃圾收集的全部阶段，但是在实现上却复杂很多</li>
</ol>
</li>
</ol>
<h3 id="触发时机"><a href="#触发时机" class="headerlink" title="触发时机"></a>触发时机</h3><p><img src="/images/go_garbage_collector/img_6.png" alt="img_1.png"></p>
<h4 id="后台触发"><a href="#后台触发" class="headerlink" title="后台触发"></a>后台触发</h4><p>gcTriggerTime — 如果一定时间内没有触发，就会触发新的循环，该触发条件由 runtime.forcegcperiod 变量控制，默认为 2 分钟；</p>
<h4 id="手动触发"><a href="#手动触发" class="headerlink" title="手动触发"></a>手动触发</h4><p>用户程序会通过 runtime.GC 函数在程序运行期间主动通知运行时执行，该方法在调用时会阻塞调用方直到当前垃圾收集循环完成，在垃圾收集期间也可能会通过 STW 暂停整个程序：</p>
<h4 id="申请内存"><a href="#申请内存" class="headerlink" title="申请内存"></a>申请内存</h4><ol>
<li>当前线程的内存管理单元中不存在空闲空间时，创建微对象和小对象需要调用 runtime.mcache.nextFree <strong>从中心缓存或者页堆中获取新的管理单元，在这时就可能触发垃圾收集</strong>；</li>
<li><strong>当用户程序申请分配 32KB 以上的大对象时，一定会构建 runtime.gcTrigger 结构体尝试触发垃圾收集</strong>；</li>
</ol>
<h3 id="垃圾收集启动"><a href="#垃圾收集启动" class="headerlink" title="垃圾收集启动"></a>垃圾收集启动</h3><ol>
<li>两次调用 runtime.gcTrigger.test 检查是否满足垃圾收集条件；</li>
<li><strong>暂停程序</strong>、在后台<strong>启动用于处理标记任务的工作 Goroutine</strong>、确定所有内存管理单元都被清理以及其他标记阶段开始前的准备工作；</li>
<li>进入标记阶段、准备后台的标记工作、根对象的标记工作以及微对象、恢复用户程序，进入并发扫描和标记阶段；</li>
</ol>
<h3 id="并发扫描与标记辅助"><a href="#并发扫描与标记辅助" class="headerlink" title="并发扫描与标记辅助"></a>并发扫描与标记辅助</h3><ol>
<li>获取当前处理器以及 Goroutine 打包成runtime.gcBgMarkWorkerNode 类型的结构并主动陷入休眠等待唤醒；</li>
<li>根据处理器上的 gcMarkWorkerMode 模式决定扫描任务的策略；</li>
<li>所有标记任务都完成后，调用 runtime.gcMarkDone 方法完成标记阶段；</li>
</ol>
<h4 id="工作池"><a href="#工作池" class="headerlink" title="工作池"></a>工作池</h4><p><img src="/images/go_garbage_collector/img_7.png" alt="img_2.png"><br>4. 写屏障、根对象扫描和栈扫描都会向工作池中增加额外的灰色对象等待处理，而对象的扫描过程会将灰色对象标记成黑色，同时也可能发现新的灰色对象，当工作队列中不包含灰色对象时，整个扫描过程就会结束。<br>5. 为了减少锁竞争，运行时在每个处理器上会保存独立的待扫描工作，然而这会遇到与调度器一样的问题 — 不同处理器的资源不平均，导致部分处理器无事可做，调度器引入了工作窃取来解决这个问题，垃圾收集器也使用了差不多的机制平衡不同处理器上的待处理任务。</p>
<h4 id="写屏障"><a href="#写屏障" class="headerlink" title="写屏障"></a>写屏障</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if writeBarrier.enabled &#123;</span><br><span class="line">  gcWriteBarrier(ptr, val)</span><br><span class="line">&#125; else &#123;</span><br><span class="line">  *ptr = val</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>gcWriteBarrier</code> 该函数会覆盖原来的值并通过 runtime.wbBufFlush <strong>通知垃圾收集器将原值和新值加入当前处理器的工作队列</strong></p>
<h4 id="标记辅助"><a href="#标记辅助" class="headerlink" title="标记辅助"></a>标记辅助</h4><p>为了保证用户程序分配内存的速度不会超出后台任务的标记速度，运行时还引入了标记辅助技术，它遵循一条非常简单并且朴实的原则，<strong>分配多少内存就需要完成多少标记任务</strong>。<br><img src="/images/go_garbage_collector/img_8.png" alt="img_3.png"><br>用户程序辅助标记的核心目的是避免用户程序分配内存影响垃圾收集器完成标记工作的期望时间，它通过维护账户体系保证用户程序不会对垃圾收集造成过多的负担，一旦用户程序分配了大量的内存，该用户程序就会通过辅助标记的方式平衡账本，这个过程会在最后达到相对平衡，保证标记任务在到达期望堆大小时完成。</p>
<h3 id="标记终止"><a href="#标记终止" class="headerlink" title="标记终止"></a>标记终止</h3><h3 id="内存清理"><a href="#内存清理" class="headerlink" title="内存清理"></a>内存清理</h3><blockquote>
<p>用户程序在申请内存时才会惰性回收内存。<br>垃圾收集的清理中包含<strong>对象回收器（Reclaimer）和内存单元回收器</strong>，这两种回收器使用不同的算法清理堆内存：</p>
</blockquote>
<ol>
<li>对象回收器在内存管理单元中查找并释放未被标记的对象，<strong>但是如果 runtime.mspan 中的所有对象都没有被标记，整个单元就会被直接回收</strong>，该过程会被 runtime.mcentral.cacheSpan 或者 runtime.sweepone 异步触发；</li>
<li>内存单元回收器会在内存中查找所有的对象都未被标记的 runtime.mspan，该过程会被 runtime.mheap.reclaim 触发；</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Go 语言为了实现高性能的并发垃圾收集器，使用<strong>三色抽象、并发增量回收、混合写屏障、调步算法以及用户程序协助</strong>等机制将垃圾收集的暂停时间优化至毫秒级以下，从早期的版本看到今天，我们能体会到其中的工程设计和演进，作者觉得研究垃圾收集的是实现原理还是非常值得的。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collecto">go垃圾收集器</a></p>
]]></content>
      <categories>
        <category>go</category>
        <category>内存</category>
      </categories>
      <tags>
        <tag>gc</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka</title>
    <url>/2022/11/11/kafka/</url>
    <content><![CDATA[<h3 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h3><ul>
<li><p>为什么是拉模式</p>
</li>
<li><p>每个partition物理上对应一个文件夹，每个segment对应一个文件，删数据是直接删segment,因此删数据也很快。</p>
</li>
<li><p>存磁盘，append-only 顺序写(读)磁盘 对于机械磁盘，顺序写磁盘比随机写内存还要快</p>
</li>
<li><p>异步刷盘，broker系统crash了可能丢数据</p>
</li>
<li><p>默认异步发送，本地有个缓存，如果想同步发送，调用flush方法，producer宕机了可能丢缓存了的数据</p>
<span id="more"></span></li>
<li><p>producer如何保证消息顺序 query和retry机制</p>
<ul>
<li>设置max.in.flight.requests.per.connection 表示一个producer与broker之间的连接最多同时有几个请求，设置了会影响吞吐量</li>
</ul>
</li>
<li><p>一个partition只能被一个consumer消费</p>
<ul>
<li>容易保证不重复消费数据</li>
<li>保证顺序消费</li>
</ul>
</li>
<li><p>ISR中所有副本都对某记录ack后，leader才会commit某记录，只有commit的记录消费者才能读到</p>
</li>
<li><p>failover后随机从ISR列表中选出一个副本为leader，因此能够保证已经commit的数据都没有丢失。</p>
</li>
</ul>
<h4 id="rebalance"><a href="#rebalance" class="headerlink" title="rebalance"></a>rebalance</h4><p>新成员加入组流程<br><img src="/images/queue/rebalance.png" alt="img.png"></p>
<blockquote>
<p>基于zookeeper watch实现。没有主节点，看到的partition可能不一致，最终造成脑裂，重新分配后，假如其中一个consumer连不上broker<br>没有同步给其他consumer<br>基于Coordinator实现，为每个消费者组选择一个leader，leader通过syncgroup rpc将rebalance分配方案发给coordinator,其他member通过<br>syncgroup rpc向coordinator获取各自被分配的结果。</p>
</blockquote>
<p><strong>如何避免不必要的rebalance</strong></p>
<ul>
<li>第一类非必要 Rebalance 是因为未能及时发送心跳，导致 Consumer 被 “踢出”Group 而引发的。这种情况下我们可以设置 session.timeout.ms 和 heartbeat.interval.ms 的值，来尽量避免rebalance的出现<ul>
<li>最佳实践<ul>
<li>设置 session.timeout.ms = 6s。（超过这个时间，Coordinator 就会认为该 Consumer 已经 “死” 了，从而将其从 Group 中移除，然后开启新一轮 Rebalance）</li>
<li>设置 heartbeat.interval.ms = 2s。</li>
<li>要保证 Consumer 实例在被判定为 “dead” 之前，能够发送至少 3 轮的心跳请求，即 session.timeout.ms &gt;= 3 * heartbeat.interval.ms。</li>
</ul>
</li>
</ul>
</li>
<li>第二类非必要 Rebalance 是 Consumer 消费时间过长导致的，此时，max.poll.interval.ms 参数值设置得比下游最大处理时间稍长一点，避免非预期的 Rebalance。</li>
</ul>
<h4 id="Kafka-如何保证消息不丢失"><a href="#Kafka-如何保证消息不丢失" class="headerlink" title="Kafka 如何保证消息不丢失"></a>Kafka 如何保证消息不丢失</h4><ol>
<li>生产者<ul>
<li>在回调方法中重试，间隔一定时间</li>
</ul>
</li>
<li>消费者 <ul>
<li>关闭自动提交offset，每次在真正消费完消息之后再自己手动提交 offset。</li>
</ul>
</li>
<li>broker<ul>
<li>设置ack=all,表示只有所有 ISR 列表的副本全部收到消息时，生产者才会接收到来自服务器的响应</li>
<li>设置 replication.factor &gt;= 3,保证每个 分区(partition) 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。</li>
<li>设置 min.insync.replicas &gt; 1,这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。</li>
<li>设置 unclean.leader.election.enable = false,当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性。</li>
</ul>
</li>
</ol>
<h3 id="RocketMQ"><a href="#RocketMQ" class="headerlink" title="RocketMQ"></a>RocketMQ</h3><ol>
<li>一个 Topic 分布在多个 Broker上，一个 Broker 可以配置多个 Topic ，它们是多对多的关系.</li>
<li>NameServer其实也是一个 注册中心 ，主要提供两个功能：Broker管理 和 路由信息管理 。集群部署，但是请注意它是 <strong>去中心化</strong> 的.</li>
<li> <strong>单个Broker和所有NameServer保持长连接</strong> ，并且在每隔30秒 Broker 会向所有 Nameserver 发送心跳，心跳包含了自身的 Topic 配置信息</li>
<li>RocketMQ 是不支持自动主从切换的，当主节点挂掉之后，生产者就不能再给这个主节点生产消息了。消费者可以自动切换到从节点进行消费</li>
<li>异步刷盘只有在 Broker 意外宕机的时候会丢失部分数据，可以设置 Broker 的参数 FlushDiskType 来调整刷盘策略(ASYNC_FLUSH 或者 SYNC_FLUSH)</li>
<li>顺序消费和重复消费原理跟kafka一样（分区有序，消费幂等处理）</li>
<li>分布式事务，2pc,事务消息加上事务反查机制.本地事务和存储消息到消息队列才是同一个事务。这样也就产生了<strong>事务的最终一致性</strong>，因为整个过程是异步的，每个系统只要保证它自己那一部分的事务就行了。</li>
<li>使用mmap实现零拷贝，使用数据和索引分离，当消息需要写入时，使用 commitlog <strong>文件顺序写</strong>，当需要定位某个消息时，查询index 文件来定位，从而减少文件IO随机读写的性能损耗</li>
</ol>
<p><img src="/images/queue/img.png" alt="img.png"></p>
<p>在图中最左边说明了红色方块代表被写入的消息，虚线方块代表等待被写入的。左边的生产者发送消息会指定 Topic 、QueueId 和具体消息内容，而在 Broker 中管你是哪门子消息，<br>他直接 全部顺序存储到了 CommitLog。而根据生产者指定的 Topic 和 QueueId 将这条消息本身在 CommitLog 的偏移(offset)，消息本身大小，<br>和tag的hash值存入对应的 ConsumeQueue 索引文件中。而在每个队列中都保存了 ConsumeOffset 即每个消费者组的消费位置(我在架构那里提到了，忘了的同学可以回去看一下)，<br>而消费者拉取消息进行消费的时候只需要根据 ConsumeOffset 获取下一个未被消费的消息就行了。</p>
<h4 id="RocketMQ-不使用-ZooKeeper-作为注册中心的原因，以及自制的-NameServer-优缺点？"><a href="#RocketMQ-不使用-ZooKeeper-作为注册中心的原因，以及自制的-NameServer-优缺点？" class="headerlink" title="RocketMQ 不使用 ZooKeeper 作为注册中心的原因，以及自制的 NameServer 优缺点？"></a>RocketMQ 不使用 ZooKeeper 作为注册中心的原因，以及自制的 NameServer 优缺点？</h4><p>ZooKeeper 作为支持顺序一致性的中间件，在某些情况下，它为了满足一致性，会丢失一定时间内的可用性，RocketMQ 需要注册中心只是为了发现组件地址，<br>在某些情况下，RocketMQ 的注册中心可以出现数据不一致性，这同时也是 NameServer 的缺点，因为 NameServer 集群间互不通信，它们之间的注册信息可能会不一致</p>
<h3 id="kafka与rocketmq对比"><a href="#kafka与rocketmq对比" class="headerlink" title="kafka与rocketmq对比"></a><a href="https://blog.csdn.net/shijinghan1126/article/details/104724407#">kafka与rocketmq对比</a></h3><p>)</p>
<ol>
<li>数据可靠性：<ol>
<li>RocketMQ新增了同步刷盘机制，保证了可靠性；一个RocketMQ实例只有一个partition, 在replication时性能更好。</li>
</ol>
</li>
<li>写入性能：<ol>
<li>RocketMQ写入性能上不如kafka, 主要因为kafka主要应用于日志场景，而RocketMQ应用于业务场景，为了保证消息必达牺牲了性能，且基于线上真实场景没有在RocketMQ层做消息合并，推荐在业务层自己做。</li>
</ol>
</li>
<li>单机支持的队列数：<ol>
<li>RocketMQ支持的队列数远高于kafka支持的partition数，这样RocketMQ可以支持更多的consumer集群。</li>
</ol>
</li>
<li>消息投递的实时性：<ol>
<li>kafka与RocketMQ都支持长轮询，消息投递的延迟在几毫秒内。</li>
</ol>
</li>
<li>消费失败重试：<ol>
<li>RocketMQ支持消费失败重试功能，主要用于第一次调用不成功，后面可调用成功的场景。而kafka不支持消费失败重试。</li>
</ol>
</li>
<li>严格保证消息有序：<ol>
<li>kafka不保证消息有序，RocketMQ可保证严格的消息顺序，即使单台Broker宕机，仅会造成消息发送失败，但不会消息乱序。</li>
</ol>
</li>
<li>定时消息：<br>1、kafka不支持定时消息<br>2、开源版本的RocketMQ仅支持定时级别，定时级别用户可定制</li>
<li>分布式事务消息<br>1、kafka不支持分布式事务消息<br>2、RocketMQ支持分布式事务消息。</li>
<li>消息查询<ol>
<li>RocketMQ支持按消息标识或消息内容查询消息，用于排查消息丢失问题；kafka不支持消息查询。</li>
</ol>
</li>
<li>消息回溯<br>1、kafka可按照消息的offset来回溯消息<br>2、RocketMQ支持按照时间来回溯消息，精度到毫秒，例如从一天的几点几分几秒几毫秒来重新消费消息。</li>
<li>消息并行度:<ol>
<li>kafka的消费并行度等于partition数；RocketMQ的消费并行度等于消费的线程数，不受队列数限制。</li>
</ol>
</li>
<li>消息堆积能力：<br>kafka比RocketMQ的消息堆积能力更强，不过RocketMQ单机也可支持亿级的消息积压能力，这个堆积能力也能够完全满足业务需求。</li>
</ol>
<h4 id="kafka相比RocketMQ的优势"><a href="#kafka相比RocketMQ的优势" class="headerlink" title="kafka相比RocketMQ的优势"></a>kafka相比RocketMQ的优势</h4><p>1、单机吞吐量TPS可上百万，远高于RocketMQ的TPS7万每秒，适用于日志类消息。<br>2、kafka支持多语言的客户端</p>
<h4 id="RocketMQ相比kafka的优势"><a href="#RocketMQ相比kafka的优势" class="headerlink" title="RocketMQ相比kafka的优势"></a>RocketMQ相比kafka的优势</h4><p>1、保证消息不丢（ 数据可靠性达10个9）<br>2、可严格保证消息有序<br>3、支持分布式事务消息 todo p1<br>4、支持按时间做消息回溯（可精确到毫秒级）<br>5、支持按标识和内容查询消息，用于排查丢消息<br>6、支持消费失败重试<br>7、可支持更多的partition, 即更多的消费线程数</p>
]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
        <tag>中间件</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式一致性</title>
    <url>/2022/11/12/%E5%88%86%E5%B8%83%E5%BC%8F%E4%B8%80%E8%87%B4%E6%80%A7/</url>
    <content><![CDATA[<p>一致性</p>
<ul>
<li>共识算法 <ul>
<li>一旦一个值被确定了，所有人都认同 </li>
<li>共识算法不等于一致性，一般是强一致性<span id="more"></span>
<h2 id="raft"><a href="#raft" class="headerlink" title="raft"></a>raft</h2><blockquote>
<p>关键词RSM（replicate state machine） Log  RPC<br>关键角色 leader follower candidate<br>rpc -&gt; Log -&gt; RSM</p>
</blockquote>
</li>
</ul>
</li>
<li>对于冲突的log，raft完全依靠leader判断，不会考虑follow</li>
<li>只直接commit本term内产生的log</li>
<li>写入后读follower不一定能马上读到，可以在读follower时,查询leader的commitIndex,并将自己的commitIndex置位leader的commitIndex,然后应用状态机，最后查询返回结果</li>
</ul>
<p>###集群成员变更<br><img src="/images/consistence/img.png" alt="img.png"><br>在 Raft 中，集群先切换到一个过渡的配置，我们称之为共同一致（joint consensus)；一旦共同一致已经被提交了，那么系统就切换到新的配置上。共同一致是老配置和新配置的结合：</p>
<ul>
<li><p>日志条目被复制给集群中新、老配置的所有服务器。</p>
</li>
<li><p>新、旧配置的服务器都可以成为领导人。</p>
</li>
<li><p>达成一致（针对选举和提交）需要分别在两种配置上获得大多数的支持。</p>
</li>
<li><p>一旦一个服务器将新的配置日志条目增加到它的日志中，他就会用这个配置来做出未来所有的决定（服务器总是使用最新的配置，无论他是否已经被提交）。这意味着领导人要使用 <strong>C-old,new 的规则来决定日志条目 C-old,new 什么时候需要被提交</strong>。</p>
</li>
<li><p>一旦 C-old,new 被提交，那么无论是 C-old 还是 C-new，如果不经过另一个配置的允许都不能单独做出决定，并且领导人完全特性保证了只有拥有 C-old,new 日志条目的服务器才有可能被选举为领导人。</p>
</li>
<li><p><em>因此不会出现图中的状态，即图中至少server2或者server1也会转换到cold,new状态，因此可以避免同时选出两个leader的情况发生。</em>*</p>
</li>
<li><p>相比于paxos没有两阶段提交 </p>
</li>
</ul>
<h3 id="master选举规则"><a href="#master选举规则" class="headerlink" title="master选举规则"></a>master选举规则</h3><ul>
<li>raft选举时会检查log是否outdated,最有最新的才能当选上leader</li>
<li>选举需要多数派投票，committed也已经在多数派中，因此新leader一定持有committed log</li>
<li>Leader只能推进commit index来提交当前term的已经复制到大多数服务器上的日志，旧term日志的提交要等到<br>提交当前term的日志来间接提交（log index 小于 commit index的日志被间接提交）。</li>
<li>领导人完全特性保证了领导人一定拥有所有已经被提交的日志条目，但是在他任期开始的时候<br>，他可能不知道哪些是已经被提交的。为了知道这些信息，他需要在他的任期里提交一条日志条目。<br>Raft 中通过领导人在任期开始的时候提交一个空白的没有任何操作的日志条目到日志中去来实现。<br>形式验证（计算机穷举状态）保证算法的正确性</li>
</ul>
<p>简单实现了<a href="https://github.com/Xuwudong/myraft">raft算法</a></p>
<h4 id="写时复制"><a href="#写时复制" class="headerlink" title="写时复制"></a>写时复制</h4><blockquote>
<p>写时复制（Copy-on-write，COW），有时也称为隐式共享（implicit sharing）。COW 将复制操作推迟到第一次写入时进行：在创建一个新副本时，<br>不会立即复制资源，而是共享原始副本的资源；当修改时再执行复制操作。通过这种方式共享资源，可以显著减少创建副本时的开销，以及节省资源；同时，资源修改操作会增加少量开销。</p>
</blockquote>
<h3 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h3><ul>
<li>集群成员变更</li>
</ul>
<h2 id="paxos"><a href="#paxos" class="headerlink" title="paxos"></a>paxos</h2><p>proposer acceptor learner</p>
<p>两个rpc请求</p>
<h3 id="prepare请求"><a href="#prepare请求" class="headerlink" title="prepare请求"></a>prepare请求</h3><blockquote>
<p>proposer  –prepare(Mn, Vn) –&gt; acceptor</p>
</blockquote>
<ol>
<li>Acceptor向Proposer承诺,<strong>保证不再批准（accept）任何编号小于Mn的提案。</strong></li>
<li>如果 Acceptor已经批准过任何提案,那么其就向Proposer反馈当前该Acceptor已经批准的编号小于Mn,但为最大编号的那个提案的值。</li>
</ol>
<ul>
<li>proposer收到返回的提案值Va，为了让系统尽快达成一致，将Vn改成Va,发起accept请求</li>
</ul>
<h3 id="accept请求"><a href="#accept请求" class="headerlink" title="accept请求"></a>accept请求</h3><blockquote>
<p>proposer  –accept(Mn, Vn) –&gt; acceptor</p>
</blockquote>
<ol>
<li>Acceptor可以在任何时候响应 Accept请求，但是只有在尚未响应任意大于Mn的prepare请求的情况下，它才可以接受Mn的提案。(即prepare请求第一点)</li>
</ol>
]]></content>
      <categories>
        <category>一致性</category>
        <category>共识算法</category>
      </categories>
      <tags>
        <tag>一致性</tag>
        <tag>共识算法</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql</title>
    <url>/2022/11/17/mysql/</url>
    <content><![CDATA[<ul>
<li><p>是否分片不是取决于数据量千万条。而是取决于主节点写入速度是不是太高导致主从延迟太大，<br>或者主节点机器空间不够了，我司最大2.8T</p>
<h2 id="主从同步"><a href="#主从同步" class="headerlink" title="主从同步"></a>主从同步</h2></li>
<li><p>主从复制方式 </p>
</li>
<li><p>一致性保证</p>
</li>
<li><p>对于可重复读，查询只承认在事务启动前就已经提交完成的数据； 对于读提交，查询只承认在语句启动前就已经提交完成的数据；<br>而当前读，总是读取已经提交完成的最新版本。</p>
</li>
<li><p>间隙锁主要用来解决幻读的问题，在读已提交的隔离级别下，并且是“当前读”，才会产生幻读。<br>InnoDB在可重复读的事务隔离级别下，会有间隙锁；也就是说，在可重复读级别下，是不会出现幻读现象的。<br>间隙锁之间不存在冲突关系。与间隙锁冲突的是“往这个间隙插入一个记录”的操作。 </p>
</li>
<li><p>dml语句查询时需要获取表的MDL锁，ddl语句执行时也要获取表的MDL锁。后面的dml语句需要等待前面的ddl语句执行完才能继续执行，因此在业务高峰<br>期操作ddl,可能导致连接暴涨，解决办法之一是ddl语句加上超时和重试</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> tbl_name WAIT N <span class="keyword">add</span> <span class="keyword">column</span> ...</span><br></pre></td></tr></table></figure></li>
<li><p>binlog存储格式Statement只会记录SQL语句，但是并不能保证所有情况下这些语句在从库上能够正确的被重放出来。因为可能顺序不对。</p>
</li>
<li><p>MySQL什么时候会记录binlog呢？是在事务提交的时候，并不是按照语句的执行顺序来记录，当记录完binlog之后 ，<br>就会通知底层的存储引擎提交事务，所以有可能因为语句顺序错误导致语句出错。</p>
<h3 id="undo-log"><a href="#undo-log" class="headerlink" title="undo log"></a>undo log</h3></li>
</ul>
<h3 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h3><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><ul>
<li><p>联合索引的最左匹配原则，在遇到范围查询（如 &gt;、&lt;）的时候，就会停止匹配，也就是范围查询的字段可以用到联合索引，<br>但是在范围查询字段的后面的字段无法用到联合索引。注意，对于 &gt;=、&lt;=、BETWEEN、like 前缀匹配的范围查询，并不会停止匹配</p>
</li>
<li><p>而 MySQL 5.6 引入的<strong>索引下推优化</strong>（index condition pushdown)， 可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，<br>直接过滤掉不满足条件的记录，减少回表次数。</p>
</li>
<li><p>type 字段就是描述了找到所需数据时使用的扫描方式是什么，常见扫描类型的执行效率从低到高的顺序为：</p>
<ul>
<li>All（全表扫描）；</li>
<li>index（全索引扫描）；</li>
<li>range（索引范围扫描）；</li>
<li>ref（非唯一索引扫描）；</li>
<li>eq_ref（唯一索引扫描）；</li>
<li>const（结果只有一条的主键或唯一索引扫描）。</li>
</ul>
</li>
</ul>
<p>const 是与常量进行比较，查询效率会更快，而 eq_ref 通常用于多表联查中。</p>
<ul>
<li><p>InnoDB 的数据是按「<strong>数据页</strong>」为单位来读写的，默认数据页大小为 16 KB。每个数据页之间通过<strong>双向链表</strong>的形式组织起来，物理上不连续，但是逻辑上连续。<br>b</p>
</li>
<li><p>数据页内包含用户记录，每个记录之间用<strong>单向链表</strong>的方式组织起来，为了加快在数据页内高效查询记录，设计了一个<strong>页目录，页目录存储各个槽（分组)<strong>，且主键值是有序的，于是可以通过</strong>二分查找法</strong>的方式进行检索从而提高效率。</p>
</li>
<li><p>为了高效查询记录所在的数据页，InnoDB 采用 b+ 树作为索引，<strong>每个节点都是一个数据页</strong>。</p>
</li>
<li><p>MySQL 默认的存储引擎 InnoDB 采用的是 B+ 作为索引的数据结构，原因有：</p>
<ul>
<li>B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，<strong>查询底层节点的磁盘 I/O次数会更少</strong>。</li>
<li>B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树<strong>在插入、删除的效率都更高</strong>，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；</li>
<li>B+ 树叶子节点之间<strong>用链表连接了起来，有利于范围查询</strong>，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。</li>
</ul>
</li>
<li><p>如果数据库表中的字段只有主键+二级索引，那么即使使用了左模糊匹配，也不会走全表扫描（type=all），而是走全扫描二级索引树(type=index)。</p>
</li>
</ul>
<h3 id="online-ddl"><a href="#online-ddl" class="headerlink" title="online ddl"></a>online ddl</h3><p>我给你简单描述一下引入了 Online DDL 之后，重建表的流程：</p>
<ol>
<li>建立一个临时文件，扫描表 A 主键的所有数据页；</li>
<li>用数据页中表 A 的记录生成 B+ 树， 存储到临时文件中；</li>
<li>生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；</li>
<li>临时文件生成后， 将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；</li>
<li>用临时文件替换表 A 的数据文件。<br><img src="/images/mysql/img.png" alt="img.png"><br>本质上是 Copy-On-Write 的思想，Redis 的 Replication 中也会用到</li>
</ol>
<p>// 主备切换</p>
<h3 id="基于位点的主备切换"><a href="#基于位点的主备切换" class="headerlink" title="基于位点的主备切换"></a>基于位点的主备切换</h3><p>当我们把节点 B 设置成节点 A’的从库的时候，需要执行一条 change master 命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CHANGE MASTER TO </span><br><span class="line">MASTER_HOST=$host_name </span><br><span class="line">MASTER_PORT=$port </span><br><span class="line">MASTER_USER=$user_name </span><br><span class="line">MASTER_PASSWORD=$password </span><br><span class="line">MASTER_LOG_FILE=$master_log_name </span><br><span class="line">MASTER_LOG_POS=$master_log_pos</span><br></pre></td></tr></table></figure>
<p>最后两个参数 MASTER_LOG_FILE 和 MASTER_LOG_POS 表示，要从主库的 master_log_name 文件的 master_log_pos 这个位置的日志继续同步。而这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量。<br>问题：相同的日志，主库A 的位点和 备库A’的位点是不同的。<br>考虑到切换过程中不能丢数据，所以我们找位点的时候，总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库 B 上已经执行过的事务。</p>
<p>一种取同步位点的方法是这样的：</p>
<ol>
<li><p>等待新主库 A’把中转日志（relay log）全部同步完成；</p>
</li>
<li><p>在 A’上执行 show master status 命令，得到当前 A’上最新的 File 和 Position；</p>
</li>
<li><p>取原主库 A 故障的时刻 T；</p>
</li>
<li><p>用 mysqlbinlog 工具解析 A’的 File，得到 T 时刻的位点。</p>
</li>
<li><p>缺点：需要主动判断错误跳过已经执行的事务</p>
</li>
</ol>
<h3 id="GTID"><a href="#GTID" class="headerlink" title="GTID"></a>GTID</h3><p>GTID 的全称是 Global Transaction Identifier，也就是全局事务 ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。</p>
<h3 id="基于-GTID-的主备切换"><a href="#基于-GTID-的主备切换" class="headerlink" title="基于 GTID 的主备切换"></a>基于 GTID 的主备切换</h3><p>在 GTID 模式下，备库 B 要设置为新主库 A’的从库的语法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CHANGE MASTER TO </span><br><span class="line">MASTER_HOST=$host_name </span><br><span class="line">MASTER_PORT=$port </span><br><span class="line">MASTER_USER=$user_name </span><br><span class="line">MASTER_PASSWORD=$password </span><br><span class="line">master_auto_position=1</span><br></pre></td></tr></table></figure>
<p> 其中，master_auto_position=1 就表示这个主备关系使用的是 GTID 协议。可以看到，前面让我们头疼不已的 MASTER_LOG_FILE 和 MASTER_LOG_POS 参数，已经不需要指定了。<br> 我们把现在这个时刻，实例 A’的 GTID 集合记为 set_a，实例 B 的 GTID 集合记为 set_b。接下来，我们就看看现在的主备切换逻辑。<br>我们在实例 B 上执行 start slave 命令，取 binlog 的逻辑是这样的：</p>
<ol>
<li>实例 B 指定主库 A’，基于主备协议建立连接。</li>
<li>实例 B 把 set_b 发给主库 A’。</li>
<li>实例 A’算出 set_a 与 set_b 的差集，也就是所有存在于 set_a，但是不存在于 set_b 的 GTID 的集合，判断 A’本地是否包含了这个差集需要的所有 binlog 事务。<ol>
<li>如果不包含，表示 A’已经把实例 B 需要的 binlog 给删掉了，直接返回错误；</li>
<li>如果确认全部包含，A’从自己的 binlog 文件里面，找出第一个不在 set_b 的事务，发给 B；</li>
</ol>
</li>
<li>之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行。</li>
</ol>
<p>业务高峰期时，考虑到要避免新增索引对主库性能造成的影响，我们可以先在备库加索引，然后再切换。</p>
<h2 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h2><h3 id="处理主从不一致的方案"><a href="#处理主从不一致的方案" class="headerlink" title="处理主从不一致的方案"></a>处理主从不一致的方案</h3><ul>
<li>强制走主库方案；</li>
<li>sleep 方案；</li>
<li>判断主备无延迟方案；</li>
<li>配合 semi-sync 方案；</li>
<li>等主库位点方案；</li>
<li>等 GTID 方案。</li>
</ul>
<h3 id="判断主备无延迟方案"><a href="#判断主备无延迟方案" class="headerlink" title="判断主备无延迟方案"></a>判断主备无延迟方案</h3><ul>
<li>第一种确保主备无延迟的方法是，每次从库执行查询请求前，<strong>先判断 seconds_behind_master 是否已经等于 0</strong>。如果还不等于 0 ，<br>那就必须等到这个参数变为 0 才能执行查询请求。缺点：单位是秒，不够精确</li>
<li>第二种方法，对比主从位点确保主备无延迟</li>
<li>第三种方法，对比主从 GTID 集合确保主备无延迟<br>缺点：上面判断主备无延迟的逻辑，是“备库收到的日志都执行完成了”。但是，从 binlog 在主备之间状态的分析中，不难看出还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。</li>
</ul>
<h3 id="配合-semi-sync-方案"><a href="#配合-semi-sync-方案" class="headerlink" title="配合 semi-sync 方案"></a>配合 semi-sync 方案</h3><p>semi-sync 做了这样的设计：</p>
<ol>
<li>事务提交的时候，主库把 binlog 发给从库；</li>
<li>从库收到 binlog 以后，发回给主库一个 ack，表示收到了；</li>
<li>主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。<br>可以避免主库挂了，binlog没有同步到从库的数据丢失情况<br>缺点：</li>
</ol>
<ul>
<li>一主多从的时候，在某些从库执行查询请求会存在过期读的现象；</li>
<li>在持续延迟的情况下，可能出现过度等待的问题。</li>
</ul>
<h3 id="等主库位点方案"><a href="#等主库位点方案" class="headerlink" title="等主库位点方案"></a>等主库位点方案</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select master_pos_wait(file, pos[, timeout]);</span><br></pre></td></tr></table></figure>
<p>这个命令正常返回的结果是一个正整数 M，表示从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务。<br>查询逻辑：</p>
<ol>
<li>trx1 事务更新完成后，马上执行 show master status 得到当前主库执行到的 File 和 Position；</li>
<li>选定一个从库执行查询语句；</li>
<li>在从库上执行 select master_pos_wait(File, Position, 1)；</li>
<li>如果返回值是 &gt;=0 的正整数，则在这个从库执行查询语句；</li>
<li>否则，到主库执行查询语句。（做好限流）</li>
</ol>
<p>缺点：需要主动查询主库位点</p>
<h3 id="等-GTID-方案"><a href="#等-GTID-方案" class="headerlink" title="等 GTID 方案"></a>等 GTID 方案</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select wait_for_executed_gtid_set(gtid_set, 1);</span><br></pre></td></tr></table></figure>
<p>这条命令的逻辑是：等待，直到这个库执行的事务中包含传入的 gtid_set，返回 0；超时返回 1。</p>
<p>这时，等 GTID 的执行流程就变成了：</p>
<ol>
<li>trx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid1；</li>
<li>选定一个从库执行查询语句；</li>
<li>在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；</li>
<li>如果返回值是 0，则在这个从库执行查询语句；</li>
<li>否则，到主库执行查询语句。</li>
</ol>
<h2 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h2><p>MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的slave(取second_behind_master的最小的master)提升为新的master，<br>然后将所有其他的slave重新指向新的master，整个故障转移过程对应用程序完全透明。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>中间件</tag>
        <tag>MySQL</tag>
        <tag>DB</tag>
      </tags>
  </entry>
  <entry>
    <title>redis</title>
    <url>/2022/11/17/redis/</url>
    <content><![CDATA[<ul>
<li>redis集群的master选举机制<br>首先会从哨兵集群中选举出来一个master作用于集群中的主备切换，哨兵自身选举算法为raft算法。<ul>
<li>当redis集群中的master因为某些原因挂掉的时候，此时如果该master下有多个slave，怎么确定哪一个可以晋为master，在此master的选举是有条件的<ol>
<li>和master断开的时间，如果副本与主服务器断开连接的时间超过已配置主服务器超时的十倍，该slave不会成为master</li>
<li>每个slave都是有优先级的，会优先选举优先级比较高的，redis.conf中配置的replica-priority</li>
<li>其次当优先级一致的情况下，会选举数据同步最多的。</li>
<li>当上述两个条件均满足的时候，哪一个节点最先启动，优先成为master（slaves中runid最小的）</li>
</ol>
</li>
</ul>
</li>
</ul>
<h3 id="HashTag用户自定义散列key"><a href="#HashTag用户自定义散列key" class="headerlink" title="HashTag用户自定义散列key"></a>HashTag用户自定义散列key</h3><p>使用不当容易产生数据倾斜和访问热点</p>
<p>为什么用skiplist 不用红黑树实现zset，因为skiplist实现比较简单</p>
<ul>
<li>缓存穿透指的是数据库本就没有这个数据，请求直奔数据库，缓存系统形同虚设。<ul>
<li>给不存在的数据也设置缓存，值为空</li>
</ul>
</li>
<li>缓存击穿(失效)指的是数据库有数据，缓存本应该也有数据，但是缓存过期了，Redis 这层流量防护屏障被击穿了，请求直奔数据库。<ul>
<li>访问db加锁，保证只有一个请求到db,没有获取锁的等待一会再获取数据</li>
</ul>
</li>
<li>缓存雪崩指的是大量的热点数据无法在 Redis 缓存中处理(大面积热点数据缓存失效、Redis 宕机)，流量全部打到数据库，导致数据库极大压力。<ul>
<li>缓存设置随机值</li>
<li>db开启连接限流</li>
<li>构建高可用缓存系统</li>
</ul>
</li>
</ul>
<h3 id="AOF-记录命令"><a href="#AOF-记录命令" class="headerlink" title="AOF 记录命令"></a>AOF 记录命令</h3><ul>
<li>写后日志 先写数据，再写日志 <ul>
<li>优点：<strong>不会阻塞当前的写操作</strong>；不用记录错误日志</li>
<li>缺点： 写完数据后宕机了，丢失数据；每次刷盘，影响写入性能<h4 id="三种写会策略"><a href="#三种写会策略" class="headerlink" title="三种写会策略"></a>三种写会策略</h4></li>
</ul>
</li>
</ul>
<ol>
<li>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</li>
<li>Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</li>
<li>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。<br><img src="/images/redis/img.png" alt="img.png"><h4 id="AOF重写机制"><a href="#AOF重写机制" class="headerlink" title="AOF重写机制"></a>AOF重写机制</h4>解决AOF文件过大带来的问题</li>
</ol>
<p>AOF 重写机制就是在重写时，Redis 根据数据库的现状创建一个新的 AOF 文件，也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。</p>
<ul>
<li>一个拷贝，两处日志<ul>
<li>每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志（AOF日志缓冲区，AOF重写日志缓冲区）保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的进程进行数据重写，所以，这个过程并不会阻塞主线程。<br><img src="/images/redis/img_1.png" alt="img_1.png"></li>
</ul>
</li>
</ul>
<h3 id="RDB-记录数据"><a href="#RDB-记录数据" class="headerlink" title="RDB 记录数据"></a>RDB 记录数据</h3><p>Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。</p>
<p>bgsave 子进程是由主线程 fork 生成的，<strong>可以共享主线程的所有内存数据</strong>。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。</p>
<p>Redis <strong>就会借助操作系统提供的写时复制技术</strong>（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。</p>
<p><img src="/images/redis/rdb.png" alt="img.png"></p>
<h3 id="主从复制中两个-Buffer-replication-buffer-、repl-backlog-buffer-有什么区别？"><a href="#主从复制中两个-Buffer-replication-buffer-、repl-backlog-buffer-有什么区别？" class="headerlink" title="主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？"></a>主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？</h3><p>replication buffer 、repl backlog buffer 区别如下：</p>
<ul>
<li>出现的阶段不一样：<ul>
<li>repl backlog buffer 是在增量复制阶段出现，一个主节点只分配一个 repl backlog buffer；</li>
<li>replication buffer 是在全量复制阶段和增量复制阶段都会出现，主节点会给每个新连接的从节点，分配一个 replication buffer；</li>
</ul>
</li>
<li>这两个 Buffer 都有大小限制的，当缓冲区满了之后，发生的事情不一样：<ul>
<li>当 repl backlog buffer 满了，因为是环形结构，会直接覆盖起始位置数据;</li>
<li>当 replication buffer 满了，会导致连接断开，删除缓存，从节点重新连接，重新开始全量复制。</li>
</ul>
</li>
</ul>
<h1 id><a href="#" class="headerlink" title></a></h1><p><a href="https://fanlv.fun/2021/02/10/reids-action/">https://fanlv.fun/2021/02/10/reids-action/</a></p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>中间件</tag>
        <tag>redis</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title>tcp</title>
    <url>/2022/11/18/tcp/</url>
    <content><![CDATA[<h3 id="状态机"><a href="#状态机" class="headerlink" title="状态机"></a>状态机</h3><h3 id="半连接队列-全连接队列"><a href="#半连接队列-全连接队列" class="headerlink" title="半连接队列 全连接队列"></a>半连接队列 全连接队列</h3><h3 id="SYN-Flood攻击"><a href="#SYN-Flood攻击" class="headerlink" title="SYN Flood攻击"></a>SYN Flood攻击</h3><h4 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h4><h3 id="为什么TIME-WAIT要等两个MSL才到达CLOSED关闭状态"><a href="#为什么TIME-WAIT要等两个MSL才到达CLOSED关闭状态" class="headerlink" title="为什么TIME_WAIT要等两个MSL才到达CLOSED关闭状态"></a>为什么TIME_WAIT要等两个MSL才到达CLOSED关闭状态</h3><h2 id="重传机制"><a href="#重传机制" class="headerlink" title="重传机制"></a>重传机制</h2><h3 id="快重传"><a href="#快重传" class="headerlink" title="快重传"></a>快重传</h3><h3 id="RTT、RTO的计算"><a href="#RTT、RTO的计算" class="headerlink" title="RTT、RTO的计算"></a>RTT、RTO的计算</h3><h3 id="SACK、DSACK方法"><a href="#SACK、DSACK方法" class="headerlink" title="SACK、DSACK方法"></a>SACK、DSACK方法</h3><h2 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h2><h3 id="糊涂窗口综合症"><a href="#糊涂窗口综合症" class="headerlink" title="糊涂窗口综合症"></a>糊涂窗口综合症</h3><h3 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h3><p>ACK 报文是不会重传的</p>
<h4 id="如果已经建立了连接，但是服务端的进程崩溃会发生什么？"><a href="#如果已经建立了连接，但是服务端的进程崩溃会发生什么？" class="headerlink" title="如果已经建立了连接，但是服务端的进程崩溃会发生什么？"></a>如果已经建立了连接，但是服务端的进程崩溃会发生什么？</h4><p>TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，<br>于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。</p>
]]></content>
      <categories>
        <category>tcp</category>
      </categories>
      <tags>
        <tag>tcp</tag>
      </tags>
  </entry>
  <entry>
    <title>microservice</title>
    <url>/2022/11/19/microservice/</url>
    <content><![CDATA[<p>限流<br>这篇文章介绍实现限流的几种方式，主要是窗口算法和桶算法，两者各有优势。</p>
<p>窗口算法实现简单，逻辑清晰，可以很直观的得到当前的 QPS 情况，但是会有时间窗口的临界突变问题，而且不像桶一样有队列可以缓冲。<br>桶算法虽然稍微复杂，不好统计 QPS 情况，但是桶算法也有优势所在。<br>漏桶模式消费速率恒定，可以很好的保护自身系统，可以对流量进行整形，但是面对突发流量不能快速响应。<br>令牌桶模式可以面对突发流量，但是启动时会有缓慢加速的过程，不过常见的开源工具中已经对此优化。<br><a href="https://www.wdbyte.com/java/rate-limiter.html#_7-3-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E9%99%90%E6%B5%81">https://www.wdbyte.com/java/rate-limiter.html#_7-3-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E9%99%90%E6%B5%81</a></p>
]]></content>
      <tags>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title>es</title>
    <url>/2022/11/19/es/</url>
    <content><![CDATA[<h3 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h3><h3 id="分布式"><a href="#分布式" class="headerlink" title="分布式"></a>分布式</h3><h4 id="分片"><a href="#分片" class="headerlink" title="分片"></a>分片</h4><ul>
<li>索引分散保存在一个或多个分片上，索引实际上是指向一个或多个物理分片的逻辑命名空间</li>
<li>一个分片是一个Lucene实例，以及它本事就是一个完整的搜索引擎</li>
<li>文档被存储和索引到分片内，但应用程序是直接合索引而不是分片进行交互</li>
<li>es是利用分片将数据分发到集群内各个节点上</li>
</ul>
<h3 id="副本"><a href="#副本" class="headerlink" title="副本"></a>副本</h3><ul>
<li>分片有主分片和副本分片之分，一个副本分片只是一个主分片的拷贝，高可用的保证<h3 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h3><blockquote>
<p>写操作需要所有副本都写成功后才返回？</p>
</blockquote>
<h3 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h3></li>
</ul>
<h4 id="游标查询（Scroll）"><a href="#游标查询（Scroll）" class="headerlink" title="游标查询（Scroll）"></a>游标查询（Scroll）</h4><ul>
<li>**<font color="#FF000">可以解决深分页问题</font>**。获取某个时间点的快照，在快照过期前不需要重复查询，也不用对结果做全局排序</li>
<li>过期前数据更新快照不会更新</li>
</ul>
<h3 id="近实时性-refresh操作"><a href="#近实时性-refresh操作" class="headerlink" title="近实时性-refresh操作"></a>近实时性-refresh操作</h3><p>当一个文档写入Lucene后是不能被立即查询到的，Elasticsearch提供了一个refresh操作，会定时地调用lucene的reopen(新版本为openIfChanged)为内存<br>中新写入的数据生成一个新的segment，此时被处理的文档均可以被检索到。refresh操作的时间间隔由refresh_interval参数控制，默认为1s,<br>当然还可以在写入请求中带上refresh表示写入后立即refresh，另外还可以调用refresh API显式refresh。</p>
<h3 id="数据可靠性"><a href="#数据可靠性" class="headerlink" title="数据可靠性"></a>数据可靠性</h3><ol>
<li><p>引入translog<br>当一个文档写入Lucence后是存储在内存中的，即使执行了refresh操作仍然是在文件系统缓存中，如果此时服务器宕机，那么这部分数据将会丢失。为此ES增加了translog， 当进行文档写操作时会先将文档写入Lucene，然后写入一份到translog，写入translog是落盘的(如果对可靠性要求不是很高，也可以设置异步落盘，可以提高性能，由配置index.translog.durability和index.translog.sync_interval控制)，这样就可以防止服务器宕机后数据的丢失。由于translog是追加写入，因此性能比较好。与传统的分布式系统不同，这里是先写入Lucene再写入translog，原因是写入Lucene可能会失败，为了减少写入失败回滚的复杂度，因此先写入Lucene.</p>
</li>
<li><p>flush操作<br>另外每30分钟或当translog达到一定大小(由index.translog.flush_threshold_size控制，默认512mb), ES会触发一次flush操作，此时ES会先执行refresh操作将buffer中的数据生成segment，然后调用lucene的commit方法将所有内存中的segment fsync到磁盘。此时lucene中的数据就完成了持久化，会清空translog中的数据(6.x版本为了实现sequenceIDs,不删除translog)<br><img src="/images/es/img.png" alt="img.png"></p>
</li>
<li><p>merge操作<br>由于refresh默认间隔为1s中，因此会产生大量的小segment，为此ES会运行一个任务检测当前磁盘中的segment，对符合条件的segment进行合并操作，减少lucene中的segment个数，提高查询速度，降低负载。不仅如此，merge过程也是文档删除和更新操作后，旧的doc真正被删除的时候。用户还可以手动调用_forcemerge API来主动触发merge，以减少集群的segment个数和清理已删除或更新的文档。</p>
</li>
<li><p>多副本机制<br>另外ES有多副本机制，一个分片的主副分片不能分片在同一个节点上，进一步保证数据的可靠性。</p>
</li>
</ol>
<h3 id="写入流程"><a href="#写入流程" class="headerlink" title="写入流程"></a>写入流程</h3><p>ES的任意节点都可以作为协调节点(coordinating node)接受请求，当协调节点接受到请求后进行一系列处理，然后通过_routing字段找到对应的primary shard，并将请求转发给primary shard, primary shard完成写入后，将写入并发发送给各replica， raplica执行写入操作后返回给primary shard， primary shard再将请求返回给协调节点。大致流程如下图：<br><img src="/images/es/write.png" alt="write.png"></p>
<ol>
<li>判断操作类型</li>
<li>Parse Doc</li>
<li>更新mapping</li>
<li>获取sequenceId和Version </li>
<li><strong>写入lucene</strong></li>
<li><strong>write Translog</strong></li>
<li><strong>Flush translog</strong></li>
</ol>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://elasticsearch.cn/article/13533">https://elasticsearch.cn/article/13533</a></p>
]]></content>
      <categories>
        <category>es</category>
        <category>搜索</category>
        <category>中间件</category>
      </categories>
      <tags>
        <tag>中间件</tag>
        <tag>es</tag>
        <tag>搜索</tag>
      </tags>
  </entry>
  <entry>
    <title>系统设计</title>
    <url>/2022/11/20/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<h3 id="短链接"><a href="#短链接" class="headerlink" title="短链接"></a>短链接</h3><blockquote>
<p><a href="https://soulmachine.gitbooks.io/system-design/content/cn/tinyurl.html">完整版</a></p>
</blockquote>
<ul>
<li>短链接长度理论上只用7个字符即可映射到所有网页数，将64位整数装换成字符串即可</li>
<li>为了区分生成短链接的来源，用户等，采取一对多映射</li>
<li>hash生成64位整数存在冲突，没办法。使用分布式ID生成器生成短链接地址</li>
<li>以短链接作为key,长链接作为value存储</li>
<li>为了统计短标题被点击的次数，使用302临时重定向</li>
<li>预防攻击， 使用Redis反向存储（长链接：短链接）。一个转换请求打过来，Redis有缓存就直接返回短链接，避免ID被耗尽。<span id="more"></span>
<h3 id="定时任务调度器"><a href="#定时任务调度器" class="headerlink" title="定时任务调度器"></a>定时任务调度器</h3><blockquote>
<p><a href="https://soulmachine.gitbooks.io/system-design/content/cn/task-scheduler.html">完整版</a></p>
</blockquote>
</li>
<li>基于DelayQueue实现，基于堆，复杂度logN<ul>
<li>take（） while(true) 循环，leader只休眠堆顶元素执行时间与当前时间的差值，其他线程无限期休眠。</li>
<li>put()  offer之后，peek一下如果是放进去的元素，说明当前定时任务应该最先执行，将leader置位null，唤醒（信号量notify）一个线程，让其去拿最新的定时任务。</li>
</ul>
</li>
<li>ScheduledExecutorService，JDK 的 ScheduledExecutorService 本质上仍然是一个 DelayQueue，但是任务是通过多线程的方式进行。</li>
<li>时间轮 TODO<a href="https://github.com/netty/netty/blob/4.1/common/src/main/java/io/netty/util/HashedWheelTimer.java">开源实现</a><br><a href="https://xie.infoq.cn/article/9146da561960e2cb0a5eb14b2">时间片详解</a><ul>
<li>添加任务o(1),高性能，吞吐高，只有一个线程轮询，无锁竞争，避免线程上下文切换开销</li>
<li>时效性比较差，误差能够在 100ms 左右</li>
</ul>
</li>
<li>go 定时器实现<ul>
<li>与Java不同的是，go中的线程数量比较少，没有专门启动一个线程获取，触发是通过调度器和监控系统调用netpoll()轮询是否有到达的定时任务发生 </li>
<li>通信：使用管道进行通信中断阻塞在netpoll()中的线程,让网络轮询器立刻返回并让运行时检查是否有需要触发的计时器。</li>
</ul>
</li>
</ul>
<h3 id="api限速"><a href="#api限速" class="headerlink" title="api限速"></a>api限速</h3><h4 id="令牌桶"><a href="#令牌桶" class="headerlink" title="令牌桶"></a><a href="https://zhuanlan.zhihu.com/p/20872901">令牌桶</a></h4><ul>
<li>算法：<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">access</span><span class="params">(String userId)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    String key = genKey(userId);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> (Jedis jedis = jedisPool.getResource()) &#123;</span><br><span class="line">        Map&lt;String, String&gt; counter = jedis.hgetAll(key);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (counter.size() == <span class="number">0</span>) &#123;</span><br><span class="line">            TokenBucket tokenBucket = <span class="keyword">new</span> TokenBucket(System.currentTimeMillis(), limit - <span class="number">1</span>);</span><br><span class="line">            jedis.hmset(key, tokenBucket.toHash());</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            TokenBucket tokenBucket = TokenBucket.fromHash(counter);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">long</span> lastRefillTime = tokenBucket.getLastRefillTime();</span><br><span class="line">            <span class="keyword">long</span> refillTime = System.currentTimeMillis();</span><br><span class="line">            <span class="keyword">long</span> intervalSinceLast = refillTime - lastRefillTime;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">long</span> currentTokensRemaining;</span><br><span class="line">            <span class="keyword">if</span> (intervalSinceLast &gt; intervalInMills) &#123;</span><br><span class="line">                currentTokensRemaining = limit;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">long</span> grantedTokens = (<span class="keyword">long</span>) (intervalSinceLast / intervalPerPermit);</span><br><span class="line">                System.out.println(grantedTokens);</span><br><span class="line">                currentTokensRemaining = Math.min(grantedTokens + tokenBucket.getTokensRemaining(), limit);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            tokenBucket.setLastRefillTime(refillTime);</span><br><span class="line">            <span class="keyword">assert</span> currentTokensRemaining &gt;= <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">if</span> (currentTokensRemaining == <span class="number">0</span>) &#123;</span><br><span class="line">                tokenBucket.setTokensRemaining(currentTokensRemaining);</span><br><span class="line">                jedis.hmset(key, tokenBucket.toHash());</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                tokenBucket.setTokensRemaining(currentTokensRemaining - <span class="number">1</span>);</span><br><span class="line">                jedis.hmset(key, tokenBucket.toHash());</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<p>上面的方法是最初的实现方法，对于每一个 Token Bucket，在 Redis 上面，使用一个 Hash 进行表示，一个 Token Bucket 有 lastRefillTime 表示最后一次补充 Token 的时间，tokensRemaining 则表示 Bucket 中的剩余 Token 数量，access() 方法大致的步骤为：</p>
<ol>
<li>当一个请求 Token进入 access() 方法后，先计算计算该请求的 Token Bucket 的 key；</li>
<li>如果这个 Token Bucket 在 Redis 中不存在，那么就新建一个 Token Bucket，然后设置该 Bucket 的 Token 数量为最大值减一(去掉了这次请求获取的 Token）。 在初始化 Token Bucket 的时候将 Token 数量设置为最大值这一点在后面还有讨论；</li>
<li>如果这个 Token Bucket 在 Redis 中存在，而且其上一次加入 Token 的时间到现在时间的时间间隔大于 Token Bucket 的 interval，那么也将 Bucket 的 Token 值重置为最大值减一；</li>
<li>如果 Token Bucket 上次加入 Token 的时间到现在时间的时间间隔没有大于 interval，那么就计算这次需要补充的 Token 数量，将补充过后的 Token 数量更新到 Token Bucket 中。</li>
</ol>
<ul>
<li><p>问题：<br>当用户首次请求 Token 或者长时间没有请求 Token 的情况下，首次进行 Token 请求，Bucket 此时所持有的 Token 数量应该是可以设置的，而不是一个简单的 Token Bucket 的容量最大值。因为我们的算法在 Token Bucket 被激活（第一次使用，或者间隔时间很长后使用）之后，会不断地往里面继续添加 Token（在用户请求的时候）， 这样在一个 interval 之内，用户所能够使用最大 Token 数量 M 等于初始的 Token 数量 I 加上 Bucket 的 Token 容量最大值 C。</p>
<ul>
<li>我现在做的改动比较有限，在 RateLimitPolicy 当中添加一个 maxBurstTime，然后计算 Bucket 激活的时候 初始的 Token 容量。程序创建一个 RateLimitPolicy 的时候，需要指定这个 maxBurstTime。关于这个初始容量的设置与计算 可以进一步参考 Guava 的 SmoothRateLimiter 中的文档和代码。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>系统设计</category>
      </categories>
  </entry>
  <entry>
    <title>epoll</title>
    <url>/2022/11/27/epoll/</url>
    <content><![CDATA[<h3 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h3><blockquote>
<p>所熟知的 IO 多路复用机制。 这里的复用指的就是对进程的复用。</p>
</blockquote>
<span id="more"></span>
<p>epoll简单例子</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAX_EVENTS 10</span></span><br><span class="line">           <span class="class"><span class="keyword">struct</span> <span class="title">epoll_event</span> <span class="title">ev</span>, <span class="title">events</span>[<span class="title">MAX_EVENTS</span>];</span></span><br><span class="line">           <span class="keyword">int</span> listen_sock, conn_sock, nfds, epollfd;</span><br><span class="line"></span><br><span class="line">           <span class="comment">/* Code to set up listening socket, &#x27;listen_sock&#x27;,</span></span><br><span class="line"><span class="comment">              (socket(), bind(), listen()) omitted. */</span></span><br><span class="line"></span><br><span class="line">           epollfd = epoll_create1(<span class="number">0</span>);</span><br><span class="line">           <span class="keyword">if</span> (epollfd == <span class="number">-1</span>) &#123;</span><br><span class="line">               perror(<span class="string">&quot;epoll_create1&quot;</span>);</span><br><span class="line">               <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">           &#125;</span><br><span class="line"></span><br><span class="line">           ev.events = EPOLLIN;</span><br><span class="line">           ev.data.fd = listen_sock;</span><br><span class="line">           <span class="keyword">if</span> (epoll_ctl(epollfd, EPOLL_CTL_ADD, listen_sock, &amp;ev) == <span class="number">-1</span>) &#123;</span><br><span class="line">               perror(<span class="string">&quot;epoll_ctl: listen_sock&quot;</span>);</span><br><span class="line">               <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">           &#125;</span><br><span class="line"></span><br><span class="line">           <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">               nfds = epoll_wait(epollfd, events, MAX_EVENTS, <span class="number">-1</span>);</span><br><span class="line">               <span class="keyword">if</span> (nfds == <span class="number">-1</span>) &#123;</span><br><span class="line">                   perror(<span class="string">&quot;epoll_wait&quot;</span>);</span><br><span class="line">                   <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">               &#125;</span><br><span class="line"></span><br><span class="line">               <span class="keyword">for</span> (n = <span class="number">0</span>; n &lt; nfds; ++n) &#123;</span><br><span class="line">                   <span class="keyword">if</span> (events[n].data.fd == listen_sock) &#123;</span><br><span class="line">                       conn_sock = accept(listen_sock,</span><br><span class="line">                                          (struct sockaddr *) &amp;addr, &amp;addrlen);</span><br><span class="line">                       <span class="keyword">if</span> (conn_sock == <span class="number">-1</span>) &#123;</span><br><span class="line">                           perror(<span class="string">&quot;accept&quot;</span>);</span><br><span class="line">                           <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">                       &#125;</span><br><span class="line">                       setnonblocking(conn_sock);</span><br><span class="line">                       ev.events = EPOLLIN | EPOLLET;</span><br><span class="line">                       ev.data.fd = conn_sock;</span><br><span class="line">                       <span class="keyword">if</span> (epoll_ctl(epollfd, EPOLL_CTL_ADD, conn_sock,</span><br><span class="line">                                   &amp;ev) == <span class="number">-1</span>) &#123;</span><br><span class="line">                           perror(<span class="string">&quot;epoll_ctl: conn_sock&quot;</span>);</span><br><span class="line">                           <span class="built_in">exit</span>(EXIT_FAILURE);</span><br><span class="line">                       &#125;</span><br><span class="line">                   &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                       do_use_fd(events[n].data.fd);</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li><p>accept 创建新 socket</p>
<ol>
<li>初始化 struct socket 对象</li>
<li>为新 socket 对象申请 file</li>
<li>接收连接</li>
<li>添加新文件到当前进程的打开文件列表中</li>
</ol>
<p>socket 内核对象:<br><img src="/images/epoll/img_20.png" alt="img_20.png"></p>
</li>
<li><p>epoll_create实现 </p>
<ol>
<li>eventpoll 这个结构体中的几个成员的含义如下：<ul>
<li>wq： 等待队列链表。软中断数据就绪的时候会通过 wq 来找到阻塞在 epoll 对象上的用户进程。</li>
<li>rbr： 一棵红黑树。为了支持对海量连接的高效查找、插入和删除，eventpoll 内部使用了一棵红黑树。通过这棵树来管理用户进程下添加进来的所有 socket 连接。</li>
<li>rdllist： 就绪的描述符的链表。当有的连接就绪的时候，内核会把就绪的连接放到 rdllist 链表里。这样应用进程只需要判断链表就能找出就绪进程，而不用去遍历整棵树。</li>
</ul>
</li>
</ol>
</li>
</ol>
<p><img src="/images/epoll/img_19.png" alt="img_19.png"></p>
<ol start="3">
<li><p>epoll_ctrl添加socket</p>
<blockquote>
<p>假设我们现在和客户端们的多个连接的 socket 都创建好了，也创建好了 epoll 内核对象。在使用 epoll_ctl 注册每一个 socket 的时候，内核会做如下三件事情</p>
</blockquote>
<ol>
<li>分配一个红黑树节点对象 epitem，包含socket fd和epoll对象指针</li>
<li>添加等待事件到 socket 的等待队列中，其回调函数是 ep_poll_callback ,base指针指向epitem</li>
<li>将 epitem 插入到 epoll 对象的红黑树里<br>epoll内存对象：<br><img src="/images/epoll/img_17.png" alt="img_17.png"></li>
</ol>
</li>
<li><p>epoll_wait </p>
<ol>
<li>判断就绪队列上有没有事件就绪 </li>
<li>定义等待事件并关联当前进程 </li>
<li>添加到等待队列 </li>
<li>让出CPU 主动进入睡眠状态<ul>
<li>epoll本身是<strong>阻塞</strong>的，即调用epoll_wait()如果当前监听的所有文件描述符上没有事件发生（就绪队列（rdllist）为空），当前调用线程将会被阻塞<pre><code>epoll_wait 做的事情不复杂，当它被调用时它观察 eventpoll-&gt;rdllist 链表里有没有数据即可。有数据就返回，没有数据就创建一个等待队列项（包含当前线程和回调唤醒函数（default_wake_function）），
将其添加到 eventpoll 的等待队列上，然后把自己阻塞掉就完事。
</code></pre>
<img src="/images/epoll/img_18.png" alt="img_18.png"></li>
</ul>
</li>
</ol>
</li>
<li><p>数据来啦</p>
<blockquote>
<ul>
<li>socket-&gt;sock-&gt;sk_data_ready 设置的就绪处理函数是 sock_def_readable</li>
<li>在 socket 的等待队列项中，其回调函数是 ep_poll_callback。另外其 private 没有用了，指向的是空指针 null。</li>
<li>在 eventpoll 的等待队列项中，回调函数是 default_wake_function。其 private 指向的是等待该事件的用户进程。</li>
</ul>
</blockquote>
</li>
<li><p>接收数据到socket接收队列 </p>
<ol>
<li>某个连接的数据来了，首先根据包上的src,dest信息获取对应的socket，然后将数据写入socket的接受队列中， </li>
</ol>
</li>
<li><p>查找就绪回调函数（ep_poll_callback） </p>
<ol>
<li>然后调用socket创建时设置的回调函数(sk-&gt;sk_data_ready = sock_def_readable)<br> sock_def_readable 判断当前socket的等待队列是否为空，不为空就调用等待队列项的回调函数 ep_poll_callback </li>
</ol>
</li>
<li><p>执行 socket 就绪回调函数 </p>
<ol>
<li>在ep_poll_callback 中首先根据等待队列项的额外的base指针找到当前socket的epitem,进而找到eventpoll对象，首先他做的第一件事就是将<br>自己的epitem添加到epoll的就绪队列（rdllist）中,接着会查看当前epoll对象是否有等待项（epollwait()阻塞时会设置），如果有等待项，<br>那就查找到等待项里设置的回调函数（default_wake_function)</li>
</ol>
</li>
<li><p>执行 epoll 就绪通知 </p>
<ol>
<li>default_wake_function 会唤醒epollwait时被阻塞的线程</li>
</ol>
</li>
</ol>
<p>  从用户角度来看，<strong>epoll_wait 只是多等了一会儿而已，但执行流程还是顺序的</strong>。</p>
<h4 id="水平触发-边缘触发"><a href="#水平触发-边缘触发" class="headerlink" title="水平触发 边缘触发"></a>水平触发 边缘触发</h4><blockquote>
<p>epoll有两种触发方式：EPOLLET /EPOLLLT,LT是默认方式</p>
</blockquote>
<ul>
<li><p>EPOLLET（边缘触发）</p>
<blockquote>
<p>只有数据到来才触发，不管缓冲区中是否还有数据，缓存区中剩余为读完的数据不会导致epoll_wait()返回,<strong>因此读事件发生时必须把数据读干净</strong>；写事件同样的道理 </p>
</blockquote>
</li>
<li><p>EPOLLLT（水平触发）</p>
<blockquote>
<p>只要有数据都会触发，缓冲区中剩余未读尽的数据会导致epoll_wait()返回；缓冲区剩余空间未写完也会导致epoll_wait()返回，<br>  因此对于写事件一定要及时清除，避免不必要的触发，浪费CPU资源。</p>
</blockquote>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>总结下，epoll 相关的函数里内核运行环境分两部分：</p>
</li>
<li><p>用户进程内核态。进行调用 epoll_wait 等函数时会将进程陷入内核态来执行。这部分代码负责查看接收队列，以及负责把当前进程阻塞掉，让出 CPU。</p>
</li>
<li><p>硬软中断上下文。在这些组件中，将包从网卡接收过来进行处理，然后放到 socket 的接收队列。对于 epoll 来说，再找到 socket 关联的 epitem，并把它添加到 epoll 对象的就绪链表中。 这个时候再捎带检查一下 epoll 上是否有被阻塞的进程，如果有唤醒之。<br><img src="/images/epoll/img_16.png" alt="img_16.png"></p>
</li>
</ul>
<h3 id="select-poll-epoll比较"><a href="#select-poll-epoll比较" class="headerlink" title="select poll epoll比较"></a>select poll epoll比较</h3><h4 id="select"><a href="#select" class="headerlink" title="select:"></a>select:</h4><ul>
<li>单个进程打开的fd是有限制的，通过FD_SETSIZE设置，默认1024</li>
<li>需要将被监听的fd列表从用户空间拷贝到内核空间</li>
<li>轮询，复杂度o(max_fd + 1),例如fd列表为 1、2、1000， 复杂度为o(1000)</li>
<li>每次调用select，需要重置fd列表对象中的是否可用字段</li>
</ul>
<ol>
<li>基本原理<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// Returns true if fd is ready for I/O.</span><br><span class="line">bool is_ready(int fd);</span><br><span class="line"></span><br><span class="line">struct fd_info &#123;</span><br><span class="line">  int fd;</span><br><span class="line">  bool ready;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">int select(set&lt;fd_info&gt; fds, int max_fd) &#123;</span><br><span class="line">  int ready_cnt = 0;</span><br><span class="line">  while (ready_cnt == 0) &#123;</span><br><span class="line">    for (int i = 0; i &lt; max_fd; i++) &#123;</span><br><span class="line">      if (is_ready(i)) &#123;</span><br><span class="line">        auto it = fds.find(i);</span><br><span class="line">        it-&gt;ready = true;</span><br><span class="line">        ready_cnt++;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  return ready_cnt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>使用方法<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set&lt;fd_info&gt; fds;</span><br><span class="line">while (1) &#123;</span><br><span class="line">  // Note that we need to re-initialize fds in each loop.</span><br><span class="line">  fds.clear();</span><br><span class="line">  fds.inert(&#123;.fd = 1&#125;)</span><br><span class="line">  fds.inert(&#123;.fd = 100&#125;)</span><br><span class="line"></span><br><span class="line">  int ready_cnt = select(fds, /*max_fd=*/100 + 1);</span><br><span class="line">  assert(ready_cnt &gt; 0);</span><br><span class="line">  for (int i = 0; i &lt; fds.size(); i++) &#123;</span><br><span class="line">    if (fds[i].ready) &#123;</span><br><span class="line">      // Use fds[i].fd</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h4></li>
</ol>
<ul>
<li>基于链表实现，没有最大连接数限制</li>
<li>需要将被监听的fd列表从用户空间拷贝到内核空间</li>
<li>轮询，复杂度o(n),n = len(fd_list),例如fd列表为1，2， 1000，复杂度为o(3)</li>
</ul>
<ol>
<li>基本原理<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// Returns true if fd is ready for I/O.</span><br><span class="line">bool is_ready(int fd);</span><br><span class="line"></span><br><span class="line">struct fd_info &#123;</span><br><span class="line">  int fd;</span><br><span class="line">  bool ready;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">int poll(struct fd_info* fds, int nfds) &#123;</span><br><span class="line">  int ready_cnt = 0;</span><br><span class="line">  while(ready_cnt == 0) &#123;</span><br><span class="line">    for (int i = 0; i &lt; nfds; i++) &#123;</span><br><span class="line">      if (is_ready(fds[i])) &#123;</span><br><span class="line">        fds[i].ready = true;</span><br><span class="line">        ready_cnt++;</span><br><span class="line">      &#125; else &#123;</span><br><span class="line">        fds[i] = false;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  return ready_cnt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>使用方法<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// Only need to initialize fds once.</span><br><span class="line">fd_info fds[2];</span><br><span class="line">fds[0].fd = 1;</span><br><span class="line">fds[1].fd = 100;</span><br><span class="line"></span><br><span class="line">int nfds = 2;</span><br><span class="line"></span><br><span class="line">while (1) &#123;</span><br><span class="line">  int ready_cnt = poll(fds, nfds);</span><br><span class="line">  assert(ready_cnt &gt; 0);</span><br><span class="line">  for (int i = 0; i &lt; nfds; i++) &#123;</span><br><span class="line">    if (fds[i].ready) &#123;</span><br><span class="line">      // Use fds[i].fd</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="epoll-1"><a href="#epoll-1" class="headerlink" title="epoll"></a>epoll</h3><ul>
<li>红黑树维护被监听的fd列表，增删改查效率为o(log n)</li>
<li><strong>事件驱动</strong>，复杂度为o(ready fds),例如fd列表为1、2、1000，ready fds为2，复杂度为o(1)</li>
<li>只从内核态返回ready fds,减少用户空间内核空间数据传输</li>
</ul>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://zhuanlan.zhihu.com/p/361750240">图解 | 深入揭秘 epoll 是如何实现 IO 多路复用的！</a></p>
]]></content>
      <categories>
        <category>IO</category>
      </categories>
      <tags>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title>git-rebase</title>
    <url>/2022/11/28/git-rebase/</url>
    <content><![CDATA[<h3 id="rebase"><a href="#rebase" class="headerlink" title="rebase"></a>rebase</h3><blockquote>
<p>git rebase master 表示将当前分支rebase到master，即以master为基地</p>
</blockquote>
<ol>
<li>例如 伙伴x 的a分支提交记录： 1 –&gt; 2 –&gt; 3, master分支提交记录：1 –&gt; 2 –&gt; 4 ,在a分支执行git rebase master后<br>a分支的提交记录将变成 1 –&gt; 2 –&gt; 4 –&gt;3’(3’与3不是同一个提交，但是提交的内容相同，提交id不同)</li>
<li>这时如果另一个伙伴 y 也在a分支上开发，并且本地提交记录为 1 –&gt; 2 –&gt; 5,而且将本地提交记录push到了远程的a分支。</li>
<li>如果x 将rebase后的a分支push到远程a,因为远程a有x本地a没有的提交记录5，系统此时会提示x需要git pull –rebase(变基) 或者 –no-rebase（合并),<br>如果此时x直接git push –force 强推上去，远程a就会变成 1 –&gt; 2 –&gt; 4 –&gt; 3’(5没有了)。</li>
<li>伙伴y 接着git pull远程 a,因为远程a有y本地a分支没有的提交记录4、3’，系统此时也会提醒选择 –rebase 还是 –no-base<ul>
<li>假如选择git pull –rebase 本地分支提交记录将会变成 1 – &gt; 2 –&gt; 4 –&gt; 3’ （<strong>本地5提交记录也没了</strong>），<strong>因此会丢代码</strong></li>
<li>假如选择git pull –no-rebase 本机分支提价记录将会变成 1 –&gt; 2 –&gt; 3’–&gt; 4’–&gt;5 –&gt;merge commit( 3’–&gt; 4’–&gt;5 按照提交时间排序)，<strong>不会丢代码</strong></li>
</ul>
</li>
</ol>
<p>因此实际开发中，如果有两个同事在同一个分支开发，<strong>一定不能进行git push –force强推</strong><br>另外，为了避免别人强推导致可能丢失代码，建议拉代码时选择<strong>git pull –no-rebase</strong>(合并)</p>
<p>–force-with-lease 将解决这种安全问题<br>使用了 –force-with-lease 参数之后，上面那种安全问题就没有那么危险了。</p>
<p>使用此参数推送，如果远端有其他人推送了新的提交，那么推送将被拒绝</p>
]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>主流应用io编程模型</title>
    <url>/2022/11/27/io%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><h3 id="五中IO模型"><a href="#五中IO模型" class="headerlink" title="五中IO模型"></a>五中IO模型</h3><ul>
<li>阻塞IO<blockquote>
<p>应用线程向内核请求数据时，如果没有数据<strong>会阻塞该请求</strong>，该线程陷入阻塞态，等数据到达时内核会将数据复制给应用空间，并唤醒线程，线程继续执行，返回成功</p>
</blockquote>
</li>
<li>非阻塞IO<blockquote>
<p>应用线程向内核请求数据时，如果没有数据线程不会陷入阻塞态，而是立即返回错误；应用线程再次请求数据时，如果有数据了，内核将数据拷贝到应用空间，返回成功</p>
</blockquote>
</li>
<li>IO多路复用<blockquote>
<p>上面两种IO模型均需要一个线程服务一个连接，这将会造成非常大的资源消耗，因此一种新的IO模型被提了出来：使用一个线程专门负责监听连接，如果某连接可写或可读了<br>就通知应用，应用再分配对应的线程去读取/写入数据。比如Linux实现的select, poll, <strong>epoll</strong>这些IO工具。这样就能节省很多宝贵的线程资源。</p>
</blockquote>
</li>
<li>信号驱动<blockquote>
<p>背景：IO多路复用虽然解决了多线程开销大的问题，但应用程序还是需要轮询监听线程是否有可读/可写事件发生。</p>
</blockquote>
<span id="more"></span>
<blockquote>
<p>当应用程序只用发起一次询问是否有可读/可写事件的请求(并通过系统调用sigaction执行一个信号处理函数，此时请求即刻返回)，当有可读可写事件发生时，内核通过信号回调通知应用进程，应用进程再分配对应的线程去读取/写入数据。</p>
</blockquote>
</li>
<li>异步IO<blockquote>
<p>背景：信号驱动虽然解决了应用需要轮询监听线程是否有可读/可写事件的问题，但还是需要发起一次询问内核是否有可读/可写事件的请求，然后才能调用read,write去读取/写入数据,<br>能不能有一种一劳永逸的方式，我只要发送一个请求我告诉内核我要读取数据，然后我就什么都不管了，然后内核去帮我去完成剩下的所有事情？</p>
<p>有人设计了一种方案，应用只需要向内核发送一个read 请求,告诉内核它要读取数据后即刻返回；内核收到请求后会建立一个信号联系，当数据准备就绪，<br>内核会主动把数据从内核复制到用户空间，等所有操作都完成之后，内核会发起一个通知告诉应用，我们称这种一劳永逸的模式为异步IO模型。</p>
</blockquote>
</li>
</ul>
<h4 id="同步异步"><a href="#同步异步" class="headerlink" title="同步异步"></a>同步异步</h4><ul>
<li>同步：在IO模型里面如果请求方<strong>从发起请求到数据最后完成的这一段过程中都需要自己参与</strong>(过程中可能因socket不可读或不可写线程被阻塞，如果可能，称为同步阻塞IO，如果不可能，称为同步非阻塞IO)，那么这种我们称为同步请求；</li>
<li>异步：反之，如果应用发送完指令后就不再参与过程了，只需要等待最终完成结果的通知，那么这就属于异步。</li>
</ul>
<h2 id="基于epoll实现的IO编程模型"><a href="#基于epoll实现的IO编程模型" class="headerlink" title="基于epoll实现的IO编程模型"></a>基于epoll实现的IO编程模型</h2><h3 id="go"><a href="#go" class="headerlink" title="go"></a>go</h3><blockquote>
<p>一个协程处理一个连接</p>
</blockquote>
<p>一个简单的服务器</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">func main() &#123;</span><br><span class="line"> //构造一个listener</span><br><span class="line"> listener, _ := net.Listen(&quot;tcp&quot;, &quot;127.0.0.1:9008&quot;)</span><br><span class="line"> for &#123;</span><br><span class="line">  //接收请求</span><br><span class="line">  conn, err := listener.Accept()</span><br><span class="line">  //启动一个协程来处理</span><br><span class="line">  go process(conn)</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func process(conn net.Conn) &#123;</span><br><span class="line"> //结束时关闭连接</span><br><span class="line"> defer conn.Close()</span><br><span class="line"> //读取连接上的数据</span><br><span class="line"> var buf [1024]byte</span><br><span class="line"> len, err := conn.Read(buf[:])</span><br><span class="line"> //发送数据</span><br><span class="line"> _, err = conn.Write([]byte(&quot;I am server!&quot;))</span><br><span class="line"></span><br><span class="line"> ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>go用户程序设置socket一般设置 <strong>非阻塞</strong> 模式，当调用go提供的accept()（会调用底层系统accept()）或read()时没有事件发生，会直接返回<br>accept有个for循环，如果不可读，会park当前协程,并将当前协程关联到当前socket。</li>
<li>往后 Go scheduler 会在循环调度的 runtime.schedule() 函数以及 sysmon 监控线程中调用<br>runtime.netpoll（epoll_wait） 以获取就绪的网络 socket 的文件描述符。根据网络就绪 fd 拿到 pollDesc。然后将对应的协程推入全局调度队列或者当前 P 本地调度队列去重新执行。此时协程被唤醒<br>继续accept/read,这时将会读到socket缓冲区中的数据然后返回。</li>
<li>因为系统监控 Goroutine 直接运行在线程上，所以它获取的 Goroutine 列表会直接加入全局的运行队列，其他 Goroutine 获取的列表都会加入 Goroutine 所在处理器的运行队列上。</li>
<li>网络轮询器并不是由运行时中的某一个线程独立运行的，运行时的调度器和系统调用都会通过 runtime.netpoll 与网络轮询器交换消息，获取待执行的 Goroutine 列表，并将待执行的 Goroutine 加入运行队列等待处理。</li>
<li>所有的文件 I/O、网络 I/O 和计时器都是由网络轮询器管理的，它是 Go 语言运行时重要的组成部分。</li>
</ul>
<h3 id="redis"><a href="#redis" class="headerlink" title="redis"></a>redis</h3><blockquote>
<p>单线程， io-multiple reactor编程模型</p>
</blockquote>
<ul>
<li>单线程IO<br><img src="/images/io_code_model/img_1.png" alt="img_1.png"></li>
<li>多线程IO<br><img src="/images/io_code_model/img_2.png" alt="img_2.png"></li>
</ul>
<h3 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h3><blockquote>
<p>master-多worker 模式</p>
</blockquote>
<ol>
<li>每个 Worker 都会有一个属于自己的 epoll 对象</li>
<li>每个 Worker 会关注所有的 listen 状态上的新连接事件</li>
<li>对于用户连接，只有一个 Worker 会处理，其它 Worker 不会持有该用户连接的 socket。<br><img src="/images/io_code_model/img_4.png" alt="img_4.png"><br><img src="/images/io_code_model/img_3.png" alt="img_3.png"></li>
</ol>
<ul>
<li>Nginx 的 Master 中做的网络相关动作不多，仅仅只是创建了 socket、然后 bind 并 listen 了一下。接着就是用自己 fork 出来多个 Worker 进程来。由于每个进程都一样，所以每个 Worker 都有 Master 创建出来的 listen 状态的 socket 句柄。</li>
<li>Worker 进程处理的网络相关工作就比较多了。epoll_create、epoll_ctl、epoll_wait 都是在 Worker 进程中执行的，也包括用户连接上的数据 read、处理 和 write。<br><img src="/images/io_code_model/img_6.png" alt="img_6.png"></li>
</ul>
<p>1.先是使用 epoll_create 创建一个 epoll 对象出来<br>2.设置回调为 ngx_event_accept<br>3.通过 epoll_ctl 将所有 listen 状态的 socket 的事件都管理起来<br>4.执行 epoll_wait 等待 listen socket 上的连接到来<br>5.新连接到来是 epoll_wait 返回，进入 ngx_event_accept 回调<br>6.ngx_event_accept 回调中将新连接也添加到 epoll 中进行管理（其回调为ngx_http_init_connection）<br>7.继续进入 epoll_wait 等待事件<br>8.用户数据请求到达时进入 http 回调函数进行处理</p>
<h3 id="netty"><a href="#netty" class="headerlink" title="netty"></a>netty</h3><blockquote>
<p>经典模式： boss-多worker模式</p>
</blockquote>
<p> <img src="/images/io_code_model/img_5.png" alt="img_5.png"></p>
<ul>
<li><p>在 Netty 中的 boss 线程中负责对父 channel（listen socket）上事件的监听和处理，当有新连接到达的时候，选择一个 worker 线程把这个子 channel（连接 socket ）交给 worker 线程来处理。</p>
</li>
<li><p>其中 Worker 线程就是等待其管理的所有子 channel（连接 socket）上的事件的监听和处理。当发现有事件发生的时候，回调用户设置的 handler 进行处理。在本文的例子中，这个用户 handler 就是 EchoServerHandler#channelRead。</p>
</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>几乎所有的IO编程模型都是将socket设置成非阻塞模式，然后利用epoll（epoll本身是阻塞的）等IO多路复用进行事件监听，基于回调处理事件，特别的，go netpoll一个协程服务一个连接（协程内存占用小(2k)，Linux创建一个线程占用10M内存），上下文切换开销小（100ns,线程上下文切换是30us））</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://zhuanlan.zhihu.com/p/144805500">https://zhuanlan.zhihu.com/p/144805500</a><br><a href="https://zhuanlan.zhihu.com/p/115912936">https://zhuanlan.zhihu.com/p/115912936</a><br><a href="https://zhuanlan.zhihu.com/p/541284978">https://zhuanlan.zhihu.com/p/541284978</a></p>
<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ul>
<li>半包和闭包</li>
</ul>
]]></content>
      <categories>
        <category>IO</category>
        <category>编程</category>
      </categories>
      <tags>
        <tag>IO</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title>协程</title>
    <url>/2022/11/29/%E5%8D%8F%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h2><ul>
<li><p>进程、线程 和 协程 之间概念的区别</p>
<ul>
<li>对于 进程、线程，都是由内核进行调度，有 CPU 时间片的概念，进行 <strong>抢占式调度</strong>（有多种调度算法）</li>
<li>对于 协程(用户级线程)，这是对内核透明的，也就是系统并不知道有协程的存在，是完全由用户自己的程序进行调度的，因为是由用户程序自己控制，<br>那么就很难像抢占式调度那样做到强制的 CPU 控制权切换到其他进程/线程，通常只能进行 <strong>协作式调度</strong>，需要协程自己主动把控制权转让出去之后，其他协程才能被执行到。<span id="more"></span></li>
</ul>
</li>
<li><p>线程进程的区别体现在6个方面：</p>
</li>
</ul>
<ol>
<li>根本区别：<strong>进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位。</strong></li>
<li>资源开销：每个进程都有独立的代码和数据空间，程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一进程的线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器，线程之间切换的开销小。</li>
<li>包含关系：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的。</li>
<li>内存分配：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的。</li>
<li>影响关系：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。</li>
<li>执行过程：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。两者均可并发执行。</li>
</ol>
<ul>
<li>优点</li>
</ul>
<ol>
<li>协程由于是在<strong>用户态来完成上下文切换</strong>的，所以切换耗时只有区区<strong>100ns</strong>多一些，比进程切换要高10倍。</li>
<li>单个协程需要的栈内存也足够小，只需要2KB。</li>
</ol>
<ul>
<li>缺点：</li>
</ul>
<ol start="3">
<li>协程调度机制无法实现公平调度,也无法直接利用多核优势</li>
</ol>
<ul>
<li>实现原理<ul>
<li>协程是基于线程的。内部实现上，维护了一组数据结构和 n 个线程，真正的执行还是线程，协程执行的代码被扔进一个待执行队列中，<br>由这 n 个线程从队列中拉出来执行</li>
</ul>
</li>
</ul>
<h2 id="通信方式"><a href="#通信方式" class="headerlink" title="通信方式"></a>通信方式</h2><h3 id="进程通信方式总结"><a href="#进程通信方式总结" class="headerlink" title="进程通信方式总结"></a>进程通信方式总结</h3><ul>
<li>管道：速度慢，容量有限，只有父子进程能通讯，基于字节流，半双工</li>
<li>命名管道：任何进程间都能通讯，但速度慢</li>
<li>消息队列：克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。消息队列通信的速度不是最及时的，毕竟每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。</li>
<li>共享内存：能够很容易控制容量，<strong>速度最快</strong>，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全问题。</li>
<li>信号量：不能传递复杂消息，只能用来同步。</li>
<li>信号：用于通知接收进程某个事件已经发生。唯一的异步通信机制， 可以用来直接进行用户空间进程和内核进程之间的交互，内核进程也可以利用它来通知用户空间进程发生了哪些系统事件。</li>
<li>套接字：可用于不同机器之间的进程间通信。<h3 id="线程间通信方式"><a href="#线程间通信方式" class="headerlink" title="线程间通信方式"></a>线程间通信方式</h3></li>
<li>锁 <blockquote>
<p>锁机制包括互斥锁、条件变量、读写锁。</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>有关Java的锁机制，可以点击查看<a href="https://www.cnblogs.com/wuqinglong/p/9945618.html">Java6及以上版本对synchronized的优化
</a>,<a href="https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&mid=2247483792&idx=1&sn=5f4a1763876bdc03aad3fdfbdc1f1779&scene=21#wechat_redirect">《详解Java多线程锁之synchronized》</a><br>和<a href="https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&mid=2247483798&idx=1&sn=cceca939e36c1b1748b290dc34d1f4cc&scene=21#wechat_redirect">《详解Java多线程锁之Lock和ReadWriteLock》</a></p>
</blockquote>
<blockquote>
<p>有关条件变量，可以点击查看<a href="https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&mid=2247483819&idx=1&sn=2b8a7b636f870b29df3c0c98be5eca82&scene=21#wechat_redirect">《Java多线程的可见性与有序性》</a>中有关volatile的讲解。</p>
</blockquote>
<ul>
<li>信号量<blockquote>
<p>可以查看这篇博客<a href="https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&mid=2247483885&idx=1&sn=8fe2bf133cbc7932def11e407e76a783&scene=21#wechat_redirect">《快速了解基于AQS实现的Java并发工具类》</a>中有关Semaphore的讲解，感受下信号量如何在java线程通信中的使用。</p>
</blockquote>
</li>
<li>信号<blockquote>
<p>可以查看这篇博客：<a href="https://mp.weixin.qq.com/s?__biz=MzUyNzgyNzAwNg==&mid=2247483954&idx=1&sn=cc77f94e46cf5351b28da91eda01ec2b&scene=21#wechat_redirect">《彻底搞懂Java的等待-通知(wait-notify)机制》</a></p>
</blockquote>
</li>
</ul>
<h3 id="go协程通信方式"><a href="#go协程通信方式" class="headerlink" title="go协程通信方式"></a>go协程通信方式</h3><blockquote>
<p>不要通过共享内存的方式进行通信,而是应该通过通信的方式共享内存。</p>
</blockquote>
<h4 id="channel"><a href="#channel" class="headerlink" title="channel"></a><a href="https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-channel/">channel</a></h4><blockquote>
<p>Channel 在运行时的内部表示是 runtime.hchan，该结构体中包含了用于保护成员变量的互斥锁，从某种程度上说，Channel 是一个用于同步和通信的有锁队列</p>
</blockquote>
<ul>
<li>同步 Channel — 不需要缓冲区，发送方会直接将数据交给（Handoff）接收方；</li>
<li>异步 Channel — 基于环形缓存的传统生产者消费者模型；</li>
<li>chan struct{} 类型的异步 Channel — struct{} 类型不占用内存空间，不需要实现缓冲区和直接发送（Handoff）的语义； <h5 id="发送分为三种情况"><a href="#发送分为三种情况" class="headerlink" title="发送分为三种情况"></a>发送分为三种情况</h5><ol>
<li>直接发送：当存在等待的接收者时，直接将数据发送给等待的接收者</li>
<li>写缓冲区：当缓冲区存在空余空间时，将发送的数据写入channel的缓冲区</li>
<li>阻塞发送：当不存在缓冲区或者缓存区已满时，等待其他goroutine从channel接收数据 </li>
</ol>
</li>
</ul>
<h5 id="接收也分为三种情况"><a href="#接收也分为三种情况" class="headerlink" title="接收也分为三种情况"></a>接收也分为三种情况</h5><ol>
<li>直接接收：当存在等待的发送者时，直接从阻塞的发送者获取数据</li>
<li>读缓冲区：当缓冲区存在数据时，从channel的缓冲区中读取数据</li>
<li>阻塞接收：当缓冲区不存在数据时，等待其他goroutine向channel发送数据</li>
</ol>
<h4 id="select"><a href="#select" class="headerlink" title="select"></a><a href="https://draveness.me/golang/docs/part2-foundation/ch05-keyword/golang-select/">select</a></h4><ol>
<li>随机生成一个遍历的轮询顺序 pollOrder 并根据 Channel 地址生成锁定顺序 lockOrder；</li>
<li>根据 pollOrder 遍历所有的 case 查看是否有可以立刻处理的 Channel；<br>如果存在，直接获取 case 对应的索引并返回；<br>如果不存在，创建 runtime.sudog 结构体，将当前 Goroutine 加入到所有相关 Channel 的收发队列，并调用 runtime.gopark 挂起当前 Goroutine 等待调度器的唤醒；</li>
<li>当调度器唤醒当前 Goroutine 时，会再次按照 lockOrder 遍历所有的 case，从中查找需要被处理的 runtime.sudog 对应的索引；</li>
</ol>
<h3 id="todo"><a href="#todo" class="headerlink" title="todo"></a>todo</h3><ul>
<li>Java线程通信原理(lock:aqs(cas+队列)，synchronized:jvm层面实现（无锁，偏向锁，轻量级锁，自旋锁）)</li>
<li>线程中断原理 （中断标志位，怎么响应中断，通信方式）</li>
</ul>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul>
<li><a href="https://cloud.tencent.com/developer/article/1839604">一文快速了解进程、线程与协程</a></li>
<li><a href="https://www.cnblogs.com/liang1101/p/7285955.html">golang协程详解</a></li>
</ul>
]]></content>
      <categories>
        <category>协程</category>
      </categories>
      <tags>
        <tag>协程</tag>
      </tags>
  </entry>
  <entry>
    <title>锁分析</title>
    <url>/2022/12/01/java%E9%94%81/</url>
    <content><![CDATA[<h2 id="线程状态"><a href="#线程状态" class="headerlink" title="线程状态"></a>线程状态</h2><ul>
<li>阻塞：当一个线程试图获取监视器锁（即进入synchronized块），而该锁被其他线程持有，则该线程进入阻塞状态。它的特点是使用简单，由JVM调度器来决定唤醒自己，而不需要由另一个线程来显式唤醒自己，<strong>不响应中断</strong>。</li>
<li>等待：当一个线程等待另一个线程通知调度器一个条件时，该线程进入等待状态。它的特点是需要等待另一个线程显式地唤醒自己，实现灵活，语义更丰富，可响应中断。例如调用：Object.wait()、Thread.join()以及等待Lock或Condition。<span id="more"></span>
<h2 id="synchronized-与-Lock"><a href="#synchronized-与-Lock" class="headerlink" title="synchronized 与 Lock"></a>synchronized 与 Lock</h2><blockquote>
<p><a href="https://www.cnblogs.com/wuqinglong/p/9945618.html">synchronized 实现原理</a></p>
</blockquote>
<h3 id="相同点"><a href="#相同点" class="headerlink" title="相同点"></a>相同点</h3></li>
</ul>
<ol>
<li>都是可重入的</li>
<li>都可以进行线程内通信</li>
</ol>
<h3 id="不同点"><a href="#不同点" class="headerlink" title="不同点"></a>不同点</h3><ol>
<li>实现不同，synchronized基于jvm层实现（偏向锁、轻量级锁，重量级锁）。Lock基于AQS实现（cas + volatile state + 等待队列）</li>
<li>synchronized如果拿不到锁线程会进入阻塞态，不响应中断；而JUC里的Lock是用LockSupport.park()/unpark()来实现阻塞/唤醒的，Lock拿不到锁时线程会陷入等待态，可选择是否响应中断。</li>
<li>synchronized是不公平的；Lock可选公平、不公平</li>
</ol>
<h3 id="公平锁与非公平锁实现"><a href="#公平锁与非公平锁实现" class="headerlink" title="公平锁与非公平锁实现"></a>公平锁与非公平锁实现</h3><h4 id="公平锁"><a href="#公平锁" class="headerlink" title="公平锁"></a>公平锁</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Sync object for fair locks</span><br><span class="line"> */</span><br><span class="line">static final class FairSync extends Sync &#123;</span><br><span class="line">    private static final long serialVersionUID = -3000897897090466540L;</span><br><span class="line"></span><br><span class="line">    final void lock() &#123;</span><br><span class="line">        acquire(1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * Fair version of tryAcquire.  Don&#x27;t grant access unless</span><br><span class="line">     * recursive call or no waiters or is first.</span><br><span class="line">     */</span><br><span class="line">    protected final boolean tryAcquire(int acquires) &#123;</span><br><span class="line">        final Thread current = Thread.currentThread();</span><br><span class="line">        int c = getState();</span><br><span class="line">        if (c == 0) &#123;</span><br><span class="line">            if (!hasQueuedPredecessors() &amp;&amp;</span><br><span class="line">                compareAndSetState(0, acquires)) &#123;</span><br><span class="line">                setExclusiveOwnerThread(current);</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        else if (current == getExclusiveOwnerThread()) &#123;</span><br><span class="line">            int nextc = c + acquires;</span><br><span class="line">            if (nextc &lt; 0)</span><br><span class="line">                throw new Error(&quot;Maximum lock count exceeded&quot;);</span><br><span class="line">            setState(nextc);</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">        return false;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="非公平锁"><a href="#非公平锁" class="headerlink" title="非公平锁"></a>非公平锁</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Sync object for non-fair locks</span><br><span class="line"> */</span><br><span class="line">static final class NonfairSync extends Sync &#123;</span><br><span class="line">    private static final long serialVersionUID = 7316153563782823691L;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * Performs lock.  Try immediate barge, backing up to normal</span><br><span class="line">     * acquire on failure.</span><br><span class="line">     */</span><br><span class="line">    final void lock() &#123;</span><br><span class="line">        if (compareAndSetState(0, 1))</span><br><span class="line">            setExclusiveOwnerThread(Thread.currentThread());</span><br><span class="line">        else</span><br><span class="line">            acquire(1);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    protected final boolean tryAcquire(int acquires) &#123;</span><br><span class="line">        return nonfairTryAcquire(acquires);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Performs non-fair tryLock.  tryAcquire is implemented in</span><br><span class="line"> * subclasses, but both need nonfair try for trylock method.</span><br><span class="line"> */</span><br><span class="line">final boolean nonfairTryAcquire(int acquires) &#123;</span><br><span class="line">    final Thread current = Thread.currentThread();</span><br><span class="line">    int c = getState();</span><br><span class="line">    if (c == 0) &#123;</span><br><span class="line">        if (compareAndSetState(0, acquires)) &#123;</span><br><span class="line">            setExclusiveOwnerThread(current);</span><br><span class="line">            return true;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    else if (current == getExclusiveOwnerThread()) &#123;</span><br><span class="line">        int nextc = c + acquires;</span><br><span class="line">        if (nextc &lt; 0) // overflow</span><br><span class="line">            throw new Error(&quot;Maximum lock count exceeded&quot;);</span><br><span class="line">        setState(nextc);</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="go-lock"><a href="#go-lock" class="headerlink" title="go lock"></a>go lock</h2><h3 id="Mutex-互斥锁"><a href="#Mutex-互斥锁" class="headerlink" title="Mutex 互斥锁"></a>Mutex 互斥锁</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">type Mutex struct &#123;</span><br><span class="line">	state int32</span><br><span class="line">	sema  uint32</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="正常模式（非公平）和饥饿模式（公平）"><a href="#正常模式（非公平）和饥饿模式（公平）" class="headerlink" title="正常模式（非公平）和饥饿模式（公平）"></a>正常模式（非公平）和饥饿模式（公平）</h4><blockquote>
<p>在正常模式下，锁的等待者会按照先进先出的顺序获取锁。但是刚被唤起的 Goroutine 与新创建的 Goroutine 竞争时，大概率会获取不到锁，为了减少这种情况的出现，一旦 Goroutine 超过 1ms 没有获取到锁，它就会将当前互斥锁切换饥饿模式，防止部分 Goroutine 被『饿死』。</p>
</blockquote>
<h4 id="加锁"><a href="#加锁" class="headerlink" title="加锁"></a>加锁</h4><blockquote>
<p>互斥锁的加锁过程比较复杂，它涉及自旋、信号量以及调度等概念：</p>
</blockquote>
<ol>
<li>如果互斥锁处于初始化状态，会通过置位 mutexLocked 加锁；</li>
<li>如果互斥锁处于 mutexLocked 状态并且在普通模式下工作，会进入<strong>自旋</strong>，执行 30 次 PAUSE 指令消耗 CPU 时间等待锁的释放；</li>
<li>如果当前 Goroutine 等待锁的时间超过了 1ms，互斥锁就会切换到饥饿模式；</li>
<li>互斥锁在正常情况下会通过 runtime.sync_runtime_SemacquireMutex 将尝试获取锁的 Goroutine <strong>切换至休眠状态，等待锁的持有者唤醒；</strong></li>
<li>如果当前 Goroutine 是互斥锁上的最后一个等待的协程或者等待的时间小于 1ms，那么它会将互斥锁切换回正常模式；</li>
</ol>
<h4 id="解锁"><a href="#解锁" class="headerlink" title="解锁"></a>解锁</h4><blockquote>
<p>互斥锁的解锁过程与之相比就比较简单，其代码行数不多、逻辑清晰，也比较容易理解：</p>
</blockquote>
<ol>
<li>当互斥锁已经被解锁时，调用 sync.Mutex.Unlock 会直接抛出异常；</li>
<li>当互斥锁处于饥饿模式时，将锁的所有权交给队列中的下一个等待者，等待者会负责设置 mutexLocked 标志位；</li>
<li>当互斥锁处于普通模式时，如果没有 Goroutine 等待锁的释放或者已经有被唤醒的 Goroutine 获得了锁，会直接返回；在其他情况下会通过 sync.runtime_Semrelease 唤醒对应的 Goroutine；</li>
</ol>
<h3 id="RWMutex"><a href="#RWMutex" class="headerlink" title="RWMutex"></a>RWMutex</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">type RWMutex struct &#123;</span><br><span class="line">	w           Mutex</span><br><span class="line">	writerSem   uint32</span><br><span class="line">	readerSem   uint32</span><br><span class="line">	readerCount int32</span><br><span class="line">	readerWait  int32</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>w — 复用互斥锁提供的能力；</li>
<li>writerSem 和 readerSem — 分别用于写等待读和读等待写：</li>
<li>readerCount 存储了当前正在执行的读操作数量；</li>
<li>readerWait 表示当写操作被阻塞时等待的读操作个数；</li>
</ul>
<h4 id="尝试获取写锁时；"><a href="#尝试获取写锁时；" class="headerlink" title="尝试获取写锁时；"></a>尝试获取写锁时；</h4><ul>
<li>每次 sync.RWMutex.RUnlock 都会将 readerCount 其减一，当它归零时该 Goroutine 会获得写锁；</li>
<li>将 readerCount 减少 rwmutexMaxReaders 个数以阻塞后续的读操作；<h4 id="释放写锁"><a href="#释放写锁" class="headerlink" title="释放写锁"></a>释放写锁</h4></li>
<li>会先通知所有的读操作，然后才会释放持有的互斥锁；</li>
</ul>
<h3 id="sleep-vs-wait"><a href="#sleep-vs-wait" class="headerlink" title="sleep vs wait"></a>sleep vs wait</h3><ul>
<li>sleep() 方法没有释放锁，而 wait() 方法释放了对象的监视器锁 ，因此wait()方法定义在Object类上。</li>
<li>wait() 通常被用于线程间交互/通信，sleep()通常被用于暂停执行。</li>
</ul>
<h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><h3 id="形成死锁的四个条件"><a href="#形成死锁的四个条件" class="headerlink" title="形成死锁的四个条件"></a>形成死锁的四个条件</h3><ol>
<li>互斥 资源一旦被一个进程获得后，不可被其他进程再次获得</li>
<li>不可剥夺 进程获得的资源在未使用完之前，其他进程不能强行抢走，只能等自己主动释放</li>
<li>请求与保持 进程保持持有已经获取的资源的同时，继续请求需要获取的其他资源(阻塞态)</li>
<li>循环等待 存在一种进程资源的循环等待链，链中每个进程已获得的资源同时被下一个进程所请求</li>
</ol>
<h3 id="死锁预防"><a href="#死锁预防" class="headerlink" title="死锁预防"></a>死锁预防</h3><ol>
<li>破坏请求与保持条件：运行时分配好所有的资源，之后一直保持</li>
<li>破坏循环等待：给资源编号，必须按编号从小到大的顺序申请资源</li>
</ol>
<h3 id="死锁避免"><a href="#死锁避免" class="headerlink" title="死锁避免"></a>死锁避免</h3><h4 id="安全序列"><a href="#安全序列" class="headerlink" title="安全序列"></a>安全序列</h4><blockquote>
<ol>
<li>若在某一时刻，假定系统中存在这么一个进程序列（p1, p2, p3 … pn）,系统按照该序列给进程分配资源且能达到每个进程的最大需求，使每个进程都能顺利完成，<br>（然后释放资源给后面的进程使用），那么称此时系统处于<strong>安全状态</strong>，该序列为系统的一个<strong>安全系列</strong>。</li>
<li>系统处于安全状态一定不会发生死锁，不处于安全状态则有可能会发生死锁 </li>
</ol>
</blockquote>
<h4 id="银行家算法"><a href="#银行家算法" class="headerlink" title="银行家算法"></a>银行家算法</h4><blockquote>
<ol>
<li>该算法用于死锁避免。该算法的实质就是要<strong>设法保证系统动态分配资源后不进入不安全状态，以避免可能产生的死锁。</strong>（悲观锁的思想）</li>
<li>当进程请求资源时，先判断该请求是否合法（请求的资源小于系统的剩余资源和进程应该请求的资源），如果合法，将资源预分配给该进程。<br>然后运行<strong>判断当前时刻系统是否存在安全序列的算法</strong>检查，如果存在，表明当前系统是安全的，返回成功；如果不存在，表明当前系统不安全，然后剥夺预分配的资源，阻塞进程。</li>
<li>银行家算法的执行有个前提条件，即要求进程预先提出自己的最大资源请求，并假设系统拥有固定的资源总量。</li>
<li>从某种意义上说，它<strong>缺乏实用价值</strong>，因为很少有进程能够在运行前就知道其所需资源的最大值，而且进程数也不是固定的，往往在不断地变化（如新用户登录或退出），况且原本可用的资源也可能突然间变成不可用</li>
<li><a href="https://www.cnblogs.com/wkfvawl/p/11929508.html">算法详解</a></li>
</ol>
</blockquote>
<h3 id="死锁检测和解除"><a href="#死锁检测和解除" class="headerlink" title="死锁检测和解除"></a>死锁检测和解除</h3><h4 id="死锁检测"><a href="#死锁检测" class="headerlink" title="死锁检测"></a>死锁检测</h4><blockquote>
<ol>
<li>检查死锁的办法就是由软件检查系统中由进程和资源构成的有向图是否构成一个或多个环路，若是，则存在死锁，否则不存在。</li>
<li>由于死锁是系统中的恶性小概率事件，死锁检测程序的多次执行往往都不会调用一次死锁解除程序，而这却增加了系统开销，因此在设计操作系统时需要权衡检测精度与时间开销。</li>
</ol>
</blockquote>
<h4 id="死锁解除"><a href="#死锁解除" class="headerlink" title="死锁解除"></a>死锁解除</h4><ol>
<li>撤销进程 （撤销代价最下的进程）</li>
<li>挂起进程 剥夺资源</li>
</ol>
<h3 id="MySQL解决死锁"><a href="#MySQL解决死锁" class="headerlink" title="MySQL解决死锁"></a>MySQL解决死锁</h3><ol>
<li>死锁前执行是否会发生死锁检测（消耗资源）</li>
<li>发生死锁了等一个事务超时回滚</li>
</ol>
]]></content>
      <categories>
        <category>锁</category>
      </categories>
      <tags>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title>思考</title>
    <url>/2022/12/03/%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[<ul>
<li>延迟满足感</li>
<li>懒惰（体力的、思考的、情绪的）是万恶之源，所以修炼很多时候就是在克服惰性。</li>
<li>年轻人不要试图追求安全感，特别是年轻的时候，周遭环境从来都不会有绝对的安全感，如果你觉得安全了，很有可能开始暗藏危机。真正的安全感，<br>来自你对自己的信心，是你每个阶段性目标的实现，而真正的归属感，在于你的内心深处，对自己命运的把控，因为你最大的对手永远是自己。</li>
<li>其实，德州扑克和人生一样：应该：理解不确定性、专注有可能的事情、理智评估概率、能舍才能得、避免意气用事。</li>
<li>凡事就怕不认真，不思考。好多问题我应该能知道的，只是之前没有认真看，认真想，想当然（不是没时间）。延迟满足感是一项长期修炼。</li>
<li>加强专注力训练</li>
<li>保证足够睡眠是积极高效的第一步。</li>
<li>我今天的处境都是因为我有些应该做的事情我没有做，不应该做的事情我就全做，所以要改变现状，就要从自己开始。’</li>
<li>一点不要含糊，含糊代表着侥幸、代表着自我欺骗、代表着自我感觉飘然。</li>
<li>乔布斯说stay hungry，我以为饥渴有三个层次：贪婪、成就动机、好奇心 。三者分别关注：瞬间的结果，持续的过程，和远大的未知。<br>三者也恰好对应了三种人：卑劣的投机者，艰辛的攀登者，与幸福的探索者。保持好奇心</li>
<li>人生的本质是追寻自我的提升。包括思想、能力、意志等等。这些发展好了，一切随之而来。偏偏大多数人追求的是短期的公司、职位、薪水，运气好的能有所发展，<br>运气差的会迷失方向流于平庸。</li>
</ul>
]]></content>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title>map</title>
    <url>/2022/12/05/map/</url>
    <content><![CDATA[<h3 id="go-map"><a href="#go-map" class="headerlink" title="go map"></a>go map</h3><ol>
<li>数组+链表法实现</li>
<li>通过hash(key)将元素分散在不同的桶中，每个桶有8个cell，hash值低位决定桶序号，高位标识同一个桶中的不同key</li>
<li>每个桶有个overflow指针，当8个key都被填满时，会新建一个溢出桶出来，并将overflow指向它</li>
<li>扩容分为等量扩容（overflow &gt; 2 ^ B）和2倍容量扩容（(count / 2 ^ B) &gt; 装载因子）</li>
<li>扩容是渐进式的，避免一次性迁移太多key引发性能问题，bucket迁移发生在赋值，删除期间，每次最多搬迁两个bucket<span id="more"></span>
<h3 id="go-Sync-Map"><a href="#go-Sync-Map" class="headerlink" title="go Sync.Map"></a>go Sync.Map</h3></li>
<li>空间换时间，通过冗余的两个map(read, dirty),尽量避免加锁带来的性能开销</li>
<li>使用只读数据（read），避免读写冲突</li>
<li>动态调整，miss次数多了之后，将dirty提升为read</li>
<li>double_checking(双重检测)</li>
<li>延迟删除，删除一个键值只是打上标记，避免后续获取删除元素的时候需要加锁&amp;双重检测</li>
<li>优先从read读取，插入，删除，因为对read的操作不需要加锁（cas）</li>
<li>虽然有两个map,但是value的底层是指针，指向同一份数据。</li>
</ol>
<h4 id="Store"><a href="#Store" class="headerlink" title="Store"></a>Store</h4><ol>
<li>先从read读key，如果存在并且没有删除，直接更新read[key] = entry{p:value}</li>
<li>如果存在但是被标记为删除，在dirty中插入这对KV，dirty[key] = entry{p:value}</li>
<li>如果不存在，但是dirty中存在，更新dirty[key] = entry{p:value}</li>
<li>如果dirty也不存在，如果当前read.amended为FALSE（表示dirty中不含有read没有的条目），此时将read map复制一份给dirty；最后更新dirty[key] = entry{p:value}</li>
</ol>
<h4 id="Load"><a href="#Load" class="headerlink" title="Load"></a>Load</h4><ol>
<li>从read中读取到，直接返回</li>
<li>没有读取到并且read.amended为TRUE，加锁再读read一遍</li>
<li>read中不存在，从dirty中读取key返回，并自增misses</li>
<li>misses达到dirty长度，dirty map提升为read map,dirty置nil</li>
</ol>
<h4 id="Delete"><a href="#Delete" class="headerlink" title="Delete"></a>Delete</h4><ol>
<li>先读read，若存在，cas更新read[key].p = nil</li>
<li>没有读取到并且read.amended为TRUE，加锁再读一遍，</li>
<li>read中还是不存在，dirty中调用delete(dirty,key)删除元素</li>
</ol>
<h3 id="Java-map"><a href="#Java-map" class="headerlink" title="Java map"></a>Java map</h3><ol>
<li>数组o(1)+链表o(n)</li>
<li>Java 8 链表改为红黑树，复杂度o(logN)提升hash冲突时插入查找性能</li>
<li>线程不安全</li>
</ol>
<h3 id="Java-ConcurrentMap"><a href="#Java-ConcurrentMap" class="headerlink" title="Java ConcurrentMap"></a>Java ConcurrentMap</h3><ol>
<li>分段锁解决线程安全问题</li>
</ol>
]]></content>
      <categories>
        <category>map</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>map</tag>
      </tags>
  </entry>
  <entry>
    <title>领域驱动设计（DDD）</title>
    <url>/2022/12/09/ddd/</url>
    <content><![CDATA[<p><img src="/images/ddd/img_1.png" alt="img_1.png"></p>
<h3 id="实体"><a href="#实体" class="headerlink" title="实体"></a>实体</h3><blockquote>
<p>实体就是领域中需要唯一标识的领域概念</p>
</blockquote>
<h3 id="值对象"><a href="#值对象" class="headerlink" title="值对象"></a>值对象</h3><blockquote>
<p>值对象没有唯一标识，这是它和实体的最大不同。</p>
</blockquote>
<span id="more"></span>
<h3 id="领域服务"><a href="#领域服务" class="headerlink" title="领域服务"></a>领域服务</h3><blockquote>
<ol>
<li>领域中的一些概念不太适合建模为对象，即归类到实体对象或值对象，因为它们本质上就是一些操作，一些动作，而不是事物。<br>这些操作或动作往往会涉及到多个领域对象，并且需要协调这些领域对象共同完成这个操作或动作。</li>
<li>一般的领域对象都是有状态和行为的，而领域服务没有状态只有行为;需要强调的是领域服务是无状态的，它存在的意义就是协调领域对象共完成某个操作，所有的状态还是都保存在相应的领域对象中。</li>
</ol>
</blockquote>
<h3 id="聚合及聚合根（Aggregate，Aggregate-Root）"><a href="#聚合及聚合根（Aggregate，Aggregate-Root）" class="headerlink" title="聚合及聚合根（Aggregate，Aggregate Root）"></a>聚合及聚合根（Aggregate，Aggregate Root）</h3><blockquote>
<ol>
<li>从业务的角度深入分析哪些对象它们的<strong>关系是内聚的</strong>，即我们会把他们看成是一个整体来考虑的；然后这些对象我们就可以把它们放在一个聚合内。</li>
<li>所谓关系是内聚的，<strong>是指这些对象之间必须保持一个固定规则</strong>，固定规则是指在数据变化时必须保持不变的一致性规则。当我们在修改一个聚合时，我们必须在事务级别确保整个聚合内的所有对象满足这个固定规则。</li>
</ol>
</blockquote>
<ul>
<li><p>聚合有以下一些特点：</p>
<ul>
<li><strong>每个聚合有一个根和一个边界</strong>，<strong>边界定义了一个聚合内部有哪些实体或值对象，根是聚合内的某个实体</strong>；</li>
<li>聚合内部的对象之间可以相互引用，但是聚合外部如果要访问聚合内部的对象时，必须通过聚合根开始导航，绝对不能绕过聚合根直接访问聚合内的对象，<strong>也就是说聚合根是外部可以保持 对它的引用的唯一元素</strong>；</li>
<li>聚合内除根以外的其他实体的唯一标识都是本地标识，也就是只要在聚合内部保持唯一即可，因为它们总是从属于这个聚合的；</li>
<li><strong>聚合根负责与外部其他对象打交道并维护自己内部的业务规则</strong>；</li>
<li>基于聚合的以上概念，我们可以推论出从数据库查询时的单元也是以聚合为一个单元，也就是说我们不能直接查询聚合内部的某个非根的对象；</li>
<li>聚合内部的对象可以保持对其他聚合根的引用；</li>
<li>删除一个聚合根时必须同时删除该聚合内的所有相关对象，因为他们都同属于一个聚合，是一个完整的概念；</li>
</ul>
</li>
<li><p>有分析报告显示，通常在大部分领域模型中，有70%的聚合通常只有一个实体，即聚合根，该实体内部没有包含其他实体，只包含一些值对象；另外30%的聚合中，基本上也只包含两到三个实体。这意味着大部分的聚合都只是一个实体，该实体同时也是聚合根。 </p>
</li>
</ul>
<h3 id="工厂"><a href="#工厂" class="headerlink" title="工厂"></a>工厂</h3><blockquote>
<p>封装创建复杂对象的细节</p>
</blockquote>
<h3 id="仓储"><a href="#仓储" class="headerlink" title="仓储"></a>仓储</h3><blockquote>
<ol>
<li>管理对象</li>
<li>仓储里面存放的对象一定是聚合，原因是之前提到的领域模型中是以聚合的概念去划分边界的；</li>
<li>仓储还有一个重要的特征就是分为仓储定义部分和仓储实现部分，在领域模型中我们定义仓储的接口，而在基础设施层实现具体的仓储。</li>
<li>不负责事务处理</li>
</ol>
</blockquote>
<h3 id="工作单元"><a href="#工作单元" class="headerlink" title="工作单元"></a>工作单元</h3><blockquote>
<p> 负责事务处理</p>
</blockquote>
<h3 id="设计领域模型的一般步骤"><a href="#设计领域模型的一般步骤" class="headerlink" title="设计领域模型的一般步骤"></a>设计领域模型的一般步骤</h3><ol>
<li>根据需求建立一个初步的领域模型，<strong>识别出一些明显的领域概念以及它们的关联</strong>，关联可以暂时没有方向但需要有（1：1，1：N，M：N）这些关系；可以用文字精确的没有歧义的描述出每个领域概念的涵义以及包含的主要信息；</li>
<li><strong>分析主要的软件应用程序功能，识别出主要的应用层的类</strong>；这样有助于及早发现哪些是应用层的职责，哪些是领域层的职责；</li>
<li>进一步分析领域模型，<strong>识别出哪些是实体，哪些是值对象，哪些是领域服务</strong>；</li>
<li>分析关联，通过对业务的更深入分析以及各种软件设计原则及性能方面的权衡，<strong>明确关联的方向或者去掉一些不需要的关联</strong>；</li>
<li><strong>找出聚合边界及聚合根</strong>，这是一件很有难度的事情；因为你在分析的过程中往往会碰到很多模棱两可的难以清晰判断的选择问题，所以，需要我们平时一些分析经验的积累才能找出正确的聚合根；</li>
<li>为聚合根配备仓储，<strong>一般情况下是为一个聚合分配一个仓储</strong>，此时只要设计好仓储的接口即可；</li>
<li>走查场景，<strong>确定我们设计的领域模型能够有效地解决业务需求</strong>；</li>
<li><strong>考虑如何创建领域实体或值对象，是通过工厂还是直接通过构造函数</strong>；</li>
<li><strong>停下来重构模型</strong>。寻找模型中觉得有些疑问或者是蹩脚的地方，比如思考一些对象应该通过关联导航得到还是应该从仓储获取？聚合设计的是否正确？考虑模型的性能怎样，等等；</li>
</ol>
<h3 id="CQRS架构"><a href="#CQRS架构" class="headerlink" title="CQRS架构"></a>CQRS架构</h3><blockquote>
<p>核心思想是将应用程序的查询部分和命令部分完全分离，这两部分可以用完全不同的模型和技术去实现。比如命令部分可以通过领域驱动设计来实现；查询部分可以直接用最快的非面向对象的方式去实现，比如用SQL。这样的思想有很多好处：</p>
</blockquote>
<ol>
<li>实现命令部分的领域模型不用经常为了领域对象可能会被如何查询而做一些折中处理；</li>
<li>由于命令和查询是完全分离的，所以这两部分可以用不同的技术架构实现，包括数据库设计都可以分开设计，每一部分可以充分发挥其长处；</li>
<li>高性能，命令端因为没有返回值，可以像消息队列一样接受命令，放在队列中，慢慢处理；处理完后，可以通过异步的方式通知查询端，这样查询端可以做数据同步的处理；</li>
</ol>
<h3 id="四色原型分析模式"><a href="#四色原型分析模式" class="headerlink" title="四色原型分析模式"></a>四色原型分析模式</h3><p>用一句话来概括四色原型就是：一个什么什么样的人或组织或物品以某种角色在某个时刻或某段时间内参与某个活动。<br>其中“什么什么样的”就是DESC，“人或组织或物品”就是PPT，“角色”就是Role，而”某个时刻或某段时间内的某个活动”就是MI。</p>
<h3 id="cms项目应用"><a href="#cms项目应用" class="headerlink" title="cms项目应用"></a>cms项目应用</h3><ul>
<li>有Node、Edge、Graph、IVContent 四个实体，两个聚合（Graph, IVContent），其中Graph聚合包含多个Node实体和Edge实体，实体有状态也有行为(行为用于构建具体状态)</li>
<li>存在两个领域服务(GraphDomainService和IVContentDomainService)，定义了该实体的行为（比如create，update，delete，将实体的行为对应的状态进行实际的操作（一般是持久化））；领域服务包含仓储，提供实体的持久化以及查询功能</li>
<li>涉及多个实体之间的交互通过应用服务实现，比如创建课件版本这个需求（需要创建一个根节点和课件版本实体），需要一个 创建课件版本 的应用服务，该服务聚合Node领域服务和IVContent领域服务。</li>
</ul>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://zhuanlan.zhihu.com/p/361427612">https://zhuanlan.zhihu.com/p/361427612</a></p>
]]></content>
  </entry>
  <entry>
    <title>go 内存分配器</title>
    <url>/2022/12/09/go-memory-allocator/</url>
    <content><![CDATA[<blockquote>
<p>内存分配是 Go 语言运行时内存管理的核心逻辑，运行时的内存分配器使用类似 TCMalloc 的分配策略将对象根据大小分类，并设计多层级的组件提高内存分配器的性能。</p>
</blockquote>
<span id="more"></span>
<h2 id="设计原理"><a href="#设计原理" class="headerlink" title="设计原理"></a>设计原理</h2><p>内存管理一般包含三个不同的组件，分别是用户程序（Mutator）、分配器（Allocator）和收集器（Collector）1，当用户程序申请内存时，它会通过内存分配器申请新内存，而分配器会负责从堆中初始化相应的内存区域。<br><img src="/images/go_memory_alllocator/img_1.png" alt="img_1.png"></p>
<h3 id="分配方法"><a href="#分配方法" class="headerlink" title="分配方法"></a>分配方法</h3><blockquote>
<p>编程语言的内存分配器一般包含两种分配方法，一种是线性分配器（Sequential Allocator，Bump Allocator），另一种是空闲链表分配器（Free-List Allocator），</p>
</blockquote>
<h4 id="线性分配器"><a href="#线性分配器" class="headerlink" title="线性分配器"></a>线性分配器</h4><p>线性分配（Bump Allocator）是一种高效的内存分配方法，但是有较大的局限性。当我们使用线性分配器时，只需要在内存中维护一个指向内存特定位置的指针，如果用户程序向分配器申请内存，分配器只需要检查剩余的空闲内存、返回分配的内存区域并修改指针在内存中的位置，即移动下图中的指针：</p>
<ul>
<li>线性分配器无法在内存被释放时重用内存， 所以需要与合适的垃圾回收算法配合使用，例如：标记压缩（Mark-Compact）、复制回收（Copying GC）和分代回收（Generational GC）等算法，它们可以通过拷贝的方式整理存活对象的碎片，将空闲内存定期合并，这样就能利用线性分配器的效率提升内存分配器的性能了。</li>
<li>因为线性分配器需要与具有拷贝特性的垃圾回收算法配合，所以 C 和 C++ 等需要直接对外暴露指针的语言就无法使用该策略<br><img src="/images/go_memory_alllocator/img_2.png" alt="img_2.png"></li>
</ul>
<h4 id="空闲链表分配器"><a href="#空闲链表分配器" class="headerlink" title="空闲链表分配器"></a>空闲链表分配器</h4><p>空闲链表分配器（Free-List Allocator）可以重用已经被释放的内存，它在内部会维护一个类似链表的数据结构。当用户程序申请内存时，空闲链表分配器会依次遍历空闲的内存块，找到足够大的内存，然后申请新的资源并修改链表</p>
<ul>
<li>隔离适应（Segregated-Fit） 分配策略：  将内存分割成多个链表，每个链表中的内存块大小相同，申请内存时先找到满足条件的链表，再从链表中选择合适的内存块；<br><img src="/images/go_memory_alllocator/img_3.png" alt="img_3.png"></li>
</ul>
<h3 id="分级分配"><a href="#分级分配" class="headerlink" title="分级分配"></a>分级分配</h3><blockquote>
<p>Go 语言的内存分配器就借鉴了 TCMalloc 的设计实现高速的内存分配，它的核心理念是使用<strong>多级缓存</strong>将对象根据<strong>大小分类</strong>，并按照类别实施不同的分配策略。</p>
</blockquote>
<h4 id="多级缓存"><a href="#多级缓存" class="headerlink" title="多级缓存"></a>多级缓存</h4><p>内存分配器不仅会区别对待大小不同的对象，还会将内存分成不同的级别分别管理，TCMalloc 和 Go 运行时分配器都会引入线程缓存（Thread Cache）、中心缓存（Central Cache）和页堆（Page Heap）三个组件分级管理内存：<br><img src="/images/go_memory_alllocator/img_4.png" alt="img_4.png"><br>线程缓存属于每一个独立的线程，它能够满足线程上绝大多数的内存分配需求，因为不涉及多线程，所以也不需要使用互斥锁来保护内存，这能够减少锁竞争带来的性能损耗。当线程缓存不能满足需求时，运行时会使用中心缓存作为补充解决小对象的内存分配，在遇到 32KB 以上的对象时，内存分配器会选择页堆直接分配大内存。</p>
<h3 id="虚拟内存布局"><a href="#虚拟内存布局" class="headerlink" title="虚拟内存布局"></a>虚拟内存布局</h3><p>在 Go 语言 1.10 以前的版本，堆区的内存空间都是连续的；但是在 1.11 版本，Go 团队使用稀疏的堆内存空间替代了连续的内存，解决了连续内存带来的限制以及在特殊场景下可能出现的问题。</p>
<h4 id="线性内存"><a href="#线性内存" class="headerlink" title="线性内存"></a>线性内存</h4><p><img src="/images/go_memory_alllocator/img_5.png" alt="img_5.png"><br>在 C 和 Go 混合使用时会导致程序崩溃：</p>
<ol>
<li>分配的内存地址会发生冲突，导致堆的初始化和扩容失败；</li>
<li>没有被预留的大块内存可能会被分配给 C 语言的二进制，导致扩容后的堆不连续；</li>
</ol>
<h4 id="稀疏内存"><a href="#稀疏内存" class="headerlink" title="稀疏内存"></a>稀疏内存</h4><p>使用稀疏的内存布局不仅能移除堆大小的上限，还能解决 C 和 Go 混合使用时的地址空间冲突问题。不过因为基于稀疏内存的内存管理失去了内存的连续性这一假设，这也使内存管理变得更加复杂：<br><img src="/images/go_memory_alllocator/img_6.png" alt="img_6.png"><br>如上图所示，运行时使用二维的 runtime.heapArena 数组管理所有的内存，每个单元都会管理 64MB 的内存空间：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> heapArena <span class="keyword">struct</span> &#123;</span><br><span class="line">    bitmap       [heapArenaBitmapBytes]<span class="keyword">byte</span></span><br><span class="line">    spans        [pagesPerArena]*mspan</span><br><span class="line">    pageInUse    [pagesPerArena / <span class="number">8</span>]<span class="keyword">uint8</span></span><br><span class="line">    pageMarks    [pagesPerArena / <span class="number">8</span>]<span class="keyword">uint8</span></span><br><span class="line">    pageSpecials [pagesPerArena / <span class="number">8</span>]<span class="keyword">uint8</span></span><br><span class="line">    checkmarks   *checkmarksMap</span><br><span class="line">    zeroedBase   <span class="keyword">uintptr</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>每个 runtime.heapArena 都会管理 64MB 的内存，整个堆区最多可以管理 256TB 的内存，这比之前的 512GB 多好几个数量级。</p>
<h2 id="内存管理组件"><a href="#内存管理组件" class="headerlink" title="内存管理组件"></a>内存管理组件</h2><blockquote>
<p>Go 语言的内存分配器包含内存管理单元、线程缓存、中心缓存和页堆几个重要组件，本节将介绍这几种最重要组件对应的数据结构 runtime.mspan、runtime.mcache、runtime.mcentral 和 runtime.mheap，我们会详细介绍它们在内存分配器中的作用以及实现。<br><img src="/images/go_memory_alllocator/img_7.png" alt="img_7.png"></p>
</blockquote>
<p>所有的 Go 语言程序都会在启动时初始化如上图所示的内存布局，每一个处理器都会分配一个线程缓存 runtime.mcache 用于处理微对象和小对象的分配，它们会持有内存管理单元 runtime.mspan。</p>
<p>每个类型的内存管理单元都会管理特定大小的对象，当内存管理单元中不存在空闲对象时，它们会从 runtime.mheap 持有的 134 个中心缓存 runtime.mcentral 中获取新的内存单元，中心缓存属于全局的堆结构体 runtime.mheap，它会从操作系统中申请内存。</p>
<h3 id="内存管理单元"><a href="#内存管理单元" class="headerlink" title="内存管理单元"></a>内存管理单元</h3><h4 id="页和内存"><a href="#页和内存" class="headerlink" title="页和内存"></a>页和内存</h4><p>每个 runtime.mspan 都管理 npages 个大小为 8KB 的页，这里的页不是操作系统中的内存页，它们是操作系统内存页的整数倍，该结构体会使用下面这些字段来管理内存页的分配和回收：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> mspan <span class="keyword">struct</span> &#123;</span><br><span class="line">	startAddr <span class="keyword">uintptr</span> <span class="comment">// 起始地址</span></span><br><span class="line">	npages    <span class="keyword">uintptr</span> <span class="comment">// 页数</span></span><br><span class="line">	freeindex <span class="keyword">uintptr</span></span><br><span class="line"></span><br><span class="line">	allocBits  *gcBits</span><br><span class="line">	gcmarkBits *gcBits</span><br><span class="line">	allocCache <span class="keyword">uint64</span></span><br><span class="line">	.</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>startAddr 和 npages — 确定该结构体管理的多个页所在的内存，每个页的大小都是 8KB；</li>
<li>freeindex — 扫描页中空闲对象的初始索引；</li>
<li>allocBits 和 gcmarkBits — 分别用于标记内存的占用和回收情况；</li>
<li>allocCache — allocBits 的补码，可以用于快速查找内存中未被使用的内存；</li>
</ul>
<h4 id="跨度类"><a href="#跨度类" class="headerlink" title="跨度类"></a>跨度类</h4><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> mspan <span class="keyword">struct</span> &#123;</span><br><span class="line">	.</span><br><span class="line">	spanclass   spanClass</span><br><span class="line">	.</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>Go 语言的内存管理模块中一共包含 67 种跨度类，每一个跨度类都会存储特定大小的对象并且包含特定数量的页数以及对象，所有的数据都会被预选计算好并存储在 runtime.class_to_size 和 runtime.class_to_allocnpages 等变量中：</p>
</li>
<li><p>除了上述 67 个跨度类之外，运行时中还包含 ID 为 0 的特殊跨度类，它能够管理大于 32KB 的特殊对象，我们会在后面详细介绍大对象的分配过程</p>
</li>
</ul>
<h3 id="线程缓存"><a href="#线程缓存" class="headerlink" title="线程缓存"></a>线程缓存</h3><p>runtime.mcache 是 Go 语言中的线程缓存，它会与线程上的处理器一一绑定，主要用来缓存用户程序申请的微小对象。每一个线程缓存都持有 68 * 2 个 runtime.mspan，<br>这些内存管理单元都存储在结构体的 alloc 字段中<br><img src="/images/go_memory_alllocator/img.png" alt="img.png"></p>
<h4 id="微分配器"><a href="#微分配器" class="headerlink" title="微分配器"></a>微分配器</h4><ul>
<li>线程缓存中还包含几个用于分配微对象的字段</li>
<li>微分配器只会用于分配非指针类型的内存</li>
</ul>
<h3 id="中心缓存"><a href="#中心缓存" class="headerlink" title="中心缓存"></a>中心缓存</h3><ul>
<li>与线程缓存不同，访问中心缓存中的内存管理单元需要使用互斥锁<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> mcentral <span class="keyword">struct</span> &#123;</span><br><span class="line">	spanclass spanClass</span><br><span class="line">	partial  [<span class="number">2</span>]spanSet</span><br><span class="line">	full     [<span class="number">2</span>]spanSet</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
每个中心缓存都会管理某个跨度类的内存管理单元**，它会同时持有两个 runtime.spanSet，分别存储包含空闲对象和不包含空闲对象的内存管理单元。<h4 id="内存管理单元分配"><a href="#内存管理单元分配" class="headerlink" title="内存管理单元分配"></a>内存管理单元分配</h4>线程缓存会通过中心缓存的 runtime.mcentral.cacheSpan 方法获取新的内存管理单元，该方法的实现比较复杂，我们可以将其分成以下几个部分：</li>
</ul>
<ol>
<li>调用 runtime.mcentral.partialSwept 从清理过的、包含空闲空间的 runtime.spanSet 结构中查找可以使用的内存管理单元；</li>
<li>调用 runtime.mcentral.partialUnswept 从未被清理过的、有空闲对象的 runtime.spanSet 结构中查找可以使用的内存管理单元；</li>
<li>调用 runtime.mcentral.fullUnswept 获取未被清理的、不包含空闲空间的 runtime.spanSet 中获取内存管理单元并通过 runtime.mspan.sweep 清理它的内存空间；</li>
<li>调用 runtime.mcentral.grow 从堆中申请新的内存管理单元；<br>更新内存管理单元的 allocCache 等字段帮助快速分配内存；</li>
</ol>
<h3 id="页堆"><a href="#页堆" class="headerlink" title="页堆"></a>页堆</h3><p>runtime.mheap 是内存分配的核心结构体，Go 语言程序会将其作为全局变量存储，而堆上初始化的所有对象都由该结构体统一管理，该结构体中包含两组非常重要的字段，其中一个是全局的中心缓存列表 central，另一个是管理堆区内存区域的 arenas 以及相关字段。<br><img src="/images/go_memory_alllocator/img_8.png" alt="img_8.png"></p>
<h4 id="内存管理单元分配-1"><a href="#内存管理单元分配-1" class="headerlink" title="内存管理单元分配"></a>内存管理单元分配</h4><ol>
<li>从堆上分配新的内存页和内存管理单元 runtime.mspan；</li>
<li>初始化内存管理单元并将其加入 runtime.mheap 持有内存单元列表；</li>
</ol>
<h4 id="申请内存"><a href="#申请内存" class="headerlink" title="申请内存"></a>申请内存</h4><ol>
<li>如果申请的内存比较小，获取申请内存的处理器并尝试调用 runtime.pageCache.alloc 获取内存区域的基地址和大小；</li>
<li>如果申请的内存比较大或者<strong>线程的页缓存</strong>中内存不足，会通过 runtime.pageAlloc.alloc <strong>在页堆上申请内存</strong>；</li>
<li>如果发现页堆上的内存不足，会尝试通过 runtime.mheap.grow 扩容并重新调用 runtime.pageAlloc.alloc 申请内存；<ol>
<li>如果申请到内存，意味着扩容成功；</li>
<li>如果没有申请到内存，意味着扩容失败，<strong>宿主机可能不存在空闲内存</strong>，运行时会直接中止当前程序；</li>
</ol>
</li>
</ol>
<h2 id="内存分配"><a href="#内存分配" class="headerlink" title="内存分配"></a>内存分配</h2><p>微对象 (0, 16B) — 先使用微型分配器，再依次尝试线程缓存、中心缓存和堆分配内存；<br>小对象 [16B, 32KB] — 依次尝试使用线程缓存、中心缓存和堆分配内存；<br>大对象 (32KB, +∞) — 直接在堆上分配内存；</p>
<h3 id="小对象"><a href="#小对象" class="headerlink" title="小对象"></a>小对象</h3><blockquote>
<p>小对象是指大小为 16 字节到 32,768 字节的对象以及所有小于 16 字节的指针类型的对象，小对象的分配可以被分成以下的三个步骤：</p>
</blockquote>
<ol>
<li>确定分配对象的大小以及跨度类 runtime.spanClass；</li>
<li>从线程缓存、中心缓存或者堆中获取内存管理单元并从内存管理单元找到空闲的内存空间；</li>
<li>调用 runtime.memclrNoHeapPointers 清空空闲内存中的所有数据；</li>
</ol>
<h3 id="大对象"><a href="#大对象" class="headerlink" title="大对象"></a>大对象</h3><p>运行时对于大于 32KB 的大对象会单独处理，我们不会从线程缓存或者中心缓存中获取内存管理单元</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/">go-内存分配器</a></p>
]]></content>
  </entry>
  <entry>
    <title>go调度器详解</title>
    <url>/2022/12/10/go-%E8%B0%83%E5%BA%A6%E5%99%A8/</url>
    <content><![CDATA[<blockquote>
<p>Go 语言的调度器通过使用<strong>与 CPU 数量相等的线程减少线程频繁切换的内存开销</strong>，同时在每一个线程上执行额外开销更低的 Goroutine 来<strong>降低操作系统和硬件的负载</strong></p>
</blockquote>
<span id="more"></span>
<h2 id="设计原理"><a href="#设计原理" class="headerlink" title="设计原理"></a>设计原理</h2><h3 id="任务窃取调度器"><a href="#任务窃取调度器" class="headerlink" title="任务窃取调度器"></a>任务窃取调度器</h3><ol>
<li>在当前的 G-M 模型中引入了处理器 P，增加中间层；</li>
<li>在处理器 P 的基础上实现基于工作窃取的调度器</li>
</ol>
<p>基于工作窃取的多线程调度器将每一个线程绑定到了独立的 CPU 上，这些线程会被不同处理器管理，不同的处理器通过工作窃取对任务进行再分配实现任务的平衡，</p>
<h3 id="抢占式调度"><a href="#抢占式调度" class="headerlink" title="抢占式调度"></a>抢占式调度</h3><h4 id="基于协作的抢占式调度"><a href="#基于协作的抢占式调度" class="headerlink" title="基于协作的抢占式调度"></a>基于协作的抢占式调度</h4><ol>
<li>编译器会在<strong>调用函数前插入</strong> runtime.morestack；</li>
<li>Go 语言运行时会<strong>在垃圾回收暂停程序、系统监控发现 Goroutine 运行超过 10ms 时发出抢占请求 StackPreempt</strong>；</li>
<li>当发生函数调用时，可能会执行编译器插入的 runtime.morestack，它调用的 runtime.newstack 会检查 Goroutine 的 stackguard0 字段是否为 StackPreempt；</li>
<li>如果 stackguard0 是 StackPreempt，就会<strong>触发抢占让出当前线程</strong>；</li>
</ol>
<ul>
<li>一个 Go 语言程序能够创建的最大线程数，虽然最多可以创建 10000 个线程，但是可以同时运行的线程还是由 GOMAXPROCS 变量控制。<h4 id="基于信号的抢占式调度"><a href="#基于信号的抢占式调度" class="headerlink" title="基于信号的抢占式调度"></a>基于<strong>信号</strong>的抢占式调度</h4></li>
</ul>
<ol>
<li>目前的抢占式调度也只会在垃圾回收扫描任务时触发</li>
<li>基于信号的抢占式调度只解决了垃圾回收和栈扫描时存在的问题，它到目前为止没有解决所有问题</li>
</ol>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><ol>
<li>G — 表示 Goroutine，它是一个待执行的任务；</li>
<li>M — <strong>表示操作系统的线程</strong>，它由操作系统的调度器调度和管理；<br> 1.Go 语言并发模型中的 M 是操作系统线程。调度器最多可以创建 10000 个线程，但是其中大多数的线程都不会执行用户代码（可能陷入系统调用），<strong>最多只会有 GOMAXPROCS 个活跃线程能够正常运行</strong></li>
<li>P — <strong>表示处理器</strong>，它可以被看做运行在线程上的本地调度器； <ol>
<li>调度器中的处理器 P 是线程和 Goroutine 的中间层，它能提供线程需要的上下文环境，也会负责调度线程上的等待队列，通过处理器 P 的调度，每一个内核线程都能够执行多个 Goroutine，它能在 Goroutine 进行一些 I/O 操作时及时让出计算资源，提高线程的利用率。 </li>
<li>因为调度器在启动时就会创建 GOMAXPROCS 个处理器，所以 Go 语言程序的处理器数量一定会等于 GOMAXPROCS，这些处理器会绑定到不同的内核线程上。</li>
</ol>
</li>
</ol>
<h2 id="创建goroutine"><a href="#创建goroutine" class="headerlink" title="创建goroutine"></a>创建goroutine</h2><h3 id="初始化结构体"><a href="#初始化结构体" class="headerlink" title="初始化结构体"></a>初始化结构体</h3><ul>
<li>会从处理器或者调度器的缓存中获取新的结构体，取不到调用 runtime.malg 函数创建。<h3 id="运行队列"><a href="#运行队列" class="headerlink" title="运行队列"></a>运行队列</h3>这既可能是全局的运行队列，也可能是处理器本地的运行队列：</li>
</ul>
<ol>
<li>当 next 为 true 时，将 Goroutine 设置到处理器的 runnext 作为下一个处理器执行的任务；</li>
<li>当 next 为 false 并且本地运行队列还有剩余空间时，将 Goroutine 加入处理器持有的本地运行队列；</li>
<li>当处理器的本地运行队列已经没有剩余空间时就会把本地队列中的一部分 Goroutine 和待加入的 Goroutine 通过 runtime.runqputslow 添加到调度器持有的全局运行队列上；</li>
</ol>
<ul>
<li>简单总结一下，<strong>Go 语言有两个运行队列，其中一个是处理器本地的运行队列，另一个是调度器持有的全局运行队列，只有在本地运行队列没有剩余空间时才会使用全局队列</strong>。<h3 id="调度信息"><a href="#调度信息" class="headerlink" title="调度信息"></a>调度信息</h3></li>
</ul>
<h2 id="循环调度"><a href="#循环调度" class="headerlink" title="循环调度"></a>循环调度</h2><p><img src="/images/go_schedule/img.png" alt="img.png"></p>
<ul>
<li>我们可以认为调度循环永远都不会返回。</li>
<li>Go 语言中的运行时调度循环属于P维度，一个P运行一个M,对应一个schedule,会从 runtime.schedule 开始，最终又回到 runtime.schedule</li>
</ul>
<ul>
<li><p>runtime.schedule 函数会从下面几个地方查找待执行的 Goroutine：</p>
<ol>
<li>为了保证公平，当全局运行队列中有待执行的 Goroutine 时，通过 schedtick 保证有一定几率会从全局的运行队列中查找对应的 Goroutine；</li>
<li>从处理器本地的运行队列中查找待执行的 Goroutine；</li>
<li>如果前两种方法都没有找到 Goroutine，会通过 runtime.findrunnable 进行阻塞地查找 Goroutine； <ul>
<li>runtime.findrunnable 的实现非常复杂，这个 300 多行的函数通过以下的过程获取可运行的 Goroutine：<ol>
<li>从本地运行队列、全局运行队列中查找；</li>
<li>从网络轮询器中查找是否有 Goroutine 等待运行；</li>
<li>通过 runtime.runqsteal 尝试从其他随机的处理器中窃取待运行的 Goroutine，该函数还可能窃取处理器的计时器；</li>
</ol>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<h2 id="触发调度"><a href="#触发调度" class="headerlink" title="触发调度"></a>触发调度</h2><p><img src="/images/go_schedule/img_1.png" alt="img_1.png"></p>
<p>除了上图中可能触发调度的时间点，运行时还会在线程启动 runtime.mstart 和 Goroutine 执行结束 runtime.goexit0 触发调度。我们在这里会重点介绍运行时触发调度的几个路径：</p>
<ul>
<li>主动挂起 — runtime.gopark -&gt; runtime.park_m</li>
<li>系统调用 — runtime.exitsyscall -&gt; runtime.exitsyscall0</li>
<li>协作式调度 — runtime.Gosched -&gt; runtime.gosched_m -&gt; runtime.goschedImpl</li>
<li>系统监控 — runtime.sysmon -&gt; runtime.retake -&gt; runtime.preemptone<br>我们在这里介绍的调度时间点不是将线程的运行权直接交给其他任务，而是通过调度器的 runtime.schedule 重新调度。<h3 id="主动挂起"><a href="#主动挂起" class="headerlink" title="主动挂起"></a>主动挂起</h3></li>
</ul>
<ol>
<li>runtime.park_m 会将当前 Goroutine 的状态从 _Grunning 切换至 _Gwaiting，调用 runtime.dropg 移除线程和 Goroutine 之间的关联，<br>在这之后就可以调用 runtime.schedule 触发新一轮的调度了。</li>
<li>runtime.ready 会将准备就绪的 Goroutine 的状态切换至 _Grunnable 并将其加入处理器的运行队列中，等待调度器的调度。</li>
</ol>
<h3 id="系统调用"><a href="#系统调用" class="headerlink" title="系统调用"></a>系统调用</h3><p>需要注意的是 runtime.reentersyscall 会使处理器和线程的分离，当前线程会陷入系统调用等待返回，<strong>在锁被释放后，会有其他 Goroutine 抢占处理器资源</strong>。</p>
<h3 id="协作式调度"><a href="#协作式调度" class="headerlink" title="协作式调度"></a>协作式调度</h3><p>主动让出处理器，允许其他 Goroutine 运行。该函数无法挂起 Goroutine，调度器可能会将当前 Goroutine 调度到其他线程上<br>运行时会更新 Goroutine 的状态到 _Grunnable，让出当前的处理器并将 Goroutine 重新放回全局队列，在最后，该函数会调用 runtime.schedule 触发调度。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-goroutine/#%E5%8D%8F%E4%BD%9C%E5%BC%8F%E8%B0%83%E5%BA%A6">go语言设计与实现-调度器</a></p>
]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>调度器</tag>
      </tags>
  </entry>
  <entry>
    <title>go栈内存管理</title>
    <url>/2022/12/30/go-stack-management/</url>
    <content><![CDATA[<h2 id="设计原理"><a href="#设计原理" class="headerlink" title="设计原理"></a>设计原理</h2><p>栈区的内存一般由编译器自动分配和释放，<strong>其中存储着函数的入参以及局部变量，这些参数会随着函数的创建而创建，函数的返回而消亡，一般不会在程序中长期存在</strong>，<br>这种线性的内存分配策略有着极高地效率，但是工程师也往往不能控制栈内存的分配，这部分工作基本都是由编译器完成的。</p>
<span id="more"></span>
<h3 id="寄存器"><a href="#寄存器" class="headerlink" title="寄存器"></a>寄存器</h3><ol>
<li><p>Go 语言的汇编代码包含 BP 和 SP 两个栈寄存器，它们分别存储了栈的基址指针和栈顶的地址<br><img src="/images/go_stack_management/img.png" alt="img.png"></p>
</li>
<li><p>当应用程序申请或者释放栈内存时只需要修改 SP 寄存器的值，这种线性的内存分配方式与堆内存相比更加快速，仅会带来极少的额外开销。</p>
<h3 id="线程栈"><a href="#线程栈" class="headerlink" title="线程栈"></a>线程栈</h3></li>
<li><p>多数架构上默认栈大小都在 2 ~ 4 MB 左右，极少数架构会使用 32 MB 的栈，用户程序可以在分配的栈上存储函数参数和局部变量。</p>
</li>
<li><p>线程和进程都是代码执行的上下文，但是如果一个应用程序包含成百上千个执行上下文并且每个上下文都是线程，会占用大量的内存空间并带来其他的额外开销，<br>Go 语言在设计时认为执行上下文是轻量级的，所以它在用户态实现 Goroutine 作为执行上下文。</p>
<h3 id="逃逸分析"><a href="#逃逸分析" class="headerlink" title="逃逸分析"></a>逃逸分析</h3><p>手动分配内存会导致如下的两个问题：</p>
</li>
<li><p>不需要分配到堆上的对象分配到了堆上 — 浪费内存空间；</p>
</li>
<li><p>需要分配到堆上的对象分配到了栈上 — 悬挂指针、影响内存安全；<br>在编译器优化中，<strong>逃逸分析是用来决定指针动态作用域的方法</strong>。</p>
</li>
</ol>
<ul>
<li>Go 语言的编译器使用逃逸分析决定哪些变量应该在栈上分配，哪些变量应该在堆上分配，其中包括使用 new、make 和字面量等方法隐式分配的内存，Go 语言的逃逸分析遵循以下两个不变性：</li>
</ul>
<ol>
<li>指向栈对象的指针不能存在于堆中；</li>
<li>指向栈对象的指针不能在栈对象回收后存活；<br><img src="/images/go_stack_management/img_1.png" alt="img_1.png"></li>
</ol>
<h3 id="栈内存空间"><a href="#栈内存空间" class="headerlink" title="栈内存空间"></a>栈内存空间</h3><p>Goroutine 的初始栈大小为 2KB</p>
<h4 id="分段栈"><a href="#分段栈" class="headerlink" title="分段栈"></a>分段栈</h4><p> <img src="/images/go_stack_management/img_2.png" alt="img_2.png"></p>
<p>分段栈机制虽然能够按需为当前 Goroutine 分配内存并且及时减少内存的占用，但是它也存在两个比较大的问题：</p>
<ol>
<li>如果当前 Goroutine 的栈几乎充满，那么任意的函数调用都会触发栈扩容，当函数返回后又会触发栈的收缩，如果在一个循环中调用函数，栈的分配和释放就会造成巨大的额外开销，<strong>这被称为热分裂问题</strong>（Hot split）；</li>
<li>一旦 Goroutine <strong>使用的内存越过了分段栈的扩缩容阈值</strong>，运行时会触发栈的扩容和缩容，带来额外的工作量；</li>
</ol>
<h4 id="连续栈"><a href="#连续栈" class="headerlink" title="连续栈"></a>连续栈</h4><p>连续栈可以解决分段栈中存在的两个问题，其核心原理是每当程序的栈空间不足时，初始化一片更大的栈空间并将原栈中的所有值都迁移到新栈中，<br>新的局部变量或者函数调用就有充足的内存空间。使用连续栈机制时，栈空间不足导致的扩容会经历以下几个步骤：</p>
<ol>
<li>在内存空间中分配更大的栈内存空间；</li>
<li>将旧栈中的所有内容复制到新栈中；</li>
<li><strong>将指向旧栈对应变量的指针重新指向新栈</strong>；</li>
<li>销毁并回收旧栈的内存空间；<br><img src="/images/go_stack_management/img_3.png" alt="img_3.png"><br>因为需要拷贝变量和调整指针，连续栈增加了栈扩容时的额外开销，但是通过合理栈缩容机制就能避免热分裂带来的性能问题10，在 GC 期间如果 Goroutine 使用了栈内存的四分之一，<br>那就将其内存减少一半，这样在栈内存几乎充满时也只会扩容一次，不会因为函数调用频繁扩缩容。</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-stack-management/#%E7%BA%BF%E7%A8%8B%E6%A0%88">go-栈内存管理</a></p>
]]></content>
      <categories>
        <category>go</category>
        <category>内存</category>
      </categories>
      <tags>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title>https</title>
    <url>/2022/05/12/2022-5-12-https/</url>
    <content><![CDATA[<h2 id="HTTPS-的核心—SSL-TLS协议"><a href="#HTTPS-的核心—SSL-TLS协议" class="headerlink" title="HTTPS 的核心—SSL/TLS协议"></a>HTTPS 的核心—SSL/TLS协议</h2><p>HTTPS 之所以能达到较高的安全性要求，就是结合了 SSL/TLS 和 TCP 协议，对通信数据进行加密，解决了 HTTP 数据透明的问题。接下来重点介绍一下 SSL/TLS 的工作原理。</p>
<p>###SSL 和 TLS 的区别？<br>SSL 和 TLS 没有太大的区别。</p>
<ul>
<li>SSL 指安全套接字协议（Secure Sockets Layer），首次发布与 1996 年。SSL 的首次发布其实已经是他的 3.0 版本，SSL 1.0 从未面世，SSL 2.0<br>则具有较大的缺陷（DROWN 缺陷——Decrypting RSA with Obsolete and Weakened eNcryption）。很快，在 1999 年，SSL 3.0 进一步升级，<br>新版本被命名为 TLS 1.0。因此，TLS 是基于 SSL 之上的，但由于习惯叫法，通常把 HTTPS 中的核心加密协议混成为 SSL/TLS。</li>
</ul>
<h3 id="SSL-TLS-的工作原理"><a href="#SSL-TLS-的工作原理" class="headerlink" title="SSL/TLS 的工作原理"></a>SSL/TLS 的工作原理</h3><h4 id="非对称加密"><a href="#非对称加密" class="headerlink" title="非对称加密"></a>非对称加密</h4><p>SSL/TLS 的核心要素是非对称加密。非对称加密采用两个密钥——一个公钥，一个私钥。在通信时，私钥仅由解密者保存，公钥由任何一个想与解密者通信的发送者（加密者）所知。<br>发送者使用公钥加密信息，接收者使用私钥解密信息。这样，即使通信信息被其他人截获了，因为不知道对应的私钥，也就无法解密。这依赖于私钥的保密性。<br><img src="/images/https/img.png" alt="img.png"></p>
<h4 id="对称加密"><a href="#对称加密" class="headerlink" title="对称加密"></a>对称加密</h4><p>使用 SSL/TLS 进行通信的双方需要使用非对称加密方案来通信，但是非对称加密设计了较为复杂的数学算法，在实际通信过程中，<strong>计算的代价较高，效率太低</strong>，因此，<strong>SSL/TLS 实际对消息的加密使用的是对称加密。</strong></p>
<p>对称加密：通信双方共享唯一密钥 k，加解密算法已知，加密方利用密钥 k 加密，解密方利用密钥 k 解密，<strong>保密性依赖于密钥 k 的保密性</strong>。<br><img src="/images/https/img_1.png" alt="img_1.png"></p>
<p>对称加密的密钥生成代价比公私钥对的生成代价低得多，那么有的人会问了，为什么 SSL/TLS 还需要使用非对称加密呢？因为对称加密的保密性完全依赖于密钥的保密性。<br>在双方通信之前，需要商量一个用于对称加密的密钥。我们知道网络通信的信道是不安全的，传输报文对任何人是可见的，密钥的交换肯定不能直接在网络信道中传输。<br>因此，<strong>使用非对称加密，对对称加密的密钥进行加密，保护该密钥不在网络信道中被窃听。这样，通信双方只需要一次非对称加密，交换对称加密的密钥，在之后的信息通信中，使用绝对安全的密钥，对信息进行对称加密，即可保证传输消息的保密性。</strong></p>
<h4 id="公钥传输的信赖性"><a href="#公钥传输的信赖性" class="headerlink" title="公钥传输的信赖性"></a>公钥传输的信赖性</h4><p>SSL/TLS 介绍到这里，了解信息安全的朋友又会想到一个安全隐患，设想一个下面的场景：</p>
<p>客户端 C 和服务器 S 想要使用 SSL/TLS 通信，由上述 SSL/TLS 通信原理，C 需要先知道 S 的公钥，而 S 公钥的唯一获取途径，就是把 S 公钥在网络信道中传输。要注意网络信道通信中有几个前提：</p>
<ol>
<li>任何人都可以捕获通信包</li>
<li>通信包的保密性由发送者设计</li>
<li>保密算法设计方案默认为公开，而（解密）密钥默认是安全的<br>因此，假设 S的公钥不做加密，在信道中传输，那么很有可能存在一个攻击者 A，发送给 C 一个诈包，假装是 S的 公钥，其实是诱饵服务器 AS 的公钥。当 C 收获了 AS 的公钥（却以为是 S 的公钥），C 后续就会使用 AS 公钥对数据进行加密，并在公开信道传输，<br>那么 A 将捕获这些加密包，用 AS 的私钥解密，就截获了 C 本要给 S 发送的内容，而 C 和 S 二人全然不知。</li>
</ol>
<p>同样的，S 公钥即使做加密，也难以避免这种信任性问题，C 被 AS 拐跑了！</p>
<p><img src="/images/https/img_2.png" alt="img_2.png"></p>
<p>为了公钥传输的信赖性问题，第三方机构应运而生——<strong>证书颁发机构</strong>（CA，Certificate Authority）。CA 默认是受信任的第三方。<strong>CA 会给各个服务器颁发证书，证书存储在服务器上，并附有 CA 的电子签名</strong>（见下节）。</p>
<p><strong>当客户端（浏览器）向服务器发送 HTTPS 请求时，一定要先获取目标服务器的证书，并根据证书上的信息，检验证书的合法性。一旦客户端检测到证书非法，就会发生错误。客户端获取了服务器的证书后，由于证书的信任性是由第三方信赖机构认证的，而证书上又包含着服务器的公钥信息，客户端就可以放心的信任证书上的公钥就是目标服务器的公钥。</strong></p>
<h4 id="数字签名"><a href="#数字签名" class="headerlink" title="数字签名"></a>数字签名</h4><p>好，到这一小节，已经是 SSL/TLS 的尾声了。上一小节提到了数字签名，数字签名要解决的问题，是防止证书被伪造。第三方信赖机构 CA 之所以能被信赖，就是靠 <strong>数字签名技术</strong> 。</p>
<p>数字签名，是 CA 在给服务器颁发证书时，使用<strong>散列+加密</strong>的组合技术，<strong>在证书上盖个章，以此来提供验伪的功能</strong>。具体行为如下：</p>
<blockquote>
<ol>
<li>CA 知道服务器的公钥，对证书采用散列技术生成一个摘要。CA 使用 CA 私钥对该摘要进行加密，并附在证书下方，发送给服务器。<ol>
<li>hash(证书（包含服务器公钥）) = 摘要 </li>
<li>ca私钥（摘要） = 签名</li>
</ol>
</li>
<li>现在服务器将该证书发送给客户端，客户端需要验证该证书的身份。客户端找到第三方机构 CA，<strong>获知 CA 的公钥（默认存储在浏览器信任的根或中间ca证书中）</strong>，并用 CA 公钥对证书的签名进行解密，获得了 CA 生成的摘要。<ol>
<li>ca公钥（签名） = 摘要2</li>
</ol>
</li>
<li>客户端对证书数据（包含服务器的公钥）做相同的散列处理，得到摘要，并将该摘要与之前从签名中解码出的摘要做对比，如果相同，则身份验证成功；否则验证失败。<ol>
<li>hash(证书) = 摘要3</li>
<li>摘要2 == 摘要3 签名有效</li>
</ol>
</li>
</ol>
</blockquote>
<p><img src="/images/https/img_4.png" alt="img_4.png"></p>
<p>总结来说，带有证书的公钥传输机制如下：</p>
<ol>
<li>设1. 有服务器 S，客户端 C，和第三方信赖机构 CA。</li>
<li>S 信任 CA，CA 是知道 S 公钥的，CA 向 S 颁发证书。并附上 CA 私钥对消息摘要的加密签名。</li>
<li>S 获得 CA 颁发的证书，将该证书传递给 C。</li>
<li>C 获得 S 的证书，信任 CA 并知晓 CA 公钥，使用 CA 公钥对 S 证书上的签名解密，同时对消息进行散列处理，得到摘要。比较摘要，验证 S 证书的真实性。</li>
<li>如果 C 验证 S 证书是真实的，则信任 S 的公钥（在 S 证书中）。<br><img src="/images/https/img_5.png" alt="img_5.png"></li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>端口号 ：HTTP 默认是 80，HTTPS 默认是 443。<br>URL 前缀 ：HTTP 的 URL 前缀是 http://，HTTPS 的 URL 前缀是 https://。<br>安全性和资源消耗 ： HTTP 协议运行在 TCP 之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS 是运行在 SSL/TLS 之上的 HTTP 协议，SSL/TLS 运行在 TCP 之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS 高，但是 HTTPS 比 HTTP 耗费更多服务器资源。<img src="/images/https/img_3.png" alt="img_3.png"></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://gitee.com/SnailClimb/JavaGuide/blob/main/docs/cs-basics/network/http&https.md">http and https</a></p>
]]></content>
  </entry>
  <entry>
    <title>事务</title>
    <url>/2023/01/02/transaction/</url>
    <content><![CDATA[<h2 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a>事务消息</h2><h3 id="rocketmq事务消息"><a href="#rocketmq事务消息" class="headerlink" title="rocketmq事务消息"></a>rocketmq事务消息</h3><p>RocketMQ采用了2PC的思想来实现了提交事务消息，同时增加一个补偿逻辑来处理二阶段超时或者失败的消息，流程如下图所示：<br><img src="/images/transaction/img.png" alt="img.png"><br>其具体工作流程分为正常事务消息的发送及提交和不正常情况下事务消息的补偿流程：</p>
<span id="more"></span>
<ol>
<li>在消息队列上开启一个事务主题。</li>
<li>事务中第一个执行的服务发送一条“半消息”（半消息和普通消息的唯一区别是，在事务提交之前，对于消费者来说，这个消息是不可见的）给消息队列。</li>
<li>半消息发送成功后，发送半消息的服务就会开始执行本地事务，根据本地事务执行结果来决定事务消息提交或者回滚。</li>
<li>本地事务成功后会让这个“半消息”变成正常消息，供分布式事务后面的步骤执行自己的本地事务。（这里的事务消息，Producer不会因为Consumer消费失败而做回滚，采用事务消息的应用，<br>其<strong>所追求的是高可用和最终一致性</strong>，消息消费失败的话，RocketMQ自己会负责重推消息，直到消费成功。）</li>
</ol>
<p>补偿流程：<strong>RocketMQ提供事务反查来解决异常情况</strong>，如果RocketMQ没有收到提交或者回滚的请求，Broker会定时到生产者上去反查本地事务的状态，<br>然后根据生产者本地事务的状态来处理这个“半消息”是提交还是回滚。值得注意的是我们需要根据自己的业务逻辑来实现反查逻辑接口，<br>然后根据返回值Broker决定是提交还是回滚。而且这个反查接口需要是无状态的，请求到任意一个生产者节点都会返回正确的数据</p>
<h3 id="kafka事务消息"><a href="#kafka事务消息" class="headerlink" title="kafka事务消息"></a>kafka事务消息</h3><h4 id="流处理"><a href="#流处理" class="headerlink" title="流处理"></a>流处理</h4><p><strong>要求每条消息都只处理一次，无一例外。</strong></p>
<p>如果流处理应用程序消费消息A并将结果作为消息B（B = f(A)），那么恰好一次处理保证意味着当且仅当B被成功生产后A才能被标记为消费<br><img src="/images/transaction/img_1.png" alt="img_1.png"></p>
<p><strong>事务API使流处理应用程序能够在一个原子操作中使用、处理和生成消息</strong>。这意味着，事务中的一批消息可以从许多主题分区接收、生成和确认。一个事务涉及的所有操作都作为整体成功或失败</p>
<h4 id="kafka事务消息-1"><a href="#kafka事务消息-1" class="headerlink" title="kafka事务消息"></a>kafka事务消息</h4><p>与RocketMQ的事务消息用途不同，<strong>Kafka的事务基本上是配合其幂等机制来实现Exactly-once（见上文）语义的。</strong></p>
<p>事务型Producer能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。<strong>以两阶段提交的方式</strong>，实现消息的事务提交。</p>
<p>Kafka事务消息是由Producer、事务协调器、Broker、组协调器、Consumer等共同参与实现的。</p>
<h3 id="Pulsar的事务消息"><a href="#Pulsar的事务消息" class="headerlink" title="Pulsar的事务消息"></a>Pulsar的事务消息</h3><p>Pulsar这里提供的事务区别于RocketMQ中2PC那种事务的实现方式，没有本地事务回查的机制，更类似于Kafka的事务实现机制。<br>Apache Pulsar中的事务主要用来保证类似Pulsar Functions这种流计算场景中<strong>Exactly-once</strong>语义的实现，这也符合Apache Pulsar本身Event Streaming的定位，即保证端到端（End-to-End）的事务实现的语义</p>
<p>在Pulsar中，对于事务语义是这样定义的：<strong>允许事件流应用将消费、处理、生产消息整个过程定义为一个原子操作，即生产者或消费者能够处理跨多个主题和分区的消息，并确保这些消息作为一个单元被处理。</strong></p>
<p>Pulsar事务具有以下语义：</p>
<ol>
<li><p>事务中的所有操作都作为一个单元提交。要么提交所有消息，要么都不提交。</p>
</li>
<li><p>每条消息只写入或处理一次，不会丢失数据或重复（即使发生故障）。</p>
</li>
<li><p>如果事务中止，则此事务中的所有写入和确认都将回滚。</p>
</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>RocketMQ和Kafka/Pulsar的事务消息实用的场景是不一样的。</p>
<p><strong>RocketMQ中的事务，它解决的问题是，确保执行本地事务和发消息这两个操作，要么都成功，要么都失败。</strong>并且RocketMQ增加了一个事务反查的机制，来尽量提高事务执行的成功率和数据一致性。</p>
<p><strong>Kafka中的事务，它解决的问题是，确保在一个事务中发送的多条消息，要么都成功，要么都失败。</strong>（<strong>这里面的多条消息不一定要在同一个主题和分区中，可以是发往多个主题和分区的消息</strong>）当然也可以在kafka事务执行过程中开启本地事务来实现类似RocketMQ事务消息的效果，但是Kafka是没有事务消息反查机制的，它是直接抛出异常的，用户可以根据异常来实现自己的重试等方法保证事务正常运行。</p>
<p>它们的共同点就是：<strong>都是通过两阶段提交来实现事务的</strong>，事务消息都保存在单独的主题上。不同的地方就是RocketMQ是通过“半消息”来实现的，kafka是直接将消息发送给对应的topic，通过客户端来过滤实现的。而且它们两个使用的场景区别是非常之大的，RockteMQ主要解决的是基于本地事务和消息的数据一致性，而<strong>Kafka的事务则是用于实现它的Exactly-once机制，应用于实时流计算的场景中。</strong></p>
<p>Pulsar的事务消息和Kafka应用场景和语义类似，只是由于底层实现机制有差别，在一些细节上有区别。</p>
<p>相信看到这里就非常清楚了，对于事务消息如何选型和应用，首先要明白你的业务需求是什么。是要实现分布式事务的最终一致性，还是要实现Exactly-once （精确一次）语义？明白之后需求，选择什么组件就十分明确了。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://mp.weixin.qq.com/s/Cmw3QExqCfBAz9V0AlsS9A">https://mp.weixin.qq.com/s/Cmw3QExqCfBAz9V0AlsS9A</a></p>
]]></content>
      <tags>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title>缓存一致性</title>
    <url>/2023/01/05/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7/</url>
    <content><![CDATA[<p>1、想要提高应用的性能，可以引入「缓存」来解决</p>
<p>2、引入缓存后，需要考虑缓存和数据库一致性问题，可选的方案有：「更新数据库 + 更新缓存」、「更新数据库 + 删除缓存」</p>
<p>3、更新数据库 + 更新缓存方案，在「并发」场景下无法保证缓存和数据一致性，解决方案是加「分布锁」，但这种方案存在「缓存资源浪费」和「机器性能浪费」的情况</p>
<p>4、采用「先删除缓存，再更新数据库」方案，在「并发」场景下依旧有不一致问题，解决方案是「延迟双删」，但这个延迟时间很难评估</p>
<p>5、采用「先更新数据库，再删除缓存」方案，为了保证两步都成功执行，需配合「消息队列」或「订阅变更日志」的方案来做，本质是通过「重试」的方式保证数据最终一致</p>
<p>6、采用「先更新数据库，再删除缓存」方案，「读写分离 + 主从库延迟」也会导致缓存和数据库不一致，缓解此问题的方案是「延迟双删」，凭借经验发送「延迟消息」到队列中，延迟删除缓存，同时也要控制主从库延迟，尽可能降低不一致发生的概率</p>
<p>参考<br><a href="https://developer.baidu.com/article/detail.html?id=294416">https://developer.baidu.com/article/detail.html?id=294416</a></p>
]]></content>
  </entry>
  <entry>
    <title>java基础</title>
    <url>/2023/02/07/java%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<p>Java 不提供指针来直接访问内存，程序内存更加安全。可以使用线性分配器分配内存（<strong>因为线性分配器需要与具有拷贝特性的垃圾回收算法配合</strong>，所以 C 和 C++ ，<br>go等需要直接对外暴露指针的语言就无法使用该策略）</p>
<span id="more"></span>


<p>包装类型属于对象类型，我们知道几乎所有对象实例都存在于堆中。 为什么说是几乎所有对象实例呢？ 这是因为 HotSpot 虚拟机引入了 JIT 优化之后，<br>会对对象进行逃逸分析，如果发现某一个对象并没有逃逸到方法外部，那么就可能通过标量替换来实现栈上分配，而避免堆上分配内存</p>
<p>volatile 关键字其实并非是 Java 语言特有的，在 C 语言里也有，它最原始的意义就是<strong>禁用 CPU 缓存</strong>。如果我们将一个变量使用 volatile 修饰，<br>这就指示 编译器，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。<br>在 Java 中，volatile 关键字除了可以保证变量的可见性，还有一个重要的作用就是<strong>防止 JVM 的指令重排序</strong></p>
<p><a href="https://javaguide.cn/java/concurrent/java-concurrent-questions-02.html#threadlocal-%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98%E6%98%AF%E6%80%8E%E4%B9%88%E5%AF%BC%E8%87%B4%E7%9A%84">threadloal内存泄漏问题</a></p>
<p>主内存 ：所有线程创建的实例对象都存放在主内存中，不管该实例对象是成员变量还是方法中的本地变量(也称局部变量)<br>本地内存 ：每个线程都有一个私有的本地内存（比如机器的寄存器）来存储共享变量的副本，并且，每个线程只能访问自己的本地内存，无法访问其他线程的本地内存。本地内存是 JMM 抽象出来的一个概念，存储了主内存中的共享变量副本。</p>
<p>JVM 内存结构和 Java 虚拟机的运行时区域相关，定义了 JVM 在运行时如何分区存储程序数据，就比如说堆主要用于存放对象实例。<br>Java 内存模型和 Java 的并发编程相关，抽象了线程和主内存之间的关系就比如说线程之间的共享变量必须存储在主内存中，规定了从 Java 源代码到 CPU 可执行指令的这个转化过程要遵守哪些和并发相关的原则和规范，其主要目的是为了简化多线程编程，增强程序可移植性的。</p>
<p>happens-before 原则表达的意义其实并不是一个操作发生在另外一个操作的前面，虽然这从程序员的角度上来说也并无大碍。<br>更准确地来说，它更想表达的意义是前一个操作的结果对于后一个操作是可见的，<strong>无论这两个操作是否在同一个线程里</strong>。</p>
<p>happens-before 常见规则有哪些？<br>谈谈你的理解？happens-before 的规则就 8 条，说多不多，重点了解下面列举的 5 条即可。全记是不可能的，很快就忘记了，意义不大，随时查阅即可。<br>程序顺序规则 ：一个线程内，按照代码顺序，书写在前面的操作 happens-before 于书写在后面的操作；<br>解锁规则 ：解锁 happens-before 于加锁；<br>volatile 变量规则 ：对一个 volatile 变量的写操作 happens-before 于后面对这个 volatile 变量的读操作。说白了就是对 volatile 变量的写操作的结果对于发生于其后的任何操作都是可见的。<br>传递规则 ：如果 A happens-before B，且 B happens-before C，那么 A happens-before C；<br>线程启动规则 ：Thread 对象的 start()方法 happens-before 于此线程的每一个动作。</p>
<p>动态链接 主要服务一个方法需要调用其他方法的场景。在 Java 源文件被编译成字节码文件时，所有的变量和方法引用都作为符号引用（Symbilic Reference）保存在 Class 文件的常量池里。<br>当一个方法要调用其他方法，需要将常量池中指向方法的符号引用转化为其在内存地址中的直接引用。<strong>动态链接的作用就是为了将符号引用转换为调用方法的直接引用</strong>。</p>
<p>从 JDK 1.7 开始已经默认开启逃逸分析，如果某些方法中的对象引用没有被返回或者未被外面使用（也就是未逃逸出去），那么对象可以直接在栈上分配内存。</p>
<p>JDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel）与缓存区（Buffer）的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，<br>然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。</p>
<p>大多数情况下，对象在新生代中 Eden 区分配。当 Eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC。</p>
<ul>
<li><p>部分收集 (Partial GC)：</p>
<ul>
<li>新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集；</li>
<li>老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集；</li>
<li>混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。</li>
</ul>
</li>
<li><p>整堆收集 (Full GC)：收集整个 Java 堆和方法区。#</p>
</li>
<li><p>*空间分配担保**是为了确保在 Minor GC 之前老年代本身还有容纳新生代所有对象的剩余空间。 只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小，就会进行 Minor GC，否则将进行 Full GC。</p>
</li>
<li><p>哪些对象可以作为 GC Roots 呢？</p>
<ul>
<li>虚拟机栈(栈帧中的本地变量表)中引用的对象</li>
<li>本地方法栈(Native 方法)中引用的对象</li>
<li>方法区中类静态属性引用的对象</li>
<li>方法区中常量引用的对象</li>
<li>所有被同步锁持有的对象</li>
</ul>
</li>
</ul>
<p>软引用 如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。<strong>软引用可用来实现内存敏感的高速缓存</strong>。<br>弱引用 一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。</p>
<ul>
<li>如何判断一个类是无用的类<ul>
<li>该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。</li>
<li>加载该类的 ClassLoader 已经被回收。</li>
<li>该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。</li>
</ul>
</li>
</ul>
<p>新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。<br>而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”(让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。)算法进行垃圾收集。</p>
<ul>
<li><p>CMS收集器缺点</p>
<ul>
<li><strong>对 CPU 资源敏感</strong>；<br>由于GC线程是CPU密集型线程，且它与用户线程在“并发标记”与“并发清除”阶段是并发执行的，所以GC线程会与用户线程竞争CPU资源，使得部分用户线程得不到执行，导致应用程序的总吞吐量降低。</li>
<li><strong>无法处理浮动垃圾</strong>； 无法处理并发标记阶段 本来可达的对象由于用户线程的并发运行变成不可达的这部分对象</li>
<li>它使用的回收算法-“标记-清除”<strong>算法会导致收集结束时会有大量空间碎片产生</strong>。</li>
</ul>
</li>
<li><p>G1收集器特点</p>
<ul>
<li>并行与并发</li>
<li>分代收集</li>
<li>空间整合：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。、</li>
<li><strong>可预测的停顿</strong>：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。</li>
</ul>
</li>
<li><p>加载<br>类加载过程的第一步，主要完成下面 3 件事情：</p>
<ul>
<li>通过全类名获取定义此类的二进制字节流</li>
<li>将字节流所代表的静态存储结构转换为方法区的运行时数据结构</li>
<li>在内存中生成一个代表该类的 Class 对象，作为方法区这些数据的访问入口</li>
</ul>
</li>
<li><p>连接</p>
<ul>
<li>验证<br><img src="/images/java%E5%9F%BA%E7%A1%80/img.png" alt="img.png"></li>
<li>准备<ul>
<li>准备阶段是正式为类变量分配内存并设置类变量初始值的阶段</li>
</ul>
</li>
<li>解析<ul>
<li>解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，也就是得到类或者字段、方法在内存中的指针或者偏移量。</li>
</ul>
</li>
<li>初始化 只有主动去使用类才会初始化类<ul>
<li>初始化阶段是执行初始化方法 <clinit> ()方法的过程，是类加载的最后一步，这一步 JVM 才开始真正执行类中定义的 Java 程序代码(字节码)。</clinit></li>
</ul>
</li>
</ul>
</li>
<li><p>spring</p>
<ul>
<li><p><a href="https://cloud.tencent.com/developer/article/1497692">循环依赖</a></p>
<blockquote>
<p><a href="https://developer.aliyun.com/article/766880">https://developer.aliyun.com/article/766880</a></p>
</blockquote>
<ul>
<li><img src="/images/java%E5%9F%BA%E7%A1%80/circle_depencenties.png" alt="img.png"></li>
<li>以上面A、B类使用属性field注入循环依赖的例子为例，对整个流程做文字步骤总结如下：<ul>
<li>使用context.getBean(A.class)，旨在获取容器内的单例A(若A不存在，就会走A这个Bean的创建流程)，显然初次获取A是不存在的，因此走A的创建之路~</li>
<li>实例化A（注意此处仅仅是实例化），并将它放进缓存（此时A已经实例化完成，已经可以被引用了）</li>
<li>初始化A：@Autowired依赖注入B（此时需要去容器内获取B）</li>
<li>为了完成依赖注入B，会通过getBean(B)去容器内找B。但此时B在容器内不存在，就走向B的创建之路~</li>
<li>实例化B，并将其放入缓存。（此时B也能够被引用了）</li>
<li>初始化B，@Autowired依赖注入A（此时需要去容器内获取A）</li>
<li>此处重要：初始化B时会调用getBean(A)去容器内找到A，上面我们已经说过了此时候因为A已经实例化完成了并且放进了缓存里，所以这个时候去看缓存里是已经存在A的引用了的，所以getBean(A)能够正常返回</li>
<li>B初始化成功（此时已经注入A成功了，已成功持有A的引用了），return（注意此处return相当于是返回最上面的getBean(B)这句代码，回到了初始化A的流程中~）。</li>
<li>因为B实例已经成功返回了，因此最终A也初始化成功</li>
<li>到此，B持有的已经是初始化完成的A，A持有的也是初始化完成的B，完美~</li>
</ul>
</li>
</ul>
</li>
<li><p><a href="https://www.cnblogs.com/javaguide/p/springboot-auto-config.html">自动装配</a></p>
<ul>
<li>Spring Boot 通过@EnableAutoConfiguration开启自动装配，通过 SpringFactoriesLoader 最终加载META-INF/spring.factories中的自动配置类实现自动装配，<br>自动配置类其实就是通过@Conditional按需加载的配置类，想要其生效必须引入spring-boot-starter-xxx包实现起步依赖</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
  </entry>
</search>
